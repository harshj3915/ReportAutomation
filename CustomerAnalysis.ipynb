{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5953cd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Diagnostic function to examine an Excel file\n",
    "def examine_excel_file(file_path):\n",
    "    \"\"\"Examine the structure of an Excel file to understand its columns\"\"\"\n",
    "    try:\n",
    "        print(f\"\\nExamining file: {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # Try to read with pandas\n",
    "        df = pd.read_excel(file_path)\n",
    "        print(f\"Successfully read the file. Shape: {df.shape}\")\n",
    "        \n",
    "        # Display column info\n",
    "        print(\"\\nColumns:\")\n",
    "        for i, col in enumerate(df.columns):\n",
    "            print(f\"{i+1}. {col} - Type: {df[col].dtype} - Sample: {df[col].dropna().iloc[0] if not df[col].dropna().empty else 'No data'}\")\n",
    "        \n",
    "        # Check for potential duplicate columns\n",
    "        dupe_cols = df.columns[df.columns.duplicated()].tolist()\n",
    "        if dupe_cols:\n",
    "            print(f\"\\nWarning: Found {len(dupe_cols)} duplicate column names: {dupe_cols}\")\n",
    "        \n",
    "        # Look for specific columns we need\n",
    "        print(\"\\nLooking for required columns:\")\n",
    "        email_cols = [col for col in df.columns if 'email' in str(col).lower() or 'mail' in str(col).lower()]\n",
    "        date_cols = [col for col in df.columns if 'date' in str(col).lower() or 'time' in str(col).lower()]\n",
    "        type_cols = [col for col in df.columns if 'type' in str(col).lower() or 'source' in str(col).lower()]\n",
    "        order_type_cols = [col for col in df.columns if 'type' in str(col).lower() or 'return' in str(col).lower() or 'order' in str(col).lower()]\n",
    "        \n",
    "        print(f\"Potential email columns: {email_cols}\")\n",
    "        print(f\"Potential date columns: {date_cols}\")\n",
    "        print(f\"Potential type columns: {type_cols}\")\n",
    "        print(f\"Potential order type columns: {order_type_cols}\")\n",
    "        \n",
    "        return df\n",
    "    except Exception as e:\n",
    "        print(f\"Error examining file {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Examine a sample file from each financial year\n",
    "import os\n",
    "\n",
    "# Sample from financial year 1\n",
    "fy1_path = r\"C:\\Users\\91843\\Documents\\VsCode Codes\\ReportAutomation\\q\\financial_year_1\"\n",
    "fy1_files = [f for f in os.listdir(fy1_path) if f.endswith('.xlsx') and not f.startswith('~$')]\n",
    "if fy1_files:\n",
    "    sample_file1 = os.path.join(fy1_path, fy1_files[0])\n",
    "    print(f\"Examining sample from Financial Year 1: {fy1_files[0]}\")\n",
    "    sample_df1 = examine_excel_file(sample_file1)\n",
    "\n",
    "# Sample from financial year 2\n",
    "fy2_path = r\"C:\\Users\\91843\\Documents\\VsCode Codes\\ReportAutomation\\q\\financial_year_2\"\n",
    "fy2_files = [f for f in os.listdir(fy2_path) if f.endswith('.xlsx') and not f.startswith('~$')]\n",
    "if fy2_files:\n",
    "    sample_file2 = os.path.join(fy2_path, fy2_files[0])\n",
    "    print(f\"Examining sample from Financial Year 2: {fy2_files[0]}\")\n",
    "    sample_df2 = examine_excel_file(sample_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72ec29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to financial year directories\n",
    "fy1_path = r\"C:\\Users\\91843\\Documents\\VsCode Codes\\ReportAutomation\\q\\financial_year_1\"\n",
    "fy2_path = r\"C:\\Users\\91843\\Documents\\VsCode Codes\\ReportAutomation\\q\\financial_year_2\"\n",
    "q_main_path = r\"C:\\Users\\91843\\Documents\\VsCode Codes\\ReportAutomation\\q\"  # Main q directory with 2023 files and April25 data\n",
    "\n",
    "print(\"Starting customer analysis across financial years...\")\n",
    "\n",
    "def process_excel_file(file_path):\n",
    "    \"\"\"Process each Excel file and extract relevant data.\"\"\"\n",
    "    try:\n",
    "        # Skip temporary Excel files\n",
    "        if os.path.basename(file_path).startswith('~$'):\n",
    "            print(f\"Skipping temporary file: {os.path.basename(file_path)}\")\n",
    "            return None\n",
    "        \n",
    "        # Get all sheet names in the Excel file\n",
    "        excel_file = pd.ExcelFile(file_path)\n",
    "        sheet_names = excel_file.sheet_names\n",
    "        \n",
    "        # Look for sheets with 'export' in the name (case-insensitive)\n",
    "        export_sheets = [sheet for sheet in sheet_names if 'export' in sheet.lower()]\n",
    "        \n",
    "        if export_sheets:\n",
    "            # Use the first sheet with 'export' in the name\n",
    "            sheet_name = export_sheets[0]\n",
    "            print(f\"Reading '{sheet_name}' sheet from {os.path.basename(file_path)}\")\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        else:\n",
    "            # If no export sheet found, use the default first sheet\n",
    "            sheet_name = sheet_names[0]\n",
    "            print(f\"No 'Export' sheet found, using first sheet '{sheet_name}' from {os.path.basename(file_path)}\")\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet_name)\n",
    "        \n",
    "        # Print basic file info\n",
    "        print(f\"File: {os.path.basename(file_path)} - Shape: {df.shape}\")\n",
    "        \n",
    "        # Convert all column names to strings and lowercase for easier matching\n",
    "        df.columns = [str(col).lower().strip() for col in df.columns]\n",
    "        \n",
    "        # Based on the examination, directly map common column names found in the files\n",
    "        # Initialize columns\n",
    "        email_col = None\n",
    "        date_col = None\n",
    "        channel_col = None\n",
    "        order_type_col = None\n",
    "        \n",
    "        # Map column names based on common patterns in the files\n",
    "        for col in df.columns:\n",
    "            col_lower = col.lower()\n",
    "            \n",
    "            # Email columns\n",
    "            if 'customer' in col_lower and 'email' in col_lower:\n",
    "                email_col = col\n",
    "            elif 'email' in col_lower:\n",
    "                email_col = col\n",
    "            elif 'customer' in col_lower and 'mail' in col_lower:\n",
    "                email_col = col\n",
    "            elif col_lower == 'email':\n",
    "                email_col = col\n",
    "            \n",
    "            # Date columns\n",
    "            if 'order' in col_lower and 'date' in col_lower:\n",
    "                date_col = col\n",
    "            elif 'transaction' in col_lower and 'date' in col_lower:\n",
    "                date_col = col\n",
    "            elif 'purchase' in col_lower and 'date' in col_lower:\n",
    "                date_col = col\n",
    "            elif col_lower == 'date' or col_lower == 'orderdate':\n",
    "                date_col = col\n",
    "            \n",
    "            # Type columns (replacing channel columns)\n",
    "            if col_lower.strip() == 'type':\n",
    "                channel_col = col\n",
    "            elif 'sales' in col_lower and 'type' in col_lower:\n",
    "                channel_col = col\n",
    "            elif 'customer' in col_lower and 'type' in col_lower:\n",
    "                channel_col = col\n",
    "            elif 'retail' in col_lower and 'type' in col_lower:\n",
    "                channel_col = col\n",
    "            \n",
    "            # Order type columns\n",
    "            if 'order' in col_lower and 'type' in col_lower:\n",
    "                order_type_col = col\n",
    "            elif col_lower == 'retailordertype':\n",
    "                order_type_col = col\n",
    "            elif 'retail' in col_lower and 'type' in col_lower and col_lower != channel_col:\n",
    "                order_type_col = col\n",
    "            elif 'transaction' in col_lower and 'type' in col_lower:\n",
    "                order_type_col = col\n",
    "            elif col_lower == 'ordertype':\n",
    "                order_type_col = col\n",
    "        \n",
    "        # Fall back to more general searches if the specific patterns didn't match\n",
    "        if email_col is None:\n",
    "            # First try exact column names that might be email fields\n",
    "            exact_email_cols = ['email', 'customeremail', 'customer email', 'mail', 'customer_email']\n",
    "            found = False\n",
    "            for exact_col in exact_email_cols:\n",
    "                matches = [col for col in df.columns if col.lower() == exact_col]\n",
    "                if matches:\n",
    "                    email_col = matches[0]\n",
    "                    print(f\"Using exact match {email_col} as email column\")\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            # If still not found, try broader pattern matching\n",
    "            if not found:\n",
    "                for col in df.columns:\n",
    "                    col_lower = col.lower()\n",
    "                    if ('mail' in col_lower or 'customer' in col_lower or 'id' in col_lower) and len(col_lower) > 2:\n",
    "                        # Check if column contains email-like values (with @ symbol)\n",
    "                        if df[col].astype(str).str.contains('@', na=False).any():\n",
    "                            email_col = col\n",
    "                            print(f\"Using column with @ symbols: {col} as email column\")\n",
    "                            found = True\n",
    "                            break\n",
    "                \n",
    "                # Last resort, try any column with \"type\" in the name\n",
    "                if not found:\n",
    "                    for col in df.columns:\n",
    "                        if 'type' in col.lower() or 'customer' in col.lower():\n",
    "                            email_col = col\n",
    "                            print(f\"Using fallback column: {col} as email column\")\n",
    "                            break\n",
    "        \n",
    "        if date_col is None:\n",
    "            for col in df.columns:\n",
    "                col_lower = col.lower()\n",
    "                if 'date' in col_lower or 'time' in col_lower or 'day' in col_lower:\n",
    "                    date_col = col\n",
    "                    print(f\"Using {col} as date column\")\n",
    "                    break\n",
    "        \n",
    "        if channel_col is None:\n",
    "            # First try exact columns that might be type fields\n",
    "            exact_type_cols = ['type', 'salestype', 'sales type', 'customertype']\n",
    "            found = False\n",
    "            for exact_col in exact_type_cols:\n",
    "                matches = [col for col in df.columns if col.lower() == exact_col]\n",
    "                if matches:\n",
    "                    channel_col = matches[0]\n",
    "                    print(f\"Using exact match {channel_col} as type column\")\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            # If still not found, try broader pattern matching\n",
    "            if not found:\n",
    "                for col in df.columns:\n",
    "                    col_lower = col.lower()\n",
    "                    if ('type' in col_lower or 'source' in col_lower or 'medium' in col_lower or \n",
    "                        'platform' in col_lower or 'store' in col_lower):\n",
    "                        channel_col = col\n",
    "                        print(f\"Using {col} as type column\")\n",
    "                        break\n",
    "                        \n",
    "                # If still no type, use retailcustomertype if available (based on your data structure)\n",
    "                if not found and 'retailcustomertype' in [c.lower() for c in df.columns]:\n",
    "                    for col in df.columns:\n",
    "                        if col.lower() == 'retailcustomertype':\n",
    "                            channel_col = col\n",
    "                            print(f\"Using {col} as fallback type column\")\n",
    "                            break\n",
    "        \n",
    "        if order_type_col is None:\n",
    "            exact_type_cols = ['ordertype', 'retailordertype', 'ordertype', 'order_type']\n",
    "            found = False\n",
    "            for exact_col in exact_type_cols:\n",
    "                matches = [col for col in df.columns if col.lower() == exact_col]\n",
    "                if matches:\n",
    "                    order_type_col = matches[0]\n",
    "                    print(f\"Using exact match {order_type_col} as order type column\")\n",
    "                    found = True\n",
    "                    break\n",
    "            \n",
    "            if not found:\n",
    "                for col in df.columns:\n",
    "                    col_lower = col.lower()\n",
    "                    if ('type' in col_lower or 'status' in col_lower or 'order' in col_lower):\n",
    "                        order_type_col = col\n",
    "                        print(f\"Using {col} as order type column\")\n",
    "                        break\n",
    "                        \n",
    "                # If still no order type, use retailcustomertype if available\n",
    "                if not found and channel_col and channel_col.lower() == 'retailcustomertype':\n",
    "                    order_type_col = channel_col\n",
    "                    print(f\"Using same field for both channel and order type: {order_type_col}\")\n",
    "        \n",
    "        # Log what we found\n",
    "        print(f\"Column mapping for {os.path.basename(file_path)}:\")\n",
    "        print(f\"  Email: {email_col}\")\n",
    "        print(f\"  Date: {date_col}\")\n",
    "        print(f\"  Type: {channel_col}\")\n",
    "        print(f\"  Order Type: {order_type_col}\")\n",
    "        \n",
    "        # Check if we found all required columns\n",
    "        if email_col is None:\n",
    "            print(f\"Warning: Required email column not found in {os.path.basename(file_path)}\")\n",
    "            return None\n",
    "        \n",
    "        # If channel or order_type is missing, we'll create them with default values\n",
    "        missing = []\n",
    "        if channel_col is None: \n",
    "            missing.append(\"type\")\n",
    "            print(f\"Warning: Type column not found in {os.path.basename(file_path)}, will use default value 'UNKNOWN'\")\n",
    "        \n",
    "        if order_type_col is None: \n",
    "            missing.append(\"order type\")\n",
    "            print(f\"Warning: Order type column not found in {os.path.basename(file_path)}, will use default value 'sales order'\")\n",
    "        \n",
    "        if missing:\n",
    "            print(f\"Creating default values for missing columns: {', '.join(missing)}\")\n",
    "        \n",
    "        # Create a clean DataFrame with consistent column names\n",
    "        new_df = pd.DataFrame()\n",
    "        \n",
    "        # Add each column with standardized names\n",
    "        try:\n",
    "            new_df['customeremail'] = df[email_col].astype(str)\n",
    "        except:\n",
    "            print(f\"Error extracting email column '{email_col}' from {os.path.basename(file_path)}\")\n",
    "            return None\n",
    "            \n",
    "        # Add date if available\n",
    "        if date_col:\n",
    "            try:\n",
    "                new_df['order_date'] = pd.to_datetime(df[date_col], errors='coerce')\n",
    "                # Extract month and year\n",
    "                new_df['month'] = new_df['order_date'].dt.month\n",
    "                new_df['year'] = new_df['order_date'].dt.year\n",
    "            except:\n",
    "                print(f\"Error extracting date column '{date_col}' from {os.path.basename(file_path)}\")\n",
    "                new_df['order_date'] = None\n",
    "        \n",
    "        # Add channel and order type (with fallback defaults)\n",
    "        if channel_col:\n",
    "            try:\n",
    "                new_df['channel'] = df[channel_col].astype(str)\n",
    "            except:\n",
    "                print(f\"Error extracting type column '{channel_col}' from {os.path.basename(file_path)}\")\n",
    "                new_df['channel'] = 'UNKNOWN'\n",
    "        else:\n",
    "            # Default type value if column is missing\n",
    "            new_df['channel'] = 'UNKNOWN'\n",
    "            \n",
    "        if order_type_col:\n",
    "            try:\n",
    "                new_df['retailordertype'] = df[order_type_col].astype(str)\n",
    "            except:\n",
    "                print(f\"Error extracting order type column '{order_type_col}' from {os.path.basename(file_path)}\")\n",
    "                new_df['retailordertype'] = 'sales order'\n",
    "        else:\n",
    "            # Default order type value if column is missing\n",
    "            new_df['retailordertype'] = 'sales order'\n",
    "        \n",
    "        # Add file name as metadata\n",
    "        new_df['file_name'] = os.path.basename(file_path)\n",
    "        \n",
    "        # Drop rows with missing values in critical columns\n",
    "        new_df = new_df.dropna(subset=['customeremail', 'channel', 'retailordertype'])\n",
    "        \n",
    "        # Final check on data quality\n",
    "        valid_rows = len(new_df)\n",
    "        print(f\"Processed {os.path.basename(file_path)}: Found {valid_rows} valid records (after filtering for POS/Jumbo.ae types)\")\n",
    "        \n",
    "        if valid_rows == 0:\n",
    "            print(f\"Warning: No valid data found in {os.path.basename(file_path)} after processing and type filtering\")\n",
    "            return None\n",
    "            \n",
    "        return new_df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing file {file_path}: {str(e)}\")\n",
    "        return None\n",
    "\n",
    "# Process all files in financial year 1 (excluding temporary Excel files)\n",
    "fy1_files = [os.path.join(fy1_path, f) for f in os.listdir(fy1_path) \n",
    "             if f.endswith('.xlsx') and not f.startswith('~$')]\n",
    "print(f\"Found {len(fy1_files)} Excel files in Financial Year 1\")\n",
    "\n",
    "# Process all files in financial year 2 (excluding temporary Excel files)\n",
    "fy2_files = [os.path.join(fy2_path, f) for f in os.listdir(fy2_path) \n",
    "             if f.endswith('.xlsx') and not f.startswith('~$')]\n",
    "print(f\"Found {len(fy2_files)} Excel files in Financial Year 2\")\n",
    "\n",
    "# Process files in the main q directory (2023 files)\n",
    "main_q_files = [os.path.join(q_main_path, f) for f in os.listdir(q_main_path) \n",
    "                if f.endswith('.xlsx') and not f.startswith('~$') and os.path.isfile(os.path.join(q_main_path, f))]\n",
    "print(f\"Found {len(main_q_files)} Excel files in Main Q Directory (2023 files)\")\n",
    "\n",
    "# Process FY1 files in chunks to optimize memory usage\n",
    "print(\"Processing Financial Year 1 data...\")\n",
    "fy1_dfs = []\n",
    "fy1_processed_files = set()  # Track which files have been processed\n",
    "\n",
    "for file in fy1_files:\n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if filename in fy1_processed_files:\n",
    "        print(f\"Skipping already processed file: {filename}\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing: {filename}\")\n",
    "    fy1_processed_files.add(filename)\n",
    "    \n",
    "    df = process_excel_file(file)\n",
    "    if df is not None and not df.empty:\n",
    "        fy1_dfs.append(df)\n",
    "        print(f\"Added {len(df)} records from {filename}\")\n",
    "\n",
    "# Combine all FY1 data\n",
    "if fy1_dfs:\n",
    "    fy1_data = pd.concat(fy1_dfs, ignore_index=True)\n",
    "    print(f\"FY1 data shape: {fy1_data.shape} with {fy1_data['customeremail'].nunique()} unique customers\")\n",
    "else:\n",
    "    print(\"No valid data found for Financial Year 1\")\n",
    "    fy1_data = pd.DataFrame()\n",
    "\n",
    "# Process FY2 files in chunks to optimize memory usage\n",
    "print(\"\\nProcessing Financial Year 2 data...\")\n",
    "fy2_dfs = []\n",
    "fy2_processed_files = set()  # Track which files have been processed\n",
    "\n",
    "for file in fy2_files:\n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if filename in fy2_processed_files:\n",
    "        print(f\"Skipping already processed file: {filename}\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing: {filename}\")\n",
    "    fy2_processed_files.add(filename)\n",
    "    \n",
    "    df = process_excel_file(file)\n",
    "    if df is not None and not df.empty:\n",
    "        fy2_dfs.append(df)\n",
    "        print(f\"Added {len(df)} records from {filename}\")\n",
    "\n",
    "# Combine all FY2 data\n",
    "if fy2_dfs:\n",
    "    fy2_data = pd.concat(fy2_dfs, ignore_index=True)\n",
    "    print(f\"FY2 data shape: {fy2_data.shape} with {fy2_data['customeremail'].nunique()} unique customers\")\n",
    "else:\n",
    "    print(\"No valid data found for Financial Year 2\")\n",
    "    fy2_data = pd.DataFrame()\n",
    "\n",
    "# Process Main Q files (2023 data) in chunks to optimize memory usage\n",
    "print(\"\\nProcessing Main Q directory data (2023 files)...\")\n",
    "q_2023_dfs = []\n",
    "q_2023_processed_files = set()  # Track which files have been processed\n",
    "\n",
    "for file in main_q_files:\n",
    "    filename = os.path.basename(file)\n",
    "    \n",
    "    # Skip April25 file as it belongs to 2025, not 2023\n",
    "    if 'april25' in filename.lower() or 'april_25' in filename.lower():\n",
    "        print(f\"Skipping April25 file (belongs to 2025): {filename}\")\n",
    "        continue\n",
    "    \n",
    "    # Skip if already processed\n",
    "    if filename in q_2023_processed_files:\n",
    "        print(f\"Skipping already processed file: {filename}\")\n",
    "        continue\n",
    "        \n",
    "    print(f\"Processing: {filename}\")\n",
    "    q_2023_processed_files.add(filename)\n",
    "    \n",
    "    df = process_excel_file(file)\n",
    "    if df is not None and not df.empty:\n",
    "        q_2023_dfs.append(df)\n",
    "        print(f\"Added {len(df)} records from {filename}\")\n",
    "\n",
    "# Combine all 2023 data\n",
    "if q_2023_dfs:\n",
    "    q_2023_data = pd.concat(q_2023_dfs, ignore_index=True)\n",
    "    print(f\"2023 data shape: {q_2023_data.shape} with {q_2023_data['customeremail'].nunique()} unique customers\")\n",
    "else:\n",
    "    print(\"No valid data found for 2023\")\n",
    "    q_2023_data = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4942e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Customer Analysis with Visualizations\n",
    "from IPython.display import display, HTML\n",
    "import pandas as pd\n",
    "\n",
    "print(\"\\n===== CUSTOMER ANALYSIS REPORT =====\\n\")\n",
    "\n",
    "# === Handle empty dataframes ===\n",
    "if fy1_data.empty and fy2_data.empty:\n",
    "    print(\"Error: Data for both financial years is missing. Cannot complete analysis.\")\n",
    "elif fy1_data.empty:\n",
    "    print(\"Warning: No data for Financial Year 1. Partial analysis will be performed.\")\n",
    "elif fy2_data.empty:\n",
    "    print(\"Warning: No data for Financial Year 2. Partial analysis will be performed.\")\n",
    "else:\n",
    "    # === Clean up emails for better matching ===\n",
    "    print(\"Standardizing email formats for accurate matching...\")\n",
    "    \n",
    "    # Function to clean and standardize email addresses\n",
    "    def clean_email(email):\n",
    "        if pd.isna(email) or not isinstance(email, str):\n",
    "            return email\n",
    "        return email.strip().lower()\n",
    "    \n",
    "    fy1_data['customeremail'] = fy1_data['customeremail'].apply(clean_email)\n",
    "    fy2_data['customeremail'] = fy2_data['customeremail'].apply(clean_email)\n",
    "    \n",
    "    # === ANALYSIS 1: Basic Customer Counts ===\n",
    "    print(\"\\n1. BASIC CUSTOMER COUNTS\")\n",
    "    print(\"This table shows the total unique customers in each financial year and their year-over-year change.\")\n",
    "    \n",
    "    fy1_total_emails = fy1_data['customeremail'].nunique()\n",
    "    fy2_total_emails = fy2_data['customeremail'].nunique()\n",
    "    \n",
    "    # Create a DataFrame for display\n",
    "    basic_counts_df = pd.DataFrame({\n",
    "        'Metric': ['Unique Customers', 'Year-over-Year Change'],\n",
    "        'FY1': [f\"{fy1_total_emails:,}\", \"\"],\n",
    "        'FY2': [f\"{fy2_total_emails:,}\", \"\"],\n",
    "        'Change': [\"\", f\"{((fy2_total_emails - fy1_total_emails) / fy1_total_emails * 100):.2f}% ({'increase' if fy2_total_emails >= fy1_total_emails else 'decrease'})\"]\n",
    "    })\n",
    "    \n",
    "    # Calculate change percentage for later use\n",
    "    change_percent = ((fy2_total_emails - fy1_total_emails) / fy1_total_emails * 100) if fy1_total_emails > 0 else 0\n",
    "    \n",
    "    # Apply styling to the DataFrame\n",
    "    styled_basic_counts = basic_counts_df.style.set_properties(**{'text-align': 'center'})\n",
    "    styled_basic_counts = styled_basic_counts.set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#4472C4'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "        {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nData Sources and Formulas:\")\n",
    "    print(\"- FY1 Unique Customers: Count of distinct emails in fy1_data dataframe\")\n",
    "    print(\"- FY2 Unique Customers: Count of distinct emails in fy2_data dataframe\")\n",
    "    print(\"- Year-over-Year Change: ((FY2 Count - FY1 Count) / FY1 Count) * 100%\")\n",
    "    print(\"  Formula: ((fy2_total_emails - fy1_total_emails) / fy1_total_emails * 100)\")\n",
    "    \n",
    "    display(styled_basic_counts)\n",
    "    \n",
    "    # === ANALYSIS 2: Customer Retention Analysis ===\n",
    "    print(\"\\n2. CUSTOMER RETENTION ANALYSIS\")\n",
    "    print(\"This table shows customer retention metrics including retained customers from FY1, new customers in FY2, and lost customers from FY1.\")\n",
    "    \n",
    "    fy1_unique_customers = set(fy1_data['customeremail'].unique())\n",
    "    fy2_unique_customers = set(fy2_data['customeremail'].unique())\n",
    "    \n",
    "    # Find overlapping customers (retained)\n",
    "    retained_customers = fy1_unique_customers.intersection(fy2_unique_customers)\n",
    "    new_customers_in_fy2 = fy2_unique_customers - fy1_unique_customers\n",
    "    lost_customers_from_fy1 = fy1_unique_customers - fy2_unique_customers\n",
    "    \n",
    "    # Create retention analysis DataFrame\n",
    "    retention_df = pd.DataFrame({\n",
    "        'Metric': ['Retained Customers', 'New Customers in FY2', 'Lost Customers from FY1'],\n",
    "        'Count': [\n",
    "            len(retained_customers),\n",
    "            len(new_customers_in_fy2),\n",
    "            len(lost_customers_from_fy1)\n",
    "        ],\n",
    "        'Percentage': [\n",
    "            f\"{len(retained_customers)/len(fy1_unique_customers)*100:.2f}% of FY1\",\n",
    "            f\"{len(new_customers_in_fy2)/len(fy2_unique_customers)*100:.2f}% of FY2\",\n",
    "            f\"{len(lost_customers_from_fy1)/len(fy1_unique_customers)*100:.2f}% of FY1\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Apply styling to retention DataFrame\n",
    "    styled_retention = retention_df.style.set_properties(**{'text-align': 'center'})\n",
    "    styled_retention = styled_retention.set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#4472C4'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "        {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nData Sources and Formulas:\")\n",
    "    print(\"- Retained Customers: Intersection of unique customers in FY1 and FY2\")\n",
    "    print(\"  Formula: len(fy1_unique_customers.intersection(fy2_unique_customers))\")\n",
    "    print(\"- New Customers in FY2: Customers in FY2 not present in FY1\")\n",
    "    print(\"  Formula: len(fy2_unique_customers - fy1_unique_customers)\")\n",
    "    print(\"- Lost Customers from FY1: Customers in FY1 not present in FY2\")\n",
    "    print(\"  Formula: len(fy1_unique_customers - fy2_unique_customers)\")\n",
    "    print(\"- Percentage calculations: (Count / Total relevant customers) * 100%\")\n",
    "    \n",
    "    display(styled_retention)\n",
    "    \n",
    "    # === ANALYSIS 3: Type Distribution Analysis ===\n",
    "    print(\"\\n3. TYPE DISTRIBUTION ANALYSIS\")\n",
    "    print(\"These tables show how customers are distributed across different types (POS and Jumbo.ae) for each financial year.\")\n",
    "    \n",
    "    # FY1 Type Distribution\n",
    "    print(\"\\nFinancial Year 1 Type Distribution:\")\n",
    "    fy1_channel_dist = fy1_data.groupby('channel')['customeremail'].nunique().reset_index()\n",
    "    fy1_channel_dist.columns = ['Type', 'Unique Customers']\n",
    "    fy1_channel_dist['Percentage'] = fy1_channel_dist['Unique Customers'] / fy1_channel_dist['Unique Customers'].sum() * 100\n",
    "    fy1_channel_dist['Percentage'] = fy1_channel_dist['Percentage'].apply(lambda x: f\"{x:.2f}%\")\n",
    "    \n",
    "    # Style FY1 type distribution\n",
    "    styled_fy1_channel = fy1_channel_dist.style.set_properties(**{'text-align': 'center'})\n",
    "    styled_fy1_channel = styled_fy1_channel.set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#5B9BD5'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "        {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nFY1 Type Distribution - Data Sources and Formulas:\")\n",
    "    print(\"- Data Source: fy1_data dataframe, grouped by 'channel' column (now containing Type data)\")\n",
    "    print(\"- Unique Customers: Count of distinct email addresses per type\")\n",
    "    print(\"  Formula: fy1_data.groupby('channel')['customeremail'].nunique()\")\n",
    "    print(\"- Percentage: (Type customer count / Total unique customers) * 100%\")\n",
    "    print(\"  Formula: type_count / total_count * 100\")\n",
    "    \n",
    "    display(styled_fy1_channel)\n",
    "    \n",
    "    # FY2 Type Distribution\n",
    "    print(\"\\nFinancial Year 2 Type Distribution:\")\n",
    "    fy2_channel_dist = fy2_data.groupby('channel')['customeremail'].nunique().reset_index()\n",
    "    fy2_channel_dist.columns = ['Type', 'Unique Customers']\n",
    "    fy2_channel_dist['Percentage'] = fy2_channel_dist['Unique Customers'] / fy2_channel_dist['Unique Customers'].sum() * 100\n",
    "    fy2_channel_dist['Percentage'] = fy2_channel_dist['Percentage'].apply(lambda x: f\"{x:.2f}%\")\n",
    "    \n",
    "    # Style FY2 type distribution\n",
    "    styled_fy2_channel = fy2_channel_dist.style.set_properties(**{'text-align': 'center'})\n",
    "    styled_fy2_channel = styled_fy2_channel.set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#5B9BD5'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "        {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nFY2 Type Distribution - Data Sources and Formulas:\")\n",
    "    print(\"- Data Source: fy2_data dataframe, grouped by 'channel' column (now containing Type data)\")\n",
    "    print(\"- Unique Customers: Count of distinct email addresses per type\")\n",
    "    print(\"  Formula: fy2_data.groupby('channel')['customeremail'].nunique()\")\n",
    "    print(\"- Percentage: (Type customer count / Total unique customers) * 100%\")\n",
    "    print(\"  Formula: type_count / total_count * 100\")\n",
    "    \n",
    "    display(styled_fy2_channel)\n",
    "    \n",
    "    # Type Shift Analysis\n",
    "    print(\"\\nType Shift Analysis:\")\n",
    "    print(\"This table shows how customer type distribution has changed from FY1 to FY2.\")\n",
    "    \n",
    "    if not fy1_channel_dist.empty and not fy2_channel_dist.empty:\n",
    "        # Convert percentage strings back to floats for calculations\n",
    "        fy1_channel_dist['Percentage_num'] = fy1_channel_dist['Percentage'].str.rstrip('%').astype(float)\n",
    "        fy2_channel_dist['Percentage_num'] = fy2_channel_dist['Percentage'].str.rstrip('%').astype(float)\n",
    "        \n",
    "        # Merge and calculate changes\n",
    "        channel_shift = pd.merge(\n",
    "            fy1_channel_dist[['Type', 'Percentage_num']], \n",
    "            fy2_channel_dist[['Type', 'Percentage_num']], \n",
    "            on='Type', \n",
    "            suffixes=('_FY1', '_FY2')\n",
    "        )\n",
    "        \n",
    "        if not channel_shift.empty:\n",
    "            channel_shift['Change'] = channel_shift['Percentage_num_FY2'] - channel_shift['Percentage_num_FY1']\n",
    "            \n",
    "            # Format for display\n",
    "            channel_shift['FY1 %'] = channel_shift['Percentage_num_FY1'].apply(lambda x: f\"{x:.2f}%\")\n",
    "            channel_shift['FY2 %'] = channel_shift['Percentage_num_FY2'].apply(lambda x: f\"{x:.2f}%\")\n",
    "            channel_shift['Change %'] = channel_shift['Change'].apply(lambda x: f\"{x:.2f}%\")\n",
    "            \n",
    "            # Final display columns\n",
    "            shift_display = channel_shift[['Type', 'FY1 %', 'FY2 %', 'Change %']]\n",
    "            \n",
    "            # Style channel shift table\n",
    "            styled_shift = shift_display.style.set_properties(**{'text-align': 'center'})\n",
    "            styled_shift = styled_shift.set_table_styles([\n",
    "                {'selector': 'th', 'props': [('background-color', '#4472C4'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "                {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "            ])\n",
    "            \n",
    "            # Apply conditional formatting to change column\n",
    "            def style_change(val):\n",
    "                val_num = float(val.rstrip('%'))\n",
    "                if val_num > 0:\n",
    "                    return 'color: green'\n",
    "                elif val_num < 0:\n",
    "                    return 'color: red'\n",
    "                return ''\n",
    "            \n",
    "            styled_shift = styled_shift.applymap(style_change, subset=['Change %'])\n",
    "            \n",
    "            print(\"\\nType Shift Analysis - Data Sources and Formulas:\")\n",
    "            print(\"- Data Sources: Percentages from FY1 and FY2 type distribution tables\")\n",
    "            print(\"- FY1 %: Percentage of customers using each type in FY1\")\n",
    "            print(\"- FY2 %: Percentage of customers using each type in FY2\")\n",
    "            print(\"- Change %: FY2 percentage - FY1 percentage\")\n",
    "            print(\"  Formula: channel_shift['Percentage_num_FY2'] - channel_shift['Percentage_num_FY1']\")\n",
    "            print(\"- Positive values (green) indicate growth, negative values (red) indicate decline\")\n",
    "            \n",
    "            display(styled_shift)\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63c672a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ANALYSIS 4: Order Type Analysis (Sales vs. Returns) ===\n",
    "print(\"\\n4. ORDER TYPE ANALYSIS\")\n",
    "print(\"These tables show the distribution of customers by order type (sales orders vs. returned orders) for each financial year.\")\n",
    "\n",
    "# Function to analyze order types with tables\n",
    "def analyze_order_types(data, year_label):\n",
    "    # Count unique customers by order type\n",
    "    order_type_counts = data.groupby('retailordertype')['customeremail'].nunique().reset_index()\n",
    "    order_type_counts.columns = ['Order Type', 'Unique Customers']\n",
    "    order_type_counts['Percentage'] = order_type_counts['Unique Customers'] / order_type_counts['Unique Customers'].sum() * 100\n",
    "    order_type_counts['Percentage'] = order_type_counts['Percentage'].apply(lambda x: f\"{x:.2f}%\")\n",
    "    \n",
    "    # Style the table\n",
    "    styled_order_types = order_type_counts.style.set_properties(**{'text-align': 'center'})\n",
    "    styled_order_types = styled_order_types.set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#5B9BD5'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "        {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\n{year_label} Order Type Distribution:\")\n",
    "    print(f\"Data Sources and Formulas for {year_label}:\")\n",
    "    print(f\"- Data Source: '{year_label.lower()}' dataframe, grouped by 'retailordertype' column\")\n",
    "    print(\"- Unique Customers: Count of distinct email addresses per order type\")\n",
    "    print(\"  Formula: data.groupby('retailordertype')['customeremail'].nunique()\")\n",
    "    print(\"- Percentage: (Order type customer count / Total unique customers) * 100%\")\n",
    "    print(\"  Formula: count / total * 100\")\n",
    "    \n",
    "    display(styled_order_types)\n",
    "    \n",
    "    # Identify customers who only returned products\n",
    "    all_customers = set(data['customeremail'].unique())\n",
    "    sales_customers = set(data[data['retailordertype'] == 'sales order']['customeremail'].unique())\n",
    "    only_return_customers = all_customers - sales_customers\n",
    "    \n",
    "    return_percent = len(only_return_customers) / len(all_customers) * 100 if all_customers else 0\n",
    "    \n",
    "    # Create a DataFrame for customers with only returns\n",
    "    return_only_df = pd.DataFrame({\n",
    "        'Metric': ['Customers with only returns (no purchases)'],\n",
    "        'Count': [len(only_return_customers)],\n",
    "        'Percentage': [f\"{return_percent:.2f}% of total customers\"]\n",
    "    })\n",
    "    \n",
    "    # Style the returns-only table\n",
    "    styled_returns = return_only_df.style.set_properties(**{'text-align': 'center'})\n",
    "    styled_returns = styled_returns.set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#C00000'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "        {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\n{year_label} Returns-Only Analysis:\")\n",
    "    print(\"- Data Source: Comparison of all customers vs customers who made sales\")\n",
    "    print(\"- Formula: Customers with only returns = all_customers - sales_customers\")\n",
    "    print(\"  where sales_customers = customers with retailordertype = 'sales order'\")\n",
    "    print(\"- Percentage: (Count / Total unique customers) * 100%\")\n",
    "    \n",
    "    display(styled_returns)\n",
    "    \n",
    "    return only_return_customers\n",
    "\n",
    "# Analyze order types for both financial years\n",
    "fy1_only_returns = analyze_order_types(fy1_data, \"Financial Year 1\")\n",
    "fy2_only_returns = analyze_order_types(fy2_data, \"Financial Year 2\")\n",
    "\n",
    "# === ANALYSIS 5: Cross-Type Customer Behavior ===\n",
    "print(\"\\n5. CROSS-TYPE CUSTOMER BEHAVIOR\")\n",
    "print(\"These tables show how customers use different types - whether they shop exclusively through one type (POS or Jumbo.ae) or use multiple types.\")\n",
    "\n",
    "# Function to analyze cross-type behavior\n",
    "def analyze_cross_type(data, year_label):\n",
    "    # Count customers who used both types\n",
    "    all_customers = set(data['customeremail'].unique())\n",
    "    pos_customers = set(data[data['channel'] == 'POS']['customeremail'].unique())\n",
    "    jumbo_customers = set(data[data['channel'] == 'Jumbo.ae']['customeremail'].unique())\n",
    "    \n",
    "    cross_type_customers = pos_customers.intersection(jumbo_customers)\n",
    "    pos_only_customers = pos_customers - cross_type_customers\n",
    "    jumbo_only_customers = jumbo_customers - cross_type_customers\n",
    "    \n",
    "    total = len(all_customers)\n",
    "    \n",
    "    # Create DataFrame for cross-type analysis\n",
    "    cross_type_df = pd.DataFrame({\n",
    "        'Customer Type': ['POS-only customers', 'Jumbo.ae-only customers', 'Cross-type customers'],\n",
    "        'Count': [len(pos_only_customers), len(jumbo_only_customers), len(cross_type_customers)],\n",
    "        'Percentage': [\n",
    "            f\"{len(pos_only_customers)/total*100:.2f}%\",\n",
    "            f\"{len(jumbo_only_customers)/total*100:.2f}%\",\n",
    "            f\"{len(cross_type_customers)/total*100:.2f}%\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Style the cross-type table\n",
    "    styled_cross_type = cross_type_df.style.set_properties(**{'text-align': 'center'})\n",
    "    styled_cross_type = styled_cross_type.set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#4472C4'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "        {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "    ])\n",
    "    \n",
    "    print(f\"\\n{year_label} Cross-Type Analysis:\")\n",
    "    print(f\"Data Sources and Formulas for {year_label}:\")\n",
    "    print(\"- Data Source: Customer sets categorized by type usage\")\n",
    "    print(\"- POS-only customers: Customers who only used POS type\")\n",
    "    print(\"  Formula: pos_customers - cross_type_customers\")\n",
    "    print(\"- Jumbo.ae-only customers: Customers who only used Jumbo.ae type\")\n",
    "    print(\"  Formula: jumbo_customers - cross_type_customers\")\n",
    "    print(\"- Cross-type customers: Customers who used both POS and Jumbo.ae\")\n",
    "    print(\"  Formula: pos_customers.intersection(jumbo_customers)\")\n",
    "    print(\"- Percentage: (Customer count / Total unique customers) * 100%\")\n",
    "    \n",
    "    display(styled_cross_type)\n",
    "    \n",
    "    return cross_type_customers, pos_only_customers, jumbo_only_customers\n",
    "\n",
    "# Analyze cross-type behavior for both financial years\n",
    "fy1_cross, fy1_pos_only, fy1_jumbo_only = analyze_cross_type(fy1_data, \"Financial Year 1\")\n",
    "fy2_cross, fy2_pos_only, fy2_jumbo_only = analyze_cross_type(fy2_data, \"Financial Year 2\")\n",
    "\n",
    "# Cross-type loyalty analysis\n",
    "print(\"\\nCross-Type Customer Loyalty:\")\n",
    "print(\"This table shows the retention rates for different types of customers based on their type usage patterns.\")\n",
    "\n",
    "fy1_cross_retained = fy1_cross.intersection(fy2_unique_customers)\n",
    "cross_type_retention_rate = len(fy1_cross_retained) / len(fy1_cross) * 100 if fy1_cross else 0\n",
    "\n",
    "fy1_pos_only_retained = fy1_pos_only.intersection(fy2_unique_customers)\n",
    "pos_only_retention_rate = len(fy1_pos_only_retained) / len(fy1_pos_only) * 100 if fy1_pos_only else 0\n",
    "\n",
    "fy1_jumbo_only_retained = fy1_jumbo_only.intersection(fy2_unique_customers)\n",
    "jumbo_only_retention_rate = len(fy1_jumbo_only_retained) / len(fy1_jumbo_only) * 100 if fy1_jumbo_only else 0\n",
    "\n",
    "# Create DataFrame for retention rates by type\n",
    "type_retention_df = pd.DataFrame({\n",
    "    'Customer Type': ['Cross-type customers', 'POS-only customers', 'Jumbo.ae-only customers'],\n",
    "    'Retention Rate': [\n",
    "        f\"{cross_type_retention_rate:.2f}%\",\n",
    "        f\"{pos_only_retention_rate:.2f}%\",\n",
    "        f\"{jumbo_only_retention_rate:.2f}%\"\n",
    "    ],\n",
    "    'FY1 Count': [len(fy1_cross), len(fy1_pos_only), len(fy1_jumbo_only)],\n",
    "    'Retained Count': [len(fy1_cross_retained), len(fy1_pos_only_retained), len(fy1_jumbo_only_retained)]\n",
    "})\n",
    "\n",
    "# Style the retention rates table\n",
    "styled_type_retention = type_retention_df.style.set_properties(**{'text-align': 'center'})\n",
    "styled_type_retention = styled_type_retention.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#5B9BD5'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "    {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "])\n",
    "\n",
    "# Apply conditional formatting to retention rate column\n",
    "def highlight_retention(val):\n",
    "    rate = float(val.rstrip('%'))\n",
    "    if rate >= 70:\n",
    "        return 'background-color: #c6efce; color: #006100'  # Green for high retention\n",
    "    elif rate >= 50:\n",
    "        return 'background-color: #ffeb9c; color: #9c6500'  # Yellow for medium retention\n",
    "    else:\n",
    "        return 'background-color: #ffc7ce; color: #9c0006'  # Red for low retention\n",
    "\n",
    "styled_type_retention = styled_type_retention.applymap(highlight_retention, subset=['Retention Rate'])\n",
    "\n",
    "print(\"\\nCross-Type Customer Loyalty - Data Sources and Formulas:\")\n",
    "print(\"- Data Source: FY1 customer sets by type compared with FY2 customer set\")\n",
    "print(\"- Cross-type customers retention: Percentage of FY1 cross-type customers also present in FY2\")\n",
    "print(\"  Formula: len(fy1_cross_retained) / len(fy1_cross) * 100\")\n",
    "print(\"- POS-only customers retention: Percentage of FY1 POS-only customers also present in FY2\")\n",
    "print(\"  Formula: len(fy1_pos_only_retained) / len(fy1_pos_only) * 100\")\n",
    "print(\"- Jumbo.ae-only customers retention: Percentage of FY1 Jumbo.ae-only customers also present in FY2\")\n",
    "print(\"  Formula: len(fy1_jumbo_only_retained) / len(fy1_jumbo_only) * 100\")\n",
    "print(\"- Color coding: Green ≥70%, Yellow ≥50%, Red <50%\")\n",
    "\n",
    "display(styled_type_retention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2180d4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ANALYSIS 6: Type Switching Behavior ===\n",
    "print(\"\\n6. TYPE SWITCHING BEHAVIOR\")\n",
    "print(\"This analysis shows how customers switch between types (POS and Jumbo.ae) from FY1 to FY2.\")\n",
    "\n",
    "# Analyze all customers present in both years for accuracy\n",
    "common_customers = retained_customers\n",
    "print(f\"Analyzing type switching for all {len(common_customers):,} customers that appear in both years\")\n",
    "\n",
    "if common_customers:\n",
    "    # More efficient approach: pre-compute primary type for all customers at once\n",
    "    print(\"Computing primary types for all customers (this may take a moment for large datasets)...\")\n",
    "    \n",
    "    # Create optimized dataframes with just email and type columns to minimize memory usage\n",
    "    fy1_type_data = fy1_data[['customeremail', 'channel']].copy()\n",
    "    fy2_type_data = fy2_data[['customeremail', 'channel']].copy()\n",
    "    \n",
    "    # Get primary type for each customer in FY1\n",
    "    print(\"Calculating primary types for FY1...\")\n",
    "    fy1_primary_types = fy1_type_data[fy1_type_data['customeremail'].isin(common_customers)] \\\n",
    "                      .groupby('customeremail')['channel'] \\\n",
    "                      .agg(lambda x: x.value_counts().index[0] if len(x.value_counts()) > 0 else None) \\\n",
    "                      .to_dict()\n",
    "    \n",
    "    # Get primary type for each customer in FY2\n",
    "    print(\"Calculating primary types for FY2...\")\n",
    "    fy2_primary_types = fy2_type_data[fy2_type_data['customeremail'].isin(common_customers)] \\\n",
    "                      .groupby('customeremail')['channel'] \\\n",
    "                      .agg(lambda x: x.value_counts().index[0] if len(x.value_counts()) > 0 else None) \\\n",
    "                      .to_dict()\n",
    "    \n",
    "    # Count type switching patterns\n",
    "    print(\"Analyzing type switching patterns...\")\n",
    "    same_type = 0\n",
    "    pos_to_jumbo = 0\n",
    "    jumbo_to_pos = 0\n",
    "    unknown_pattern = 0\n",
    "    \n",
    "    # Get customers with valid type data in both years\n",
    "    valid_customers = [c for c in common_customers if c in fy1_primary_types and c in fy2_primary_types]\n",
    "    print(f\"Found {len(valid_customers):,} customers with valid type data in both years\")\n",
    "    \n",
    "    # Count the different switching patterns\n",
    "    for customer in valid_customers:\n",
    "        fy1_type = fy1_primary_types[customer]\n",
    "        fy2_type = fy2_primary_types[customer]\n",
    "        \n",
    "        if fy1_type == fy2_type:\n",
    "            same_type += 1\n",
    "        elif fy1_type == 'POS' and fy2_type == 'Jumbo.ae':\n",
    "            pos_to_jumbo += 1\n",
    "        elif fy1_type == 'Jumbo.ae' and fy2_type == 'POS':\n",
    "            jumbo_to_pos += 1\n",
    "        else:\n",
    "            # This covers cases with UNKNOWN types or other edge cases\n",
    "            unknown_pattern += 1\n",
    "    \n",
    "    total_tracked = same_type + pos_to_jumbo + jumbo_to_pos + unknown_pattern\n",
    "    \n",
    "    # Further analysis - Break down the \"same type\" category\n",
    "    stayed_pos = 0\n",
    "    stayed_jumbo = 0\n",
    "    \n",
    "    for customer in valid_customers:\n",
    "        fy1_type = fy1_primary_types[customer]\n",
    "        fy2_type = fy2_primary_types[customer]\n",
    "        \n",
    "        if fy1_type == fy2_type == 'POS':\n",
    "            stayed_pos += 1\n",
    "        elif fy1_type == fy2_type == 'Jumbo.ae':\n",
    "            stayed_jumbo += 1\n",
    "    \n",
    "    # Create DataFrame for type switching analysis\n",
    "    switching_df = pd.DataFrame({\n",
    "        'Switching Pattern': [\n",
    "            'Stayed with same type (total)',\n",
    "            '- Stayed with POS',\n",
    "            '- Stayed with Jumbo.ae',\n",
    "            'Switched from POS to Jumbo.ae',\n",
    "            'Switched from Jumbo.ae to POS',\n",
    "            'Other patterns (involving UNKNOWN)'\n",
    "        ],\n",
    "        'Count': [\n",
    "            same_type,\n",
    "            stayed_pos,\n",
    "            stayed_jumbo,\n",
    "            pos_to_jumbo,\n",
    "            jumbo_to_pos,\n",
    "            unknown_pattern\n",
    "        ],\n",
    "        'Percentage': [\n",
    "            f\"{same_type/total_tracked*100:.2f}%\" if total_tracked > 0 else \"N/A\",\n",
    "            f\"{stayed_pos/total_tracked*100:.2f}%\" if total_tracked > 0 else \"N/A\",\n",
    "            f\"{stayed_jumbo/total_tracked*100:.2f}%\" if total_tracked > 0 else \"N/A\",\n",
    "            f\"{pos_to_jumbo/total_tracked*100:.2f}%\" if total_tracked > 0 else \"N/A\",\n",
    "            f\"{jumbo_to_pos/total_tracked*100:.2f}%\" if total_tracked > 0 else \"N/A\",\n",
    "            f\"{unknown_pattern/total_tracked*100:.2f}%\" if total_tracked > 0 else \"N/A\"\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    # Style the type switching table\n",
    "    styled_switching = switching_df.style.set_properties(**{'text-align': 'center'})\n",
    "    styled_switching = styled_switching.set_table_styles([\n",
    "        {'selector': 'th', 'props': [('background-color', '#4472C4'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "        {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "    ])\n",
    "    \n",
    "    print(\"\\nType Switching Behavior for All Retained Customers:\")\n",
    "    print(\"Data Sources and Formulas:\")\n",
    "    print(\"- Data Source: Primary type analysis of retained customers between FY1 and FY2\")\n",
    "    print(\"- Primary type: Most frequent type used by each customer in each year\")\n",
    "    print(\"  Formula: customer_df.groupby('customeremail')['channel'].agg(lambda x: x.value_counts().index[0])\")\n",
    "    print(\"- Same type: Customers whose primary type remained the same from FY1 to FY2\")\n",
    "    print(\"- Stayed with POS/Jumbo.ae: Subset of 'same type' customers by specific type\")\n",
    "    print(\"- Switched from POS to Jumbo.ae: Customers with primary type POS in FY1 and Jumbo.ae in FY2\")\n",
    "    print(\"- Switched from Jumbo.ae to POS: Customers with primary type Jumbo.ae in FY1 and POS in FY2\")\n",
    "    print(\"- Percentage: (Count / Total valid customers with type data) * 100%\")\n",
    "    \n",
    "    display(styled_switching)\n",
    "    \n",
    "    # Additional insights\n",
    "    print(\"\\nType Switching Insights:\")\n",
    "    if pos_to_jumbo > jumbo_to_pos:\n",
    "        print(f\"- More customers are moving from POS to Jumbo.ae ({pos_to_jumbo:,} vs {jumbo_to_pos:,})\")\n",
    "        print(f\"- Net shift towards Jumbo.ae: {pos_to_jumbo - jumbo_to_pos:,} customers ({(pos_to_jumbo - jumbo_to_pos)/total_tracked*100:.2f}% of tracked customers)\")\n",
    "    elif jumbo_to_pos > pos_to_jumbo:\n",
    "        print(f\"- More customers are moving from Jumbo.ae to POS ({jumbo_to_pos:,} vs {pos_to_jumbo:,})\")\n",
    "        print(f\"- Net shift towards POS: {jumbo_to_pos - pos_to_jumbo:,} customers ({(jumbo_to_pos - pos_to_jumbo)/total_tracked*100:.2f}% of tracked customers)\")\n",
    "    else:\n",
    "        print(f\"- Customer movement between types is perfectly balanced ({pos_to_jumbo:,} each way)\")\n",
    "        \n",
    "    print(f\"- Type loyalty is {same_type/total_tracked*100:.2f}%, with {stayed_pos/same_type*100:.2f}% loyal to POS and {stayed_jumbo/same_type*100:.2f}% loyal to Jumbo.ae\")\n",
    "else:\n",
    "    print(\"No common customers found between financial years to analyze switching behavior.\")\n",
    "\n",
    "# === ANALYSIS 7: Comprehensive Summary Table ===\n",
    "print(\"\\n7. COMPREHENSIVE SUMMARY TABLE\")\n",
    "print(\"This table provides a consolidated view of all key customer metrics across both financial years.\")\n",
    "\n",
    "# Create a summary table\n",
    "summary_data = {\n",
    "    'Metric': [\n",
    "        'Total Unique Customers',\n",
    "        'Retained Customers',\n",
    "        'Retention Rate (%)',\n",
    "        'New Customers in FY2',\n",
    "        'Lost Customers from FY1',\n",
    "        'POS-only Customers',\n",
    "        'Jumbo.ae-only Customers',\n",
    "        'Cross-type Customers',\n",
    "        'Customers with Only Returns',\n",
    "        'POS-to-Jumbo.ae Switchers',\n",
    "        'Jumbo.ae-to-POS Switchers'\n",
    "    ],\n",
    "    'FY1 Value': [\n",
    "        f\"{fy1_total_emails:,}\",\n",
    "        'N/A',\n",
    "        'N/A',\n",
    "        'N/A',\n",
    "        'N/A',\n",
    "        f\"{len(fy1_pos_only):,}\",\n",
    "        f\"{len(fy1_jumbo_only):,}\",\n",
    "        f\"{len(fy1_cross):,}\",\n",
    "        f\"{len(fy1_only_returns):,}\",\n",
    "        'N/A',\n",
    "        'N/A'\n",
    "    ],\n",
    "    'FY2 Value': [\n",
    "        f\"{fy2_total_emails:,}\",\n",
    "        f\"{len(retained_customers):,}\",\n",
    "        f\"{len(retained_customers)/len(fy1_unique_customers)*100:.2f}%\" if fy1_unique_customers else 'N/A',\n",
    "        f\"{len(new_customers_in_fy2):,}\",\n",
    "        f\"{len(lost_customers_from_fy1):,}\",\n",
    "        f\"{len(fy2_pos_only):,}\",\n",
    "        f\"{len(fy2_jumbo_only):,}\",\n",
    "        f\"{len(fy2_cross):,}\",\n",
    "        f\"{len(fy2_only_returns):,}\",\n",
    "        f\"{pos_to_jumbo:,}\" if 'pos_to_jumbo' in locals() and isinstance(pos_to_jumbo, int) else 'N/A',\n",
    "        f\"{jumbo_to_pos:,}\" if 'jumbo_to_pos' in locals() and isinstance(jumbo_to_pos, int) else 'N/A'\n",
    "    ],\n",
    "    'Change (%)': [\n",
    "        f\"{change_percent:.2f}%\",\n",
    "        'N/A',\n",
    "        'N/A',\n",
    "        f\"{len(new_customers_in_fy2)/fy2_total_emails*100:.2f}%\" if fy2_total_emails > 0 else 'N/A',\n",
    "        f\"{len(lost_customers_from_fy1)/fy1_total_emails*100:.2f}%\" if fy1_total_emails > 0 else 'N/A',\n",
    "        f\"{(len(fy2_pos_only) - len(fy1_pos_only))/len(fy1_pos_only)*100:.2f}%\" if len(fy1_pos_only) > 0 else 'N/A',\n",
    "        f\"{(len(fy2_jumbo_only) - len(fy1_jumbo_only))/len(fy1_jumbo_only)*100:.2f}%\" if len(fy1_jumbo_only) > 0 else 'N/A',\n",
    "        f\"{(len(fy2_cross) - len(fy1_cross))/len(fy1_cross)*100:.2f}%\" if len(fy1_cross) > 0 else 'N/A',\n",
    "        f\"{(len(fy2_only_returns) - len(fy1_only_returns))/len(fy1_only_returns)*100:.2f}%\" if len(fy1_only_returns) > 0 else 'N/A',\n",
    "        'N/A',\n",
    "        'N/A'\n",
    "    ]\n",
    "}\n",
    "\n",
    "summary_df = pd.DataFrame(summary_data)\n",
    "\n",
    "# Style the summary table\n",
    "styled_summary = summary_df.style.set_properties(**{'text-align': 'center'})\n",
    "styled_summary = styled_summary.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#4472C4'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "    {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "])\n",
    "\n",
    "# Apply conditional formatting to Change column\n",
    "def style_change_column(val):\n",
    "    if val == 'N/A':\n",
    "        return ''\n",
    "    \n",
    "    try:\n",
    "        val_num = float(val.rstrip('%'))\n",
    "        if val_num > 5:\n",
    "            return 'color: green; font-weight: bold'\n",
    "        elif val_num < -5:\n",
    "            return 'color: red; font-weight: bold'\n",
    "        return ''\n",
    "    except:\n",
    "        return ''\n",
    "\n",
    "styled_summary = styled_summary.applymap(style_change_column, subset=['Change (%)'])\n",
    "\n",
    "print(\"\\nComprehensive Summary Table - Data Sources and Formulas:\")\n",
    "print(\"- Data Source: Consolidated metrics from all previous analyses\")\n",
    "print(\"- Total Unique Customers: Count of distinct customers in each financial year\")\n",
    "print(\"- Retained Customers: Intersection of FY1 and FY2 customer sets\")\n",
    "print(\"- Retention Rate: (Retained customers / FY1 customers) * 100%\")\n",
    "print(\"- New Customers in FY2: FY2 customers not present in FY1\")\n",
    "print(\"- Lost Customers from FY1: FY1 customers not present in FY2\")\n",
    "print(\"- POS/Jumbo.ae/Cross-type customers: Counts from respective type analyses\")\n",
    "print(\"- Customers with Only Returns: Derived from order type analysis\")\n",
    "print(\"- Type Switchers: Derived from type switching analysis\")\n",
    "print(\"- Change percentages: ((FY2 value - FY1 value) / FY1 value) * 100%\")\n",
    "\n",
    "display(styled_summary)\n",
    "\n",
    "# === FINAL REPORT AND KEY INSIGHTS ===\n",
    "print(\"\\n===== FINAL REPORT AND KEY INSIGHTS =====\\n\")\n",
    "\n",
    "# Calculate retention rates for different segments\n",
    "overall_retention_rate = len(retained_customers) / fy1_total_emails * 100 if fy1_total_emails > 0 else 0\n",
    "\n",
    "# Create insights DataFrame\n",
    "insights_data = {\n",
    "    'Key Insight': [\n",
    "        f\"Overall customer retention rate: {overall_retention_rate:.2f}%\",\n",
    "        f\"Cross-type customers retention rate: {cross_type_retention_rate:.2f}%\",\n",
    "        f\"POS-only customers retention rate: {pos_only_retention_rate:.2f}%\",\n",
    "        f\"Jumbo.ae-only customers retention rate: {jumbo_only_retention_rate:.2f}%\"\n",
    "    ],\n",
    "    'Interpretation': [\n",
    "        \"Percentage of FY1 customers who remained in FY2\",\n",
    "        \"Shows how loyal multi-type customers are\",\n",
    "        \"Shows loyalty of POS customers\",\n",
    "        \"Shows loyalty of Jumbo.ae-only customers\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "insights_df = pd.DataFrame(insights_data)\n",
    "\n",
    "# Style the insights table\n",
    "styled_insights = insights_df.style.set_properties(**{'text-align': 'left'})\n",
    "styled_insights = styled_insights.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#5B9BD5'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]}\n",
    "])\n",
    "\n",
    "print(\"KEY RETENTION INSIGHTS:\")\n",
    "print(\"Data Sources and Formulas:\")\n",
    "print(\"- Overall retention rate: (Retained customers / Total FY1 customers) * 100%\")\n",
    "print(\"  Formula: len(retained_customers) / fy1_total_emails * 100\")\n",
    "print(\"- Cross-type customers retention: (Retained cross-type / Total FY1 cross-type) * 100%\")\n",
    "print(\"  Formula: len(fy1_cross_retained) / len(fy1_cross) * 100\")\n",
    "print(\"- Type-specific retention rates use the same formula pattern for their respective customer sets\")\n",
    "\n",
    "display(styled_insights)\n",
    "\n",
    "# Customer overlap metrics\n",
    "overlap_data = {\n",
    "    'Metric': [\n",
    "        f\"Total unique customers across both years: {len(fy1_unique_customers.union(fy2_unique_customers)):,}\",\n",
    "        f\"Customers present in both years: {len(retained_customers):,} ({len(retained_customers)/len(fy1_unique_customers)*100:.2f}% of FY1)\",\n",
    "        f\"New customers in FY2: {len(new_customers_in_fy2):,} ({len(new_customers_in_fy2)/len(fy2_unique_customers)*100:.2f}% of FY2)\",\n",
    "        f\"Lost customers from FY1: {len(lost_customers_from_fy1):,} ({len(lost_customers_from_fy1)/len(fy1_unique_customers)*100:.2f}% of FY1)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "overlap_df = pd.DataFrame(overlap_data)\n",
    "\n",
    "# Style the overlap metrics table\n",
    "styled_overlap = overlap_df.style.set_properties(**{'text-align': 'left'})\n",
    "styled_overlap = styled_overlap.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#5B9BD5'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]}\n",
    "])\n",
    "\n",
    "print(\"\\nCUSTOMER OVERLAP METRICS:\")\n",
    "print(\"Data Sources and Formulas:\")\n",
    "print(\"- Total unique customers across both years: Union of FY1 and FY2 customer sets\")\n",
    "print(\"  Formula: len(fy1_unique_customers.union(fy2_unique_customers))\")\n",
    "print(\"- Customers present in both years: Intersection of FY1 and FY2 customer sets\")\n",
    "print(\"  Formula: len(retained_customers)\")\n",
    "print(\"- New customers in FY2: FY2 customers not in FY1\")\n",
    "print(\"  Formula: len(new_customers_in_fy2)\")\n",
    "print(\"- Lost customers from FY1: FY1 customers not in FY2\")\n",
    "print(\"  Formula: len(lost_customers_from_fy1)\")\n",
    "print(\"- Percentages calculated relative to their respective base year totals\")\n",
    "\n",
    "display(styled_overlap)\n",
    "\n",
    "# Type distribution insights\n",
    "fy1_pos_percent = len(fy1_pos_only) / fy1_total_emails * 100 if fy1_total_emails > 0 else 0\n",
    "fy1_jumbo_percent = len(fy1_jumbo_only) / fy1_total_emails * 100 if fy1_total_emails > 0 else 0\n",
    "fy1_cross_percent = len(fy1_cross) / fy1_total_emails * 100 if fy1_total_emails > 0 else 0\n",
    "\n",
    "fy2_pos_percent = len(fy2_pos_only) / fy2_total_emails * 100 if fy2_total_emails > 0 else 0\n",
    "fy2_jumbo_percent = len(fy2_jumbo_only) / fy2_total_emails * 100 if fy2_total_emails > 0 else 0\n",
    "fy2_cross_percent = len(fy2_cross) / fy2_total_emails * 100 if fy2_total_emails > 0 else 0\n",
    "\n",
    "type_insight_data = {\n",
    "    'Type Insight': [\n",
    "        f\"POS-only customers: FY1 {fy1_pos_percent:.2f}% → FY2 {fy2_pos_percent:.2f}% ({fy2_pos_percent-fy1_pos_percent:.2f}% change)\",\n",
    "        f\"Jumbo.ae-only customers: FY1 {fy1_jumbo_percent:.2f}% → FY2 {fy2_jumbo_percent:.2f}% ({fy2_jumbo_percent-fy1_jumbo_percent:.2f}% change)\",\n",
    "        f\"Cross-type customers: FY1 {fy1_cross_percent:.2f}% → FY2 {fy2_cross_percent:.2f}% ({fy2_cross_percent-fy1_cross_percent:.2f}% change)\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "type_insight_df = pd.DataFrame(type_insight_data)\n",
    "\n",
    "# Style the type insights table\n",
    "styled_type_insight = type_insight_df.style.set_properties(**{'text-align': 'left'})\n",
    "styled_type_insight = styled_type_insight.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#5B9BD5'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]}\n",
    "])\n",
    "\n",
    "print(\"\\nTYPE DISTRIBUTION INSIGHTS:\")\n",
    "print(\"Data Sources and Formulas:\")\n",
    "print(\"- POS-only customer percentages: len(fy1_pos_only) / fy1_total_emails * 100 for FY1\")\n",
    "print(\"  and len(fy2_pos_only) / fy2_total_emails * 100 for FY2\")\n",
    "print(\"- Jumbo.ae-only customer percentages: len(fy1_jumbo_only) / fy1_total_emails * 100 for FY1\")\n",
    "print(\"  and len(fy2_jumbo_only) / fy2_total_emails * 100 for FY2\")\n",
    "print(\"- Cross-type customer percentages: len(fy1_cross) / fy1_total_emails * 100 for FY1\")\n",
    "print(\"  and len(fy2_cross) / fy2_total_emails * 100 for FY2\")\n",
    "print(\"- Change calculated as FY2 percentage - FY1 percentage\")\n",
    "\n",
    "display(styled_type_insight)\n",
    "\n",
    "# Final conclusions\n",
    "conclusion_data = {\n",
    "    'Conclusion & Recommendation': [\n",
    "        f\"Retention Analysis: The data shows an overall retention rate of {overall_retention_rate:.2f}%.\",\n",
    "        \"Type Strategy: \" + (\n",
    "            \"Cross-type customers show the highest retention rate, suggesting customers using both POS and Jumbo.ae are most loyal.\" \n",
    "            if cross_type_retention_rate > pos_only_retention_rate and cross_type_retention_rate > jumbo_only_retention_rate\n",
    "            else \"POS-only customers have higher retention than Jumbo.ae-only customers, suggesting focusing on in-store experience.\"\n",
    "            if pos_only_retention_rate > jumbo_only_retention_rate\n",
    "            else \"Jumbo.ae-only customers have higher retention than POS-only customers, suggesting focusing on Jumbo.ae platform experience.\"\n",
    "        ),\n",
    "        f\"Customer Growth: {'Increased' if fy2_total_emails > fy1_total_emails else 'Decreased'} by {abs(change_percent):.2f}% from FY1 to FY2.\",\n",
    "        f\"Type Shift: \" + (\n",
    "            \"More customers are migrating from POS to Jumbo.ae.\"\n",
    "            if 'pos_to_jumbo' in locals() and 'jumbo_to_pos' in locals() and pos_to_jumbo > jumbo_to_pos\n",
    "            else \"More customers are returning to POS from Jumbo.ae.\"\n",
    "            if 'pos_to_jumbo' in locals() and 'jumbo_to_pos' in locals() and jumbo_to_pos > pos_to_jumbo\n",
    "            else \"Similar numbers of customers switching between POS and Jumbo.ae.\"\n",
    "        )\n",
    "    ]\n",
    "}\n",
    "\n",
    "conclusion_df = pd.DataFrame(conclusion_data)\n",
    "\n",
    "# Style the conclusions table\n",
    "styled_conclusion = conclusion_df.style.set_properties(**{'text-align': 'left'})\n",
    "styled_conclusion = styled_conclusion.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#4472C4'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]}\n",
    "])\n",
    "\n",
    "print(\"\\nCONCLUSION AND RECOMMENDATIONS:\")\n",
    "print(\"Data Sources and Formulas for Conclusions:\")\n",
    "print(\"- Retention Analysis: Based on overall retention rate calculated from retained customers\")\n",
    "print(\"- Type Strategy: Based on comparison of retention rates across different type segments (POS-only, Jumbo.ae-only, Cross-type)\")\n",
    "print(\"- Customer Growth: Based on year-over-year change in total unique customers\")\n",
    "print(\"- Type Shift: Based on customer migration patterns between POS and Jumbo.ae\")\n",
    "\n",
    "display(styled_conclusion)\n",
    "\n",
    "print(\"\\nThis analysis provides a comprehensive overview of customer behavior across the two financial years, focusing on retention rates, channel preferences, and buying patterns.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df19645",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === ANALYSIS 8: 2025 Customer Repeat Analysis by 2024 Half-Year ===\n",
    "print(\"\\n8. CUSTOMER REPEAT ANALYSIS FROM 2024 HALF-YEARS\")\n",
    "print(\"This analysis examines customers from 2025 who were also present in the first and second half of 2024.\")\n",
    "\n",
    "# Using already loaded data from fy1_data and fy2_data instead of re-reading Excel files\n",
    "print(\"Using already loaded data from previous cells to perform analysis\")\n",
    "\n",
    "# Extract data from different time periods using the existing dataframes\n",
    "# 1. Extract customers from 2025 files (in FY2 data)\n",
    "print(\"\\nExtracting data from different time periods...\")\n",
    "customers_2025 = set()\n",
    "if 'year' in fy2_data.columns:\n",
    "    # If year information is directly available in the data\n",
    "    for _, row in fy2_data[fy2_data['year'] == 2025].iterrows():\n",
    "        customers_2025.add(str(row['customeremail']).strip().lower())\n",
    "else:\n",
    "    # Otherwise, detect year from file name\n",
    "    for _, row in fy2_data[fy2_data['file_name'].str.contains('25|2025', case=False)].iterrows():\n",
    "        customers_2025.add(str(row['customeremail']).strip().lower())\n",
    "\n",
    "print(f\"Found {len(customers_2025)} unique customers in 2025 files\")\n",
    "\n",
    "# 2. Extract customers from first half of 2024 (Jan-Jun) - could be in both FY1 and FY2\n",
    "first_half_2024 = set()\n",
    "\n",
    "# First half patterns to search for in filenames\n",
    "first_half_patterns = ['jan.*24', 'feb.*24', 'mar.*24', 'apr.*24', 'may.*24', 'jun.*24', \n",
    "                       '24.*jan', '24.*feb', '24.*mar', '24.*apr', '24.*may', '24.*jun']\n",
    "\n",
    "# Check in FY1 data\n",
    "for pattern in first_half_patterns:\n",
    "    mask = fy1_data['file_name'].str.contains(pattern, case=False, regex=True)\n",
    "    for _, row in fy1_data[mask].iterrows():\n",
    "        first_half_2024.add(str(row['customeremail']).strip().lower())\n",
    "\n",
    "# Check in FY2 data\n",
    "for pattern in first_half_patterns:\n",
    "    mask = fy2_data['file_name'].str.contains(pattern, case=False, regex=True)\n",
    "    for _, row in fy2_data[mask].iterrows():\n",
    "        first_half_2024.add(str(row['customeremail']).strip().lower())\n",
    "\n",
    "print(f\"Found {len(first_half_2024)} unique customers in first half of 2024 files\")\n",
    "\n",
    "# 3. Extract customers from second half of 2024 (Jul-Dec) - likely only in FY2\n",
    "second_half_2024 = set()\n",
    "\n",
    "# Second half patterns to search for in filenames\n",
    "second_half_patterns = ['jul.*24', 'aug.*24', 'sep.*24', 'oct.*24', 'nov.*24', 'dec.*24',\n",
    "                        '24.*jul', '24.*aug', '24.*sep', '24.*oct', '24.*nov', '24.*dec']\n",
    "\n",
    "# Check in FY1 data (just in case)\n",
    "for pattern in second_half_patterns:\n",
    "    mask = fy1_data['file_name'].str.contains(pattern, case=False, regex=True)\n",
    "    for _, row in fy1_data[mask].iterrows():\n",
    "        second_half_2024.add(str(row['customeremail']).strip().lower())\n",
    "\n",
    "# Check in FY2 data\n",
    "for pattern in second_half_patterns:\n",
    "    mask = fy2_data['file_name'].str.contains(pattern, case=False, regex=True)\n",
    "    for _, row in fy2_data[mask].iterrows():\n",
    "        second_half_2024.add(str(row['customeremail']).strip().lower())\n",
    "\n",
    "print(f\"Found {len(second_half_2024)} unique customers in second half of 2024 files\")\n",
    "\n",
    "# Find repeated customers\n",
    "print(\"\\nAnalyzing customer overlap between periods...\")\n",
    "repeat_from_first_half = customers_2025.intersection(first_half_2024)\n",
    "repeat_from_second_half = customers_2025.intersection(second_half_2024)\n",
    "repeat_from_both_halves = repeat_from_first_half.intersection(repeat_from_second_half)\n",
    "completely_new = customers_2025 - first_half_2024.union(second_half_2024)\n",
    "\n",
    "# Print detailed metrics for debugging\n",
    "print(f\"Customers present in both 2025 and first half 2024: {len(repeat_from_first_half):,}\")\n",
    "print(f\"Customers present in both 2025 and second half 2024: {len(repeat_from_second_half):,}\")\n",
    "print(f\"Customers present across all periods (2025, H1 2024, H2 2024): {len(repeat_from_both_halves):,}\")\n",
    "print(f\"Completely new customers in 2025 (not in any 2024 period): {len(completely_new):,}\")\n",
    "\n",
    "# Calculate metrics\n",
    "if customers_2025:\n",
    "    repeat_first_half_percent = len(repeat_from_first_half) / len(customers_2025) * 100\n",
    "    repeat_second_half_percent = len(repeat_from_second_half) / len(customers_2025) * 100\n",
    "    repeat_both_halves_percent = len(repeat_from_both_halves) / len(customers_2025) * 100\n",
    "    completely_new_percent = len(completely_new) / len(customers_2025) * 100\n",
    "else:\n",
    "    repeat_first_half_percent = repeat_second_half_percent = repeat_both_halves_percent = completely_new_percent = 0\n",
    "    print(\"WARNING: No customers found in 2025 files\")\n",
    "\n",
    "# Create DataFrame for half-year repeat analysis\n",
    "half_year_df = pd.DataFrame({\n",
    "    'Customer Source': [\n",
    "        'Repeat customers from first half of 2024 (Jan-Jun)',\n",
    "        'Repeat customers from second half of 2024 (Jul-Dec)',\n",
    "        'Repeat customers from both halves of 2024',\n",
    "        'Completely new customers in 2025'\n",
    "    ],\n",
    "    'Count': [\n",
    "        f\"{len(repeat_from_first_half):,}\",\n",
    "        f\"{len(repeat_from_second_half):,}\",\n",
    "        f\"{len(repeat_from_both_halves):,}\",\n",
    "        f\"{len(completely_new):,}\"\n",
    "    ],\n",
    "    'Percentage of 2025 Customers': [\n",
    "        f\"{repeat_first_half_percent:.2f}%\",\n",
    "        f\"{repeat_second_half_percent:.2f}%\",\n",
    "        f\"{repeat_both_halves_percent:.2f}%\",\n",
    "        f\"{completely_new_percent:.2f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Style the half-year analysis table\n",
    "styled_half_year = half_year_df.style.set_properties(**{'text-align': 'center'})\n",
    "styled_half_year = styled_half_year.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#5B9BD5'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "    {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "])\n",
    "\n",
    "print(\"\\nRepeat Customer Analysis by 2024 Half-Year:\")\n",
    "print(\"Data Sources and Formulas:\")\n",
    "print(\"- Data Source: Customer sets from first half 2024, second half 2024, and 2025\")\n",
    "print(\"- First half 2024: Customers from Jan-Jun 2024 files (based on filename patterns)\")\n",
    "print(\"- Second half 2024: Customers from Jul-Dec 2024 files (based on filename patterns)\")\n",
    "print(\"- Repeat from first half: Intersection of 2025 and first half 2024 customers\")\n",
    "print(\"  Formula: customers_2025.intersection(first_half_2024)\")\n",
    "print(\"- Repeat from second half: Intersection of 2025 and second half 2024 customers\")\n",
    "print(\"  Formula: customers_2025.intersection(second_half_2024)\")\n",
    "print(\"- Repeat from both halves: Intersection of 2025, first half, and second half customers\")\n",
    "print(\"  Formula: repeat_from_first_half.intersection(repeat_from_second_half)\")\n",
    "print(\"- Completely new: 2025 customers not found in any 2024 data\")\n",
    "print(\"  Formula: customers_2025 - first_half_2024.union(second_half_2024)\")\n",
    "print(\"- Percentage: (Customer count / Total 2025 customers) * 100%\")\n",
    "\n",
    "display(styled_half_year)\n",
    "\n",
    "# Create a visual comparison of retention from each half-year\n",
    "# Calculate retention rates with safeguards against division by zero\n",
    "if first_half_2024:\n",
    "    first_half_rate = f\"{len(repeat_from_first_half) / len(first_half_2024) * 100:.2f}%\"\n",
    "else:\n",
    "    first_half_rate = 'N/A (no customers in first half 2024)'\n",
    "\n",
    "if second_half_2024:\n",
    "    second_half_rate = f\"{len(repeat_from_second_half) / len(second_half_2024) * 100:.2f}%\"\n",
    "else:\n",
    "    second_half_rate = 'N/A (no customers in second half 2024)'\n",
    "\n",
    "both_halves = first_half_2024.intersection(second_half_2024)\n",
    "if both_halves:\n",
    "    both_halves_rate = f\"{len(repeat_from_both_halves) / len(both_halves) * 100:.2f}%\"\n",
    "else:\n",
    "    both_halves_rate = 'N/A (no customers in both halves)'\n",
    "\n",
    "half_year_comparison = pd.DataFrame({\n",
    "    'Time Period': [\n",
    "        'First Half 2024 → 2025',\n",
    "        'Second Half 2024 → 2025',\n",
    "        'Both Halves → 2025'\n",
    "    ],\n",
    "    'Retention Rate': [\n",
    "        first_half_rate,\n",
    "        second_half_rate,\n",
    "        both_halves_rate\n",
    "    ],\n",
    "    'Numerator/Denominator': [\n",
    "        f\"{len(repeat_from_first_half):,} / {len(first_half_2024):,}\" if first_half_2024 else \"N/A\",\n",
    "        f\"{len(repeat_from_second_half):,} / {len(second_half_2024):,}\" if second_half_2024 else \"N/A\",\n",
    "        f\"{len(repeat_from_both_halves):,} / {len(both_halves):,}\" if both_halves else \"N/A\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Style the half-year comparison table\n",
    "styled_comparison = half_year_comparison.style.set_properties(**{'text-align': 'center'})\n",
    "styled_comparison = styled_comparison.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#4472C4'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "    {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "])\n",
    "\n",
    "print(\"\\nRetention Rate Comparison:\")\n",
    "print(\"This shows what percentage of customers from each 2024 time period returned in 2025\")\n",
    "print(\"Data Sources and Formulas:\")\n",
    "print(\"- First Half 2024 → 2025 Retention Rate: (Customers in both periods / First half 2024 customers) * 100%\")\n",
    "print(\"  Formula: len(repeat_from_first_half) / len(first_half_2024) * 100\")\n",
    "print(\"- Second Half 2024 → 2025 Retention Rate: (Customers in both periods / Second half 2024 customers) * 100%\")\n",
    "print(\"  Formula: len(repeat_from_second_half) / len(second_half_2024) * 100\")\n",
    "print(\"- Both Halves → 2025 Retention Rate: (Customers in all periods / Customers in both halves of 2024) * 100%\")\n",
    "print(\"  Formula: len(repeat_from_both_halves) / len(both_halves) * 100\")\n",
    "print(\"- Numerator/Denominator shows the raw counts used in each calculation\")\n",
    "\n",
    "display(styled_comparison)\n",
    "\n",
    "# Key insights with data validation\n",
    "print(\"\\nKey Insights:\")\n",
    "if not customers_2025:\n",
    "    print(\"- WARNING: No customer data found for 2025. Check file naming patterns and data availability.\")\n",
    "elif len(customers_2025) < 10:\n",
    "    print(f\"- WARNING: Only {len(customers_2025)} customers found in 2025 files, which is suspiciously low.\")\n",
    "    print(\"  Check file naming patterns and email column detection.\")\n",
    "else:\n",
    "    # Normal insights when we have sufficient data\n",
    "    if repeat_first_half_percent > repeat_second_half_percent:\n",
    "        print(f\"- Customers from the first half of 2024 showed stronger repeat purchase behavior ({repeat_first_half_percent:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"- Customers from the second half of 2024 showed stronger repeat purchase behavior ({repeat_second_half_percent:.2f}%)\")\n",
    "    \n",
    "    print(f\"- {repeat_both_halves_percent:.2f}% of 2025 customers were consistent throughout 2024 (both halves)\")\n",
    "    print(f\"- {completely_new_percent:.2f}% of 2025 customers are completely new (not seen in 2024)\")\n",
    "\n",
    "# Calculate full year 2024 to 2025 retention metrics\n",
    "all_2024_customers = first_half_2024.union(second_half_2024)\n",
    "repeating_full_year = customers_2025.intersection(all_2024_customers)\n",
    "full_year_retention_percent = len(repeating_full_year) / len(all_2024_customers) * 100 if all_2024_customers else 0\n",
    "full_year_repeat_percent = len(repeating_full_year) / len(customers_2025) * 100 if customers_2025 else 0\n",
    "\n",
    "# Create a DataFrame for the full-year analysis\n",
    "full_year_df = pd.DataFrame({\n",
    "    'Analysis Type': [\n",
    "        'Full Year 2024 → 2025 Retention',\n",
    "        'Full Year 2024 → 2025 Repeat Rate',\n",
    "        'New in 2025 (not in 2024)',\n",
    "        'In 2024 but not in 2025'\n",
    "    ],\n",
    "    'Customer Count': [\n",
    "        f\"{len(repeating_full_year):,} / {len(all_2024_customers):,}\",\n",
    "        f\"{len(repeating_full_year):,} / {len(customers_2025):,}\",\n",
    "        f\"{len(customers_2025 - all_2024_customers):,}\",\n",
    "        f\"{len(all_2024_customers - customers_2025):,}\"\n",
    "    ],\n",
    "    'Percentage': [\n",
    "        f\"{full_year_retention_percent:.2f}%\",\n",
    "        f\"{full_year_repeat_percent:.2f}%\",\n",
    "        f\"{len(customers_2025 - all_2024_customers) / len(customers_2025) * 100:.2f}%\",\n",
    "        f\"{len(all_2024_customers - customers_2025) / len(all_2024_customers) * 100:.2f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Style the full-year analysis table\n",
    "styled_full_year = full_year_df.style.set_properties(**{'text-align': 'center'})\n",
    "styled_full_year = styled_full_year.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#5B9BD5'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "    {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "])\n",
    "\n",
    "print(\"\\nFULL YEAR 2024 TO 2025 ANALYSIS:\")\n",
    "print(\"This shows the complete year-over-year customer retention metrics\")\n",
    "print(\"Data Sources and Formulas:\")\n",
    "print(\"- Data Source: Combined customer sets from all 2024 files and all 2025 files\")\n",
    "print(\"- Full Year 2024 → 2025 Retention: (Customers in both years / All 2024 customers) * 100%\")\n",
    "print(\"  Formula: len(repeating_full_year) / len(all_2024_customers) * 100\")\n",
    "print(\"- Full Year 2024 → 2025 Repeat Rate: (Customers in both years / All 2025 customers) * 100%\")\n",
    "print(\"  Formula: len(repeating_full_year) / len(customers_2025) * 100\")\n",
    "print(\"- New in 2025: Customers in 2025 not found in any 2024 data\")\n",
    "print(\"  Formula: len(customers_2025 - all_2024_customers) / len(customers_2025) * 100\")\n",
    "print(\"- In 2024 but not in 2025: Customers in 2024 not present in 2025\")\n",
    "print(\"  Formula: len(all_2024_customers - customers_2025) / len(all_2024_customers) * 100\")\n",
    "print(\"- Customer Count column shows the raw counts used in each calculation\")\n",
    "\n",
    "display(styled_full_year)\n",
    "\n",
    "# Add analytical insights\n",
    "print(f\"\\nAdditional Context:\")\n",
    "print(f\"- Total unique customers in all 2024 files: {len(all_2024_customers):,}\")\n",
    "print(f\"- Total unique customers in 2025 files: {len(customers_2025):,}\")\n",
    "print(f\"- Customer overlap between first and second half of 2024: {len(first_half_2024.intersection(second_half_2024)):,} \" +\n",
    "      f\"({len(first_half_2024.intersection(second_half_2024)) / len(all_2024_customers) * 100:.2f}% of all 2024 customers)\" if all_2024_customers else \"- No data available for 2024\")\n",
    "\n",
    "# === ANALYSIS 9: Three-Year Comparison (First 4 Months 2025 vs 2024 vs 2023) ===\n",
    "print(\"\\n9. THREE-YEAR COMPARISON (FIRST 4 MONTHS 2025 vs 2024 vs 2023)\")\n",
    "print(\"This analysis compares the first four months of 2025 (Jan-Apr, including April25 file) with full year data from 2024 and 2023\")\n",
    "\n",
    "# Get customers from first 4 months 2025 (Jan-Apr 2025, including April25 file)\n",
    "first_4_months_2025_customers = set()\n",
    "if 'year' in fy2_data.columns and 'month' in fy2_data.columns:\n",
    "    # If year and month information is directly available in the data\n",
    "    first_4_mask = (fy2_data['year'] == 2025) & (fy2_data['month'].isin([1, 2, 3, 4]))\n",
    "    for _, row in fy2_data[first_4_mask].iterrows():\n",
    "        first_4_months_2025_customers.add(str(row['customeremail']).strip().lower())\n",
    "else:\n",
    "    # Otherwise, detect from file name\n",
    "    first_4_patterns = ['jan.*25', 'feb.*25', 'mar.*25', 'apr.*25', 'april.*25', \n",
    "                       '25.*jan', '25.*feb', '25.*mar', '25.*apr', '25.*april',\n",
    "                       'jan.*2025', 'feb.*2025', 'mar.*2025', 'apr.*2025', 'april.*2025']\n",
    "    for pattern in first_4_patterns:\n",
    "        mask = fy2_data['file_name'].str.contains(pattern, case=False, regex=True)\n",
    "        for _, row in fy2_data[mask].iterrows():\n",
    "            first_4_months_2025_customers.add(str(row['customeremail']).strip().lower())\n",
    "\n",
    "# Also check for April25 file in main q directory if it exists\n",
    "april25_file_path = os.path.join(q_main_path, \"CUSTOMER PROFILE_April25.xlsx\")\n",
    "if os.path.exists(april25_file_path):\n",
    "    april25_df = process_excel_file(april25_file_path)\n",
    "    if april25_df is not None and not april25_df.empty:\n",
    "        for _, row in april25_df.iterrows():\n",
    "            first_4_months_2025_customers.add(str(row['customeremail']).strip().lower())\n",
    "        print(f\"Added {len(april25_df)} records from April25 file\")\n",
    "\n",
    "print(f\"Found {len(first_4_months_2025_customers):,} unique customers in first 4 months of 2025 (Jan-Apr)\")\n",
    "\n",
    "# Get all 2023 customers\n",
    "all_2023_customers = set()\n",
    "for _, row in q_2023_data.iterrows():\n",
    "    all_2023_customers.add(str(row['customeremail']).strip().lower())\n",
    "\n",
    "# Add any 2023 customers from fy1_data (just in case there are any files from 2023 there)\n",
    "if 'year' in fy1_data.columns:\n",
    "    mask_2023 = fy1_data['year'] == 2023\n",
    "    for _, row in fy1_data[mask_2023].iterrows():\n",
    "        all_2023_customers.add(str(row['customeremail']).strip().lower())\n",
    "else:\n",
    "    # Look for files with 2023 in the name\n",
    "    mask_2023 = fy1_data['file_name'].str.contains('23|2023', case=False)\n",
    "    for _, row in fy1_data[mask_2023].iterrows():\n",
    "        all_2023_customers.add(str(row['customeremail']).strip().lower())\n",
    "\n",
    "print(f\"Found {len(all_2023_customers):,} unique customers in 2023\")\n",
    "\n",
    "# Calculate overlaps between the years\n",
    "overlap_2025_4m_2024 = first_4_months_2025_customers.intersection(all_2024_customers)\n",
    "overlap_2025_4m_2023 = first_4_months_2025_customers.intersection(all_2023_customers)\n",
    "overlap_2024_2023 = all_2024_customers.intersection(all_2023_customers)\n",
    "overlap_all_years = first_4_months_2025_customers.intersection(all_2024_customers).intersection(all_2023_customers)\n",
    "\n",
    "# Calculate percentages for the comparative analysis\n",
    "if first_4_months_2025_customers:\n",
    "    first_4m_2025_to_2024_percent = len(overlap_2025_4m_2024) / len(first_4_months_2025_customers) * 100\n",
    "    first_4m_2025_to_2023_percent = len(overlap_2025_4m_2023) / len(first_4_months_2025_customers) * 100\n",
    "    first_4m_2025_new_percent = len(first_4_months_2025_customers - all_2024_customers - all_2023_customers) / len(first_4_months_2025_customers) * 100\n",
    "else:\n",
    "    first_4m_2025_to_2024_percent = first_4m_2025_to_2023_percent = first_4m_2025_new_percent = 0\n",
    "\n",
    "if all_2024_customers:\n",
    "    y2024_to_first_4m_2025_percent = len(overlap_2025_4m_2024) / len(all_2024_customers) * 100\n",
    "    y2024_to_2023_percent = len(overlap_2024_2023) / len(all_2024_customers) * 100\n",
    "else:\n",
    "    y2024_to_first_4m_2025_percent = y2024_to_2023_percent = 0\n",
    "\n",
    "if all_2023_customers:\n",
    "    y2023_to_first_4m_2025_percent = len(overlap_2025_4m_2023) / len(all_2023_customers) * 100\n",
    "    y2023_to_2024_percent = len(overlap_2024_2023) / len(all_2023_customers) * 100\n",
    "else:\n",
    "    y2023_to_first_4m_2025_percent = y2023_to_2024_percent = 0\n",
    "\n",
    "# Create a DataFrame for the three-year comparison\n",
    "three_year_df = pd.DataFrame({\n",
    "    'Comparison': [\n",
    "        'First 4 months 2025 customers also in 2024',\n",
    "        'First 4 months 2025 customers also in 2023',\n",
    "        'First 4 months 2025 customers in both 2024 & 2023',\n",
    "        'First 4 months 2025 customers new (not in 2023/2024)',\n",
    "        '2024 customers also in first 4 months 2025',\n",
    "        '2024 customers also in 2023',\n",
    "        '2023 customers also in first 4 months 2025',\n",
    "        '2023 customers also in 2024',\n",
    "        'Customers present in all three periods'\n",
    "    ],\n",
    "    'Customer Count': [\n",
    "        f\"{len(overlap_2025_4m_2024):,}\",\n",
    "        f\"{len(overlap_2025_4m_2023):,}\",\n",
    "        f\"{len(overlap_all_years):,}\",\n",
    "        f\"{len(first_4_months_2025_customers - all_2024_customers - all_2023_customers):,}\",\n",
    "        f\"{len(overlap_2025_4m_2024):,}\",\n",
    "        f\"{len(overlap_2024_2023):,}\",\n",
    "        f\"{len(overlap_2025_4m_2023):,}\",\n",
    "        f\"{len(overlap_2024_2023):,}\",\n",
    "        f\"{len(overlap_all_years):,}\"\n",
    "    ],\n",
    "    'Percentage': [\n",
    "        f\"{first_4m_2025_to_2024_percent:.2f}% of first 4 months 2025\",\n",
    "        f\"{first_4m_2025_to_2023_percent:.2f}% of first 4 months 2025\",\n",
    "        f\"{len(overlap_all_years) / len(first_4_months_2025_customers) * 100:.2f}% of first 4 months 2025\" if first_4_months_2025_customers else \"0.00%\",\n",
    "        f\"{first_4m_2025_new_percent:.2f}% of first 4 months 2025\",\n",
    "        f\"{y2024_to_first_4m_2025_percent:.2f}% of 2024\",\n",
    "        f\"{y2024_to_2023_percent:.2f}% of 2024\",\n",
    "        f\"{y2023_to_first_4m_2025_percent:.2f}% of 2023\",\n",
    "        f\"{y2023_to_2024_percent:.2f}% of 2023\",\n",
    "        f\"Present in all three periods\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Style the three-year comparison table\n",
    "styled_three_year = three_year_df.style.set_properties(**{'text-align': 'center'})\n",
    "styled_three_year = styled_three_year.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#5B9BD5'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "    {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "])\n",
    "\n",
    "print(\"\\nThree-Year Customer Comparison (First 4 Months 2025 vs 2024 vs 2023):\")\n",
    "print(\"Data Sources and Formulas:\")\n",
    "print(\"- Data Source: Customer sets from first 4 months 2025 (including April25), full year 2024, and full year 2023\")\n",
    "print(\"- First 4 months 2025: Customers from Jan-Apr 2025 files (based on filename patterns) including April25 file\")\n",
    "print(\"- 2024: All unique customers from 2024 files in either financial year\")\n",
    "print(\"- 2023: All unique customers from 2023 files\")\n",
    "print(\"- First 4 months 2025 customers also in 2024: first_4_months_2025_customers.intersection(all_2024_customers)\")\n",
    "print(\"- First 4 months 2025 customers also in 2023: first_4_months_2025_customers.intersection(all_2023_customers)\")\n",
    "print(\"- First 4 months 2025 customers in both 2024 & 2023: first_4_months_2025_customers.intersection(all_2024_customers).intersection(all_2023_customers)\")\n",
    "print(\"- New customers: first_4_months_2025_customers - all_2024_customers - all_2023_customers\")\n",
    "print(\"- Percentages calculated relative to their respective base customer sets\")\n",
    "\n",
    "display(styled_three_year)\n",
    "\n",
    "# Create a visual representation of year-over-year retention trends\n",
    "retention_trend_df = pd.DataFrame({\n",
    "    'Retention Metric': [\n",
    "        'First 4 months 2025 customers retained from 2024',\n",
    "        'First 4 months 2025 customers retained from 2023',\n",
    "        '2024 customers retained from 2023',\n",
    "        'First 4 months 2025 completely new customers'\n",
    "    ],\n",
    "    'Percentage': [\n",
    "        f\"{first_4m_2025_to_2024_percent:.2f}%\",\n",
    "        f\"{first_4m_2025_to_2023_percent:.2f}%\",\n",
    "        f\"{y2024_to_2023_percent:.2f}%\",\n",
    "        f\"{first_4m_2025_new_percent:.2f}%\"\n",
    "    ],\n",
    "    'Count': [\n",
    "        f\"{len(overlap_2025_4m_2024):,} / {len(first_4_months_2025_customers):,}\",\n",
    "        f\"{len(overlap_2025_4m_2023):,} / {len(first_4_months_2025_customers):,}\",\n",
    "        f\"{len(overlap_2024_2023):,} / {len(all_2024_customers):,}\",\n",
    "        f\"{len(first_4_months_2025_customers - all_2024_customers - all_2023_customers):,} / {len(first_4_months_2025_customers):,}\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Style the retention trend table\n",
    "styled_trend = retention_trend_df.style.set_properties(**{'text-align': 'center'})\n",
    "styled_trend = styled_trend.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#4472C4'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "    {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "])\n",
    "\n",
    "print(\"\\nRetention Trend Analysis:\")\n",
    "print(\"Data Sources and Formulas:\")\n",
    "print(\"- First 4 months 2025 customers retained from 2024: (Overlap between first 4 months 2025 and 2024 / Total first 4 months 2025 customers) * 100%\")\n",
    "print(\"  Formula: len(overlap_2025_4m_2024) / len(first_4_months_2025_customers) * 100\")\n",
    "print(\"- First 4 months 2025 customers retained from 2023: (Overlap between first 4 months 2025 and 2023 / Total first 4 months 2025 customers) * 100%\")\n",
    "print(\"  Formula: len(overlap_2025_4m_2023) / len(first_4_months_2025_customers) * 100\")\n",
    "print(\"- 2024 customers retained from 2023: (Overlap between 2024 and 2023 / Total 2024 customers) * 100%\")\n",
    "print(\"  Formula: len(overlap_2024_2023) / len(all_2024_customers) * 100\")\n",
    "print(\"- First 4 months 2025 completely new customers: (New customers in first 4 months 2025 / Total first 4 months 2025 customers) * 100%\")\n",
    "print(\"  Formula: len(first_4_months_2025_customers - all_2024_customers - all_2023_customers) / len(first_4_months_2025_customers) * 100\")\n",
    "print(\"- Count column shows the raw counts (numerator/denominator) used in each calculation\")\n",
    "\n",
    "display(styled_trend)\n",
    "\n",
    "# === ANALYSIS 10: Cross-Type Customer Comparison Across Years ===\n",
    "print(\"\\n10. CROSS-TYPE CUSTOMER COMPARISON ACROSS YEARS\")\n",
    "print(\"This analysis compares cross-type shopping behavior (POS and Jumbo.ae) across 2023, 2024, and first 4 months 2025\")\n",
    "\n",
    "# Function to identify cross-type customers in a dataset\n",
    "def identify_cross_type_customers(df):\n",
    "    pos_customers = set()\n",
    "    jumbo_customers = set()\n",
    "    for _, row in df[df['channel'] == 'POS'].iterrows():\n",
    "        pos_customers.add(str(row['customeremail']).strip().lower())\n",
    "    for _, row in df[df['channel'] == 'Jumbo.ae'].iterrows():\n",
    "        jumbo_customers.add(str(row['customeremail']).strip().lower())\n",
    "    cross_type = pos_customers.intersection(jumbo_customers)\n",
    "    return cross_type, pos_customers, jumbo_customers\n",
    "\n",
    "# Identify cross-type customers in each year/period\n",
    "print(\"\\nAnalyzing cross-type shopping behavior...\")\n",
    "\n",
    "# For 2023\n",
    "cross_2023, pos_2023, jumbo_2023 = identify_cross_type_customers(q_2023_data)\n",
    "print(f\"2023: Found {len(cross_2023):,} cross-type customers out of {len(all_2023_customers):,} total customers\")\n",
    "\n",
    "# For 2024 (combining both halves)\n",
    "cross_2024 = set()\n",
    "pos_2024 = set()\n",
    "jumbo_2024 = set()\n",
    "\n",
    "# First check FY1 data\n",
    "cross_fy1, pos_fy1, jumbo_fy1 = identify_cross_type_customers(fy1_data[fy1_data['file_name'].str.contains('24|2024', case=False)])\n",
    "cross_2024.update(cross_fy1)\n",
    "pos_2024.update(pos_fy1)\n",
    "jumbo_2024.update(jumbo_fy1)\n",
    "\n",
    "# Then check FY2 data\n",
    "cross_fy2, pos_fy2, jumbo_fy2 = identify_cross_type_customers(fy2_data[fy2_data['file_name'].str.contains('24|2024', case=False)])\n",
    "cross_2024.update(cross_fy2)\n",
    "pos_2024.update(pos_fy2)\n",
    "jumbo_2024.update(jumbo_fy2)\n",
    "\n",
    "print(f\"2024: Found {len(cross_2024):,} cross-type customers out of {len(all_2024_customers):,} total customers\")\n",
    "\n",
    "# For first 4 months 2025\n",
    "first_4m_2025_df = fy2_data[fy2_data['file_name'].str.contains('jan.*25|feb.*25|mar.*25|apr.*25|april.*25|25.*jan|25.*feb|25.*mar|25.*apr|25.*april', case=False, regex=True)]\n",
    "cross_first_4m_2025, pos_first_4m_2025, jumbo_first_4m_2025 = identify_cross_type_customers(first_4m_2025_df)\n",
    "print(f\"First 4 months 2025: Found {len(cross_first_4m_2025):,} cross-type customers out of {len(first_4_months_2025_customers):,} total customers\")\n",
    "\n",
    "# Create a DataFrame to compare cross-type behavior\n",
    "cross_type_comparison = pd.DataFrame({\n",
    "    'Time Period': ['2023', '2024', 'First 4 Months 2025'],\n",
    "    'Cross-Type Customers': [\n",
    "        f\"{len(cross_2023):,} ({len(cross_2023)/len(all_2023_customers)*100:.2f}%)\" if all_2023_customers else \"N/A\",\n",
    "        f\"{len(cross_2024):,} ({len(cross_2024)/len(all_2024_customers)*100:.2f}%)\" if all_2024_customers else \"N/A\", \n",
    "        f\"{len(cross_first_4m_2025):,} ({len(cross_first_4m_2025)/len(first_4_months_2025_customers)*100:.2f}%)\" if first_4_months_2025_customers else \"N/A\"\n",
    "    ],\n",
    "    'POS-Only Customers': [\n",
    "        f\"{len(pos_2023 - cross_2023):,} ({len(pos_2023 - cross_2023)/len(all_2023_customers)*100:.2f}%)\" if all_2023_customers else \"N/A\",\n",
    "        f\"{len(pos_2024 - cross_2024):,} ({len(pos_2024 - cross_2024)/len(all_2024_customers)*100:.2f}%)\" if all_2024_customers else \"N/A\",\n",
    "        f\"{len(pos_first_4m_2025 - cross_first_4m_2025):,} ({len(pos_first_4m_2025 - cross_first_4m_2025)/len(first_4_months_2025_customers)*100:.2f}%)\" if first_4_months_2025_customers else \"N/A\"\n",
    "    ],\n",
    "    'Jumbo.ae-Only Customers': [\n",
    "        f\"{len(jumbo_2023 - cross_2023):,} ({len(jumbo_2023 - cross_2023)/len(all_2023_customers)*100:.2f}%)\" if all_2023_customers else \"N/A\",\n",
    "        f\"{len(jumbo_2024 - cross_2024):,} ({len(jumbo_2024 - cross_2024)/len(all_2024_customers)*100:.2f}%)\" if all_2024_customers else \"N/A\",\n",
    "        f\"{len(jumbo_first_4m_2025 - cross_first_4m_2025):,} ({len(jumbo_first_4m_2025 - cross_first_4m_2025)/len(first_4_months_2025_customers)*100:.2f}%)\" if first_4_months_2025_customers else \"N/A\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Style the cross-type comparison table\n",
    "styled_cross_type = cross_type_comparison.style.set_properties(**{'text-align': 'center'})\n",
    "styled_cross_type = styled_cross_type.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#5B9BD5'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "    {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "])\n",
    "\n",
    "print(\"\\nCross-Type Shopping Behavior Comparison:\")\n",
    "print(\"Data Sources and Formulas:\")\n",
    "print(\"- Data Source: Customer type behavior analysis across all three time periods\")\n",
    "print(\"- 2023 data: From q_2023_data dataframe\")\n",
    "print(\"- 2024 data: Combined from fy1_data and fy2_data with '24' or '2024' in filename\")\n",
    "print(\"- First 4 months 2025 data: From fy2_data with Jan/Feb/Mar/Apr 2025 patterns in filename\")\n",
    "print(\"- Cross-Type Customers: Customers who used both POS and Jumbo.ae types\")\n",
    "print(\"  Formula: pos_customers.intersection(jumbo_customers) for each time period\")\n",
    "print(\"- POS-Only Customers: Customers who only used POS type (not cross-type)\")\n",
    "print(\"  Formula: pos_customers - cross_type_customers for each time period\")\n",
    "print(\"- Jumbo.ae-Only Customers: Customers who only used Jumbo.ae type (not cross-type)\")\n",
    "print(\"  Formula: jumbo_customers - cross_type_customers for each time period\")\n",
    "print(\"- Percentages: (Customer count / Total period customers) * 100%\")\n",
    "\n",
    "display(styled_cross_type)\n",
    "\n",
    "# === ANALYSIS 11: Combined 2023+2024 Retention in 2025 Analysis ===\n",
    "print(\"\\n11. COMBINED 2023+2024 RETENTION IN 2025 ANALYSIS\")\n",
    "print(\"This analysis examines customers from 2025 who were retained from both 2024 and 2023\")\n",
    "\n",
    "# Get customers present in both 2023 and 2024\n",
    "customers_2023_2024_combined = all_2023_customers.union(all_2024_customers)\n",
    "customers_both_2023_2024 = all_2023_customers.intersection(all_2024_customers)\n",
    "print(f\"Total unique customers across 2023 and 2024 combined: {len(customers_2023_2024_combined):,}\")\n",
    "print(f\"Customers present in both 2023 and 2024: {len(customers_both_2023_2024):,}\")\n",
    "\n",
    "# Calculate retention rates for full 2025 (using all 2025 customers found)\n",
    "retained_from_combined = customers_2025.intersection(customers_2023_2024_combined)\n",
    "retained_from_both = customers_2025.intersection(customers_both_2023_2024)\n",
    "\n",
    "# Calculate percentages\n",
    "combined_retention_rate = len(retained_from_combined) / len(customers_2023_2024_combined) * 100 if customers_2023_2024_combined else 0\n",
    "both_retention_rate = len(retained_from_both) / len(customers_both_2023_2024) * 100 if customers_both_2023_2024 else 0\n",
    "\n",
    "# For 2025 perspective\n",
    "combined_repeat_rate = len(retained_from_combined) / len(customers_2025) * 100 if customers_2025 else 0\n",
    "both_repeat_rate = len(retained_from_both) / len(customers_2025) * 100 if customers_2025 else 0\n",
    "\n",
    "# Create DataFrame for the combined retention analysis\n",
    "combined_retention_df = pd.DataFrame({\n",
    "    'Customer Group': [\n",
    "        'Customers from either 2023 or 2024 retained in 2025',\n",
    "        'Customers from both 2023 and 2024 retained in 2025',\n",
    "        '2025 customers who were also customers in either 2023 or 2024',\n",
    "        '2025 customers who were also customers in both 2023 and 2024',\n",
    "        '2025 customers who are completely new (not in 2023 or 2024)'\n",
    "    ],\n",
    "    'Customer Count': [\n",
    "        f\"{len(retained_from_combined):,} / {len(customers_2023_2024_combined):,}\",\n",
    "        f\"{len(retained_from_both):,} / {len(customers_both_2023_2024):,}\",\n",
    "        f\"{len(retained_from_combined):,} / {len(customers_2025):,}\",\n",
    "        f\"{len(retained_from_both):,} / {len(customers_2025):,}\",\n",
    "        f\"{len(customers_2025 - customers_2023_2024_combined):,} / {len(customers_2025):,}\"\n",
    "    ],\n",
    "    'Percentage': [\n",
    "        f\"{combined_retention_rate:.2f}%\",\n",
    "        f\"{both_retention_rate:.2f}%\",\n",
    "        f\"{combined_repeat_rate:.2f}%\",\n",
    "        f\"{both_repeat_rate:.2f}%\",\n",
    "        f\"{len(customers_2025 - customers_2023_2024_combined) / len(customers_2025) * 100:.2f}%\"\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Style the combined retention table\n",
    "styled_combined_retention = combined_retention_df.style.set_properties(**{'text-align': 'center'})\n",
    "styled_combined_retention = styled_combined_retention.set_table_styles([\n",
    "    {'selector': 'th', 'props': [('background-color', '#4472C4'), ('color', 'white'), ('font-weight', 'bold'), ('text-align', 'center')]},\n",
    "    {'selector': '.col0', 'props': [('text-align', 'left')]}\n",
    "])\n",
    "\n",
    "print(\"\\nCombined 2023+2024 Retention Analysis:\")\n",
    "print(\"Data Sources and Formulas:\")\n",
    "print(\"- Data Source: Combined customer sets from 2023, 2024, and 2025\")\n",
    "print(\"- Customers from either 2023 or 2024 retained in 2025:\")\n",
    "print(\"  Formula: customers_2025.intersection(customers_2023_2024_combined) / len(customers_2023_2024_combined) * 100\")\n",
    "print(\"- Customers from both 2023 and 2024 retained in 2025:\")\n",
    "print(\"  Formula: customers_2025.intersection(customers_both_2023_2024) / len(customers_both_2023_2024) * 100\")\n",
    "print(\"- 2025 customers who were also customers in either 2023 or 2024:\")\n",
    "print(\"  Formula: len(retained_from_combined) / len(customers_2025) * 100\")\n",
    "print(\"- 2025 customers who were also customers in both 2023 and 2024:\")\n",
    "print(\"  Formula: len(retained_from_both) / len(customers_2025) * 100\")\n",
    "print(\"- 2025 customers who are completely new:\")\n",
    "print(\"  Formula: len(customers_2025 - customers_2023_2024_combined) / len(customers_2025) * 100\")\n",
    "print(\"- Customer Count column shows the raw counts (numerator/denominator) used in each calculation\")\n",
    "\n",
    "display(styled_combined_retention)\n",
    "\n",
    "# Key three-year insights\n",
    "print(\"\\nKey Three-Year Insights:\")\n",
    "print(f\"- Total unique customers across all three periods (First 4 months 2025, 2024, 2023): {len(first_4_months_2025_customers.union(all_2024_customers).union(all_2023_customers)):,}\")\n",
    "print(f\"- Customers present in all three periods: {len(overlap_all_years):,}\")\n",
    "\n",
    "# Insights about cross-type behavior\n",
    "if len(cross_2023) > 0 and len(cross_2024) > 0 and len(cross_first_4m_2025) > 0:\n",
    "    cross_trend = \"increasing\" if (len(cross_2024)/len(all_2024_customers) > len(cross_2023)/len(all_2023_customers) and \n",
    "                                   len(cross_first_4m_2025)/len(first_4_months_2025_customers) > len(cross_2024)/len(all_2024_customers)) else \"decreasing\"\n",
    "    print(f\"- Cross-type shopping behavior (POS + Jumbo.ae) is {cross_trend} over the three-year period\")\n",
    "    \n",
    "    # Calculate retention rate for cross-type customers\n",
    "    cross_2023_retained_in_2025 = cross_2023.intersection(customers_2025)\n",
    "    cross_type_retention = len(cross_2023_retained_in_2025) / len(cross_2023) * 100 if cross_2023 else 0\n",
    "    print(f\"- Cross-type customers from 2023 have a {cross_type_retention:.2f}% retention rate in 2025\")\n",
    "\n",
    "if first_4_months_2025_customers:\n",
    "    if first_4m_2025_to_2024_percent > first_4m_2025_to_2023_percent:\n",
    "        print(f\"- First 4 months 2025 has stronger customer overlap with 2024 ({first_4m_2025_to_2024_percent:.2f}%) than with 2023 ({first_4m_2025_to_2023_percent:.2f}%)\")\n",
    "    else:\n",
    "        print(f\"- First 4 months 2025 has stronger customer overlap with 2023 ({first_4m_2025_to_2023_percent:.2f}%) than with 2024 ({first_4m_2025_to_2024_percent:.2f}%)\")\n",
    "\n",
    "print(f\"- Of all 2025 customers, {both_repeat_rate:.2f}% were loyal customers present in both 2023 and 2024\")\n",
    "print(f\"- {combined_repeat_rate - both_repeat_rate:.2f}% of 2025 customers were present in either 2023 or 2024, but not both years\")\n",
    "\n",
    "# Calculate customer base growth/decline\n",
    "if all_2023_customers and all_2024_customers:\n",
    "    growth_2023_to_2024 = (len(all_2024_customers) - len(all_2023_customers)) / len(all_2023_customers) * 100\n",
    "    print(f\"- Customer base {'grew' if growth_2023_to_2024 >= 0 else 'declined'} by {abs(growth_2023_to_2024):.2f}% from 2023 to 2024\")\n",
    "\n",
    "# Estimate annualized growth for 2025 based on first 4 months\n",
    "if all_2024_customers and first_4_months_2025_customers:\n",
    "    first_4m_2025_annualized = len(first_4_months_2025_customers) * 3  # Approximate full year based on first 4 months (12/4 = 3)\n",
    "    estimated_growth = (first_4m_2025_annualized - len(all_2024_customers)) / len(all_2024_customers) * 100\n",
    "    print(f\"- Based on first 4 months data, 2025 customer base is projected to {'grow' if estimated_growth >= 0 else 'decline'} by approximately {abs(estimated_growth):.2f}% compared to 2024\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
