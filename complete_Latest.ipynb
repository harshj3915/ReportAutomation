{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e3797bdb",
   "metadata": {},
   "source": [
    "# Day-wise Invoice Sum Report for Multiple Sheets\n",
    "This notebook reads three Excel sheets, filters out unwanted rows, groups by day number, and writes the results to a new Excel file for easy analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d681eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get necessary imports\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font, PatternFill, Border, Side, Alignment, numbers\n",
    "from openpyxl.utils import get_column_letter\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "from copy import copy  # For copying Excel cell styles\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "791d1d6d",
   "metadata": {},
   "source": [
    "## Define the sheets and paths to process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c784c797",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated Path Configuration\n",
    "import os\n",
    "import glob\n",
    "from datetime import datetime, timedelta\n",
    "import calendar\n",
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "def get_month_year_combinations(latest_month_year):\n",
    "    \"\"\"\n",
    "    Get the latest month, last month, and last year combinations\n",
    "    \"\"\"\n",
    "    # Parse the latest month-year\n",
    "    month_name, year = latest_month_year.split('-')\n",
    "    year = int(year)\n",
    "    month_num = list(calendar.month_name).index(month_name)\n",
    "    \n",
    "    # Calculate last month\n",
    "    if month_num == 1:  # January\n",
    "        last_month_num = 12\n",
    "        last_month_year_num = year - 1\n",
    "    else:\n",
    "        last_month_num = month_num - 1\n",
    "        last_month_year_num = year\n",
    "    \n",
    "    # Calculate last year same month\n",
    "    last_year_month_num = month_num\n",
    "    last_year_year_num = year - 1\n",
    "    \n",
    "    # Convert back to names\n",
    "    last_month_name = calendar.month_name[last_month_num]\n",
    "    last_year_month_name = calendar.month_name[last_year_month_num]\n",
    "    \n",
    "    return {\n",
    "        'latest': {'month': month_name, 'year': year, 'folder': f\"{month_name}-{year}\"},\n",
    "        'last_month': {'month': last_month_name, 'year': last_month_year_num, 'folder': f\"{last_month_name}-{last_month_year_num}\"},\n",
    "        'last_year': {'month': last_year_month_name, 'year': last_year_year_num, 'folder': f\"{last_year_month_name}-{last_year_year_num}\"}\n",
    "    }\n",
    "\n",
    "def find_file_by_keyword(folder_path, keyword):\n",
    "    \"\"\"\n",
    "    Find a file in the folder that contains the keyword in its name\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        return None\n",
    "    \n",
    "    files = os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        if keyword.lower() in file.lower() and file.endswith('.xlsx'):\n",
    "            return os.path.join(folder_path, file)\n",
    "    return None\n",
    "\n",
    "def get_sheet_name_with_keyword(file_path, keyword):\n",
    "    \"\"\"\n",
    "    Get the sheet name that contains the keyword\n",
    "    \"\"\"\n",
    "    try:\n",
    "        xl = pd.ExcelFile(file_path)\n",
    "        for sheet_name in xl.sheet_names:\n",
    "            if keyword.lower() in sheet_name.lower():\n",
    "                return sheet_name\n",
    "        # If no sheet with keyword found, return the first sheet\n",
    "        return xl.sheet_names[0] if xl.sheet_names else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def setup_automated_paths(latest_month_year, dsr_folder_path=None):\n",
    "    \"\"\"\n",
    "    Setup all paths automatically based on the latest month-year input\n",
    "    \n",
    "    Parameters:\n",
    "    latest_month_year: str - Format: \"June-2025\"\n",
    "    dsr_folder_path: str - Full path to DSR folder (if None, uses default)\n",
    "    \n",
    "    Returns:\n",
    "    dict containing all the required paths and configurations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get month-year combinations\n",
    "    dates = get_month_year_combinations(latest_month_year)\n",
    "    \n",
    "    # Base DSR folder path\n",
    "    if dsr_folder_path:\n",
    "        dsr_path = dsr_folder_path\n",
    "    else:\n",
    "        dsr_path = os.path.join(os.getcwd(), \"test\", \"DSR\")\n",
    "    \n",
    "    # Prepare results\n",
    "    sheet_info = []\n",
    "    target_info = {}\n",
    "    session_info = {}\n",
    "    \n",
    "    # Process each period (last_month, last_year, latest)\n",
    "    periods = ['last_month', 'last_year', 'latest']\n",
    "    display_names = [\n",
    "        f\"{dates['last_month']['month']} {dates['last_month']['year'] % 100}\",  # May 25\n",
    "        f\"{dates['last_year']['month']} {dates['last_year']['year'] % 100}\",   # June 24\n",
    "        f\"{dates['latest']['month']} {dates['latest']['year'] % 100}\"          # June 25\n",
    "    ]\n",
    "    \n",
    "    for i, period in enumerate(periods):\n",
    "        period_data = dates[period]\n",
    "        folder_path = os.path.join(dsr_path, period_data['folder'])\n",
    "        \n",
    "        # Find invoice file\n",
    "        invoice_file = find_file_by_keyword(folder_path, 'invoice')\n",
    "        if invoice_file:\n",
    "            # Get the first sheet (since invoice files have only one sheet)\n",
    "            try:\n",
    "                xl = pd.ExcelFile(invoice_file)\n",
    "                sheet_name = xl.sheet_names[0] if xl.sheet_names else 'Sheet1'\n",
    "            except:\n",
    "                sheet_name = 'Sheet1'\n",
    "            \n",
    "            # Use absolute path\n",
    "            sheet_info.append((invoice_file, sheet_name, display_names[i]))\n",
    "    \n",
    "    # Setup target information (using latest month)\n",
    "    latest_folder = os.path.join(dsr_path, dates['latest']['folder'])\n",
    "    target_file = find_file_by_keyword(latest_folder, 'target')\n",
    "    if target_file:\n",
    "        target_sheet = get_sheet_name_with_keyword(target_file, 'target')\n",
    "        if not target_sheet:\n",
    "            target_sheet = 'Target'  # Default if not found\n",
    "        \n",
    "        target_info = {\n",
    "            'path': target_file,\n",
    "            'sheet': target_sheet\n",
    "        }\n",
    "    \n",
    "    # Setup session information (using latest month)\n",
    "    traffic_file = find_file_by_keyword(latest_folder, 'traffic')\n",
    "    if traffic_file:\n",
    "        download_sheet = get_sheet_name_with_keyword(traffic_file, 'download')\n",
    "        if not download_sheet:\n",
    "            # If no download sheet found, get the first sheet\n",
    "            try:\n",
    "                xl = pd.ExcelFile(traffic_file)\n",
    "                download_sheet = xl.sheet_names[0] if xl.sheet_names else 'Sheet1'\n",
    "            except:\n",
    "                download_sheet = 'Sheet1'\n",
    "        \n",
    "        session_info = {\n",
    "            'path': traffic_file,\n",
    "            'sheet': download_sheet\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'sheet_info': sheet_info,\n",
    "        'target_info': target_info,\n",
    "        'session_info': session_info,\n",
    "        'dates': dates\n",
    "    }\n",
    "\n",
    "# Define target Excel file \n",
    "output_path = 'invoice_day_channel_report_compatible.xlsx'\n",
    "\n",
    "# AUTOMATED PATH CONFIGURATION\n",
    "# Get user input for latest month-year and DSR path\n",
    "latest_month_year = input(\"Enter the latest month-year (e.g., 'June-2025'): \").strip()\n",
    "# Load configuration from config.json\n",
    "try:\n",
    "    with open('config.json', 'r') as f:\n",
    "        config_data = json.load(f)\n",
    "    dsr_folder_path = config_data['paths']['dsr_folder_path']\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading config.json: {e}\")\n",
    "    print(\"Using default DSR folder path...\")\n",
    "    dsr_folder_path = \"C:\\\\Users\\\\91843\\\\Documents\\\\VsCode Codes\\\\ReportAutomation\\\\test\\\\DSR\"\n",
    "\n",
    "# Setup all paths automatically\n",
    "try:\n",
    "    config = setup_automated_paths(latest_month_year, dsr_folder_path)\n",
    "    \n",
    "    # Extract configuration\n",
    "    sheet_info = config['sheet_info']\n",
    "    target_config = config['target_info']\n",
    "    session_config = config['session_info']\n",
    "    \n",
    "    print(f\"\\n✅ Configuration successful!\")\n",
    "    if dsr_folder_path:\n",
    "        print(f\"📁 Using DSR folder: {dsr_folder_path}\")\n",
    "    print(f\"📁 Found {len(sheet_info)} invoice files:\")\n",
    "    for i, (path, sheet, display) in enumerate(sheet_info):\n",
    "        print(f\"   {i+1}. {display}: {path} -> {sheet}\")\n",
    "    \n",
    "    if target_config:\n",
    "        print(f\"🎯 Target file: {target_config['path']} -> {target_config['sheet']}\")\n",
    "    else:\n",
    "        print(\"⚠️  No target file found - using fallback\")\n",
    "    \n",
    "    if session_config:\n",
    "        print(f\"📊 Session file: {session_config['path']} -> {session_config['sheet']}\")\n",
    "    else:\n",
    "        print(\"⚠️  No session file found - using fallback\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in automated setup: {e}\")\n",
    "    print(\"🔄 Falling back to manual configuration...\")\n",
    "    \n",
    "    # Fallback to manual configuration\n",
    "    sheet_info = [\n",
    "        ('test2/may25-final.xlsx', 'Sheet1', 'May 25'),   # Last month raw sheet\n",
    "        ('test2/June24_Invoice.xlsx', 'Raw data June 24', 'June 24'),        # Last year raw sheet\n",
    "        ('test2/June25.xlsx', 'Sheet1', 'June 25')                # Latest month raw sheet\n",
    "    ]\n",
    "    target_config = {'path': 'test2/Target_June_25.xlsx', 'sheet': 'Target-June25'}\n",
    "    session_config = {'path': 'test2/June_2025_Daily traffic.xlsx', 'sheet': 'download - 2025-01-08T160122.10'}\n",
    "\n",
    "# Constants for easier sheet reference - DO NOT USE THESE DIRECTLY\n",
    "# Instead, use the index to get the specific dataframe\n",
    "LAST_MONTH_INDEX = 0  # Last month index\n",
    "LAST_YEAR_INDEX = 1   # Last year index  \n",
    "LATEST_MONTH_INDEX = 2      # Latest month index\n",
    "\n",
    "# Display names for column headers\n",
    "LAST_MONTH_DISPLAY = sheet_info[LAST_MONTH_INDEX][2] if len(sheet_info) > LAST_MONTH_INDEX else \"Last Month\"\n",
    "LAST_YEAR_DISPLAY = sheet_info[LAST_YEAR_INDEX][2] if len(sheet_info) > LAST_YEAR_INDEX else \"Last Year\"\n",
    "LATEST_DISPLAY = sheet_info[LATEST_MONTH_INDEX][2] if len(sheet_info) > LATEST_MONTH_INDEX else \"Latest\"\n",
    "\n",
    "# Target sheet information  \n",
    "TARGET_PATH = target_config['path'] if target_config else 'test2/Target_June_25.xlsx'\n",
    "TARGET_SHEET = target_config['sheet'] if target_config else 'Target-June25'\n",
    "\n",
    "# Read the session data with specific columns\n",
    "important_columns = [\n",
    "    'Day',\n",
    "    'Channel', \n",
    "    'Sessions',\n",
    "    'Purchases',\n",
    "    'Purchase revenue',\n",
    "    'CG',\n",
    "    'Category'\n",
    "]\n",
    "\n",
    "# Read the session data\n",
    "session_file_path = session_config['path'] if session_config else \"test2/June_2025_Daily traffic.xlsx\"\n",
    "session_sheet_name = session_config['sheet'] if session_config else \"download - 2025-01-08T160122.10\"\n",
    "\n",
    "try:\n",
    "    session_df = pd.read_excel(session_file_path, sheet_name=session_sheet_name)\n",
    "    print(f\"📈 Session data loaded successfully from: {session_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Error loading session data: {e}\")\n",
    "    print(\"Please check the file path and sheet name manually.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f47338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target Excel file \n",
    "output_path = 'invoice_day_channel_report_compatible.xlsx'\n",
    "\n",
    "# AUTOMATED PATH CONFIGURATION\n",
    "# Get user input for latest month-year\n",
    "latest_month_year = latest_month_year.strip()\n",
    "\n",
    "# Setup all paths automatically\n",
    "try:\n",
    "    config = setup_automated_paths(latest_month_year,dsr_folder_path)\n",
    "\n",
    "    print( config)\n",
    "    \n",
    "    # Extract configuration\n",
    "    sheet_info = config['sheet_info']\n",
    "    target_config = config['target_info']\n",
    "    session_config = config['session_info']\n",
    "    \n",
    "    print(f\"\\n✅ Configuration successful!\")\n",
    "    print(f\"📁 Found {len(sheet_info)} invoice files:\")\n",
    "    for i, (path, sheet, display) in enumerate(sheet_info):\n",
    "        print(f\"   {i+1}. {display}: {path} -> {sheet}\")\n",
    "    \n",
    "    if target_config:\n",
    "        print(f\"🎯 Target file: {target_config['path']} -> {target_config['sheet']}\")\n",
    "    else:\n",
    "        print(\"⚠️  No target file found - using fallback\")\n",
    "    \n",
    "    if session_config:\n",
    "        print(f\"📊 Session file: {session_config['path']} -> {session_config['sheet']}\")\n",
    "    else:\n",
    "        print(\"⚠️  No session file found - using fallback\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in automated setup: {e}\")\n",
    "    print(\"🔄 Falling back to manual configuration...\")\n",
    "    \n",
    "    # Fallback to manual configuration\n",
    "    sheet_info = [\n",
    "        ('test2/may25-final.xlsx', 'Sheet1', 'May 25'),   # Last month raw sheet\n",
    "        ('test2/June24_Invoice.xlsx', 'Raw data June 24', 'June 24'),        # Last year raw sheet\n",
    "        ('test2/June25.xlsx', 'Sheet1', 'June 25')                # Latest month raw sheet\n",
    "    ]\n",
    "    target_config = {'path': 'test2/Target_June_25.xlsx', 'sheet': 'Target-June25'}\n",
    "    session_config = {'path': 'test2/June_2025_Daily traffic.xlsx', 'sheet': 'download - 2025-01-08T160122.10'}\n",
    "\n",
    "# Constants for easier sheet reference - DO NOT USE THESE DIRECTLY\n",
    "# Instead, use the index to get the specific dataframe\n",
    "LAST_MONTH_INDEX = 0  # Last month index\n",
    "LAST_YEAR_INDEX = 1   # Last year index  \n",
    "LATEST_MONTH_INDEX = 2      # Latest month index\n",
    "\n",
    "# Display names for column headers\n",
    "LAST_MONTH_DISPLAY = sheet_info[LAST_MONTH_INDEX][2] if len(sheet_info) > LAST_MONTH_INDEX else \"Last Month\"\n",
    "LAST_YEAR_DISPLAY = sheet_info[LAST_YEAR_INDEX][2] if len(sheet_info) > LAST_YEAR_INDEX else \"Last Year\"\n",
    "LATEST_DISPLAY = sheet_info[LATEST_MONTH_INDEX][2] if len(sheet_info) > LATEST_MONTH_INDEX else \"Latest\"\n",
    "\n",
    "# Target sheet information  \n",
    "TARGET_PATH = target_config['path'] if target_config else 'test2/Target_June_25.xlsx'\n",
    "TARGET_SHEET = target_config['sheet'] if target_config else 'Target-June25'\n",
    "\n",
    "# Read the session data with specific columns\n",
    "important_columns = [\n",
    "    'Day',\n",
    "    'Channel', \n",
    "    'Sessions',\n",
    "    'Purchases',\n",
    "    'Purchase revenue',\n",
    "    'CG',\n",
    "    'Category'\n",
    "]\n",
    "\n",
    "# Read the session data\n",
    "session_file_path = session_config['path'] if session_config else \"test2/June_2025_Daily traffic.xlsx\"\n",
    "session_sheet_name = session_config['sheet'] if session_config else \"download - 2025-01-08T160122.10\"\n",
    "\n",
    "try:\n",
    "    session_df = pd.read_excel(session_file_path, sheet_name=session_sheet_name)\n",
    "    print(f\"📈 Session data loaded successfully from: {session_file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"⚠️  Error loading session data: {e}\")\n",
    "    print(\"Please check the file path and sheet name manually.\")\n",
    "\n",
    "# Verify the configuration setup\n",
    "print(\"🔧 Current Configuration:\")\n",
    "print(f\"📁 DSR Folder: {dsr_folder_path}\")\n",
    "print(f\"📅 Latest Month-Year: {latest_month_year}\")\n",
    "\n",
    "# Verify the paths are correctly set\n",
    "if config:\n",
    "    print(f\"\\n📊 Sheet Information:\")\n",
    "    for i, (path, sheet, display) in enumerate(sheet_info):\n",
    "        print(f\"   {i+1}. {display}: {os.path.basename(path)} -> {sheet}\")\n",
    "        # Verify file exists\n",
    "        if os.path.exists(path):\n",
    "            print(f\"      ✅ File exists: {path}\")\n",
    "        else:\n",
    "            print(f\"      ❌ File not found: {path}\")\n",
    "    \n",
    "    print(f\"\\n🎯 Target Configuration:\")\n",
    "    if target_config:\n",
    "        print(f\"   Path: {target_config['path']}\")\n",
    "        print(f\"   Sheet: {target_config['sheet']}\")\n",
    "        if os.path.exists(target_config['path']):\n",
    "            print(f\"   ✅ Target file exists\")\n",
    "        else:\n",
    "            print(f\"   ❌ Target file not found\")\n",
    "    \n",
    "    print(f\"\\n📈 Session Configuration:\")\n",
    "    if session_config:\n",
    "        print(f\"   Path: {session_config['path']}\")\n",
    "        print(f\"   Sheet: {session_config['sheet']}\")\n",
    "        if os.path.exists(session_config['path']):\n",
    "            print(f\"   ✅ Session file exists\")\n",
    "        else:\n",
    "            print(f\"   ❌ Session file not found\")\n",
    "\n",
    "# Print the final paths that will be used\n",
    "print(f\"\\n🔗 Final Paths to be Used:\")\n",
    "print(f\"   TARGET_PATH: {TARGET_PATH}\")\n",
    "print(f\"   TARGET_SHEET: {TARGET_SHEET}\")\n",
    "print(f\"   Session Path: {session_file_path}\")\n",
    "print(f\"   Session Sheet: {session_sheet_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494c3935",
   "metadata": {},
   "source": [
    "## Collect day-wise sums for each sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a41991",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect day-wise and TYPE-wise sums for each sheet\n",
    "results = []\n",
    "type_results = []\n",
    "dfs = []  # Store the processed dataframes for each sheet\n",
    "\n",
    "# First, process each sheet and store the dataframe, day sum, and type sum\n",
    "for idx, (path, sheet, display_name) in enumerate(sheet_info):\n",
    "    df = pd.read_excel(path, sheet_name=sheet)\n",
    "    filtered_df = df[~df['idg'].isin(['FOC', 'Remove', 'WRT'])].copy()\n",
    "    filtered_df['InvoiceDay'] = pd.to_datetime(filtered_df['InvoiceDate'], dayfirst=True, errors='coerce').dt.day\n",
    "    \n",
    "    # Map CC to Jumbo.ae in the TYPE column\n",
    "    filtered_df['TYPE'] = filtered_df['TYPE'].replace('CC', 'Jumbo.ae')\n",
    "    \n",
    "    # Day-wise sum\n",
    "    invoice_day_sum = filtered_df.groupby('InvoiceDay')['Amount Invoiced W.O. VAT'].sum()\n",
    "    results.append((idx, invoice_day_sum))  # Store the index instead of sheet name\n",
    "    \n",
    "    # TYPE-wise sum for Jumbo.ae and EA\n",
    "    filtered_type = filtered_df[filtered_df['TYPE'].isin(['Jumbo.ae', 'EA'])]\n",
    "    sum_by_day_type = filtered_type.groupby(['InvoiceDay', 'TYPE'])['Amount Invoiced W.O. VAT'].sum().unstack(fill_value=0)\n",
    "    type_results.append((idx, sum_by_day_type))  # Store the index instead of sheet name\n",
    "    \n",
    "    # Store the processed dataframe\n",
    "    dfs.append(filtered_df)\n",
    "\n",
    "type_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80c40a15",
   "metadata": {},
   "source": [
    "## Combine results into a single DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cccb38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get all days\n",
    "all_days = set()\n",
    "for _, s in results:\n",
    "    all_days.update(s.index)\n",
    "all_days = sorted(all_days)\n",
    "\n",
    "# Convert results to a DataFrame using sheet indices\n",
    "output = pd.DataFrame({'Day': all_days})\n",
    "for idx, s in results:\n",
    "    sheet_display = sheet_info[idx][2]  # Get display name from sheet_info\n",
    "    output[sheet_display] = output['Day'].map(s)  # Use display name as column name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0946bd4",
   "metadata": {},
   "source": [
    "## Sum the 'Target' column by day number from the 'Date' column in the target sheet"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e867bf59",
   "metadata": {},
   "source": [
    "## Calculate Percentage Differences\n",
    "Add comparison columns for each channel:\n",
    "- 'v/s Last Year': Percentage difference between first sheet (Raw data May 24) and latest sheet (Sheet1)\n",
    "- 'v/s Last Month': Percentage difference between middle sheet (Raw data April 25) and latest sheet (Sheet1)\n",
    "- 'v/s Target': Percentage difference between Target value and latest sheet (Sheet1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308029a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target sums by day and channel using constants\n",
    "target_df = pd.read_excel(TARGET_PATH, sheet_name=TARGET_SHEET)\n",
    "target_sums = target_df.groupby(['Date', 'Channel'])['Target'].sum().unstack(fill_value=0).round(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98dd9e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define channels and prepare data for final output (changed order to Jumbo.ae, EA, Total)\n",
    "channels = ['Jumbo.ae', 'EA', 'Total']\n",
    "# Use display names for column headers, but keep original indices for data processing\n",
    "display_names = [display_name for _, _, display_name in sheet_info]\n",
    "subcolumns = display_names[:2] + ['Target'] + [display_names[2]] + ['v/s Target', 'v/s Last Year', 'v/s Last Month']\n",
    "\n",
    "# Create the MultiIndex\n",
    "arrays = [[], []]\n",
    "for channel in channels:\n",
    "    for subcol in subcolumns:\n",
    "        arrays[0].append(channel)\n",
    "        arrays[1].append(subcol)\n",
    "\n",
    "multiindex = pd.MultiIndex.from_arrays(arrays, names=['Channel', 'Type'])\n",
    "\n",
    "# Process data by channel\n",
    "multiindex_data = {}\n",
    "for channel in channels:\n",
    "    channel_data = {}\n",
    "    \n",
    "    # Process the raw data using indices for data access\n",
    "    for idx, (sheet_idx, df) in enumerate(type_results):\n",
    "        if channel == 'Total':\n",
    "            channel_data[sheet_idx] = df.sum(axis=1)\n",
    "        else:\n",
    "            channel_data[sheet_idx] = df[channel]\n",
    "\n",
    "    # Add target data\n",
    "    if channel == 'Total':\n",
    "        channel_data['Target'] = target_sums.sum(axis=1)\n",
    "    else:\n",
    "        channel_data['Target'] = target_sums[channel]\n",
    "\n",
    "    # Calculate percentage differences using indices\n",
    "    vs_last_year = []\n",
    "    for day in all_days:\n",
    "        latest_sheet_value = channel_data[LATEST_MONTH_INDEX].get(day, 0)\n",
    "        first_sheet_value = channel_data[LAST_YEAR_INDEX].get(day, 0)\n",
    "        \n",
    "        if first_sheet_value == 0:\n",
    "            if latest_sheet_value == 0:\n",
    "                pct_diff = 0\n",
    "            else:\n",
    "                pct_diff = float('inf')\n",
    "        else:\n",
    "            pct_diff = ((latest_sheet_value - first_sheet_value) / first_sheet_value) * 100\n",
    "            pct_diff = int(round(pct_diff))\n",
    "        \n",
    "        vs_last_year.append(pct_diff)\n",
    "    \n",
    "    vs_last_month = []\n",
    "    for day in all_days:\n",
    "        latest_sheet_value = channel_data[LATEST_MONTH_INDEX].get(day, 0)\n",
    "        middle_sheet_value = channel_data[LAST_MONTH_INDEX].get(day, 0)\n",
    "        \n",
    "        if middle_sheet_value == 0:\n",
    "            if latest_sheet_value == 0:\n",
    "                pct_diff = 0\n",
    "            else:\n",
    "                pct_diff = float('inf')\n",
    "        else:\n",
    "            pct_diff = ((latest_sheet_value - middle_sheet_value) / middle_sheet_value) * 100\n",
    "            pct_diff = int(round(pct_diff))\n",
    "        \n",
    "        vs_last_month.append(pct_diff)\n",
    "    \n",
    "    vs_target = []\n",
    "    for day in all_days:\n",
    "        latest_sheet_value = channel_data[LATEST_MONTH_INDEX].get(day, 0)\n",
    "        target_value = channel_data['Target'].get(day, 0)\n",
    "        \n",
    "        if target_value == 0:\n",
    "            if latest_sheet_value == 0:\n",
    "                pct_diff = 0\n",
    "            else:\n",
    "                pct_diff = float('inf')\n",
    "        else:\n",
    "            pct_diff = ((latest_sheet_value ) / target_value) * 100\n",
    "            pct_diff = int(round(pct_diff))\n",
    "        \n",
    "        vs_target.append(pct_diff)\n",
    "    \n",
    "    # Store all calculated columns\n",
    "    channel_data['v/s Last Year'] = vs_last_year\n",
    "    channel_data['v/s Last Month'] = vs_last_month\n",
    "    channel_data['v/s Target'] = vs_target\n",
    "    multiindex_data[channel] = channel_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0fce0df",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for DataFrame\n",
    "all_data = []\n",
    "\n",
    "# Create mapping from display names to sheet indices for data access\n",
    "display_to_idx = {\n",
    "    LAST_MONTH_DISPLAY: LAST_MONTH_INDEX,\n",
    "    LAST_YEAR_DISPLAY: LAST_YEAR_INDEX,\n",
    "    LATEST_DISPLAY: LATEST_MONTH_INDEX\n",
    "}\n",
    "\n",
    "for day in all_days:\n",
    "    row = []\n",
    "    for channel in channels:\n",
    "        for subcol in subcolumns:\n",
    "            if subcol in ['v/s Target', 'v/s Last Year', 'v/s Last Month']:\n",
    "                # Get the index of this day in the list\n",
    "                day_index = all_days.index(day)\n",
    "                row.append(multiindex_data[channel][subcol][day_index])\n",
    "            elif subcol == 'Target':\n",
    "                # Target data remains the same\n",
    "                row.append(multiindex_data[channel]['Target'].get(day, 0))\n",
    "            else:\n",
    "                # Map display name to sheet index for data access\n",
    "                sheet_idx = display_to_idx.get(subcol)\n",
    "                if sheet_idx is not None:\n",
    "                    row.append(multiindex_data[channel][sheet_idx].get(day, 0))\n",
    "                else:\n",
    "                    row.append(0)  # Default if mapping not found\n",
    "    all_data.append(row)\n",
    "\n",
    "# Create final DataFrame\n",
    "final_output = pd.DataFrame(all_data, columns=multiindex)\n",
    "final_output.insert(0, 'Day', all_days)\n",
    "\n",
    "# Add day names based on the first day of the month provided by user\n",
    "# We'll add this in Excel formatting since we need the user input for first day of month\n",
    "\n",
    "# Save initial data to Excel\n",
    "final_output.to_excel(output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4d04a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import calendar\n",
    "\n",
    "def get_first_day_of_month(month_year):\n",
    "    \"\"\"\n",
    "    Determine the first day of the month given a month-year string (e.g., 'June-2025')\n",
    "    Returns the day name in lowercase (e.g., 'monday', 'tuesday', etc.)\n",
    "    \"\"\"\n",
    "    month_name, year = month_year.split('-')\n",
    "    month_name = month_name.capitalize()\n",
    "    year = int(year)\n",
    "    month_num = list(calendar.month_name).index(month_name)\n",
    "    \n",
    "    # Get the weekday of the first day of the month (0 = Monday, 6 = Sunday)\n",
    "    first_weekday = calendar.weekday(year, month_num, 1)\n",
    "    \n",
    "    # Convert to day name (0 = Monday, 6 = Sunday)\n",
    "    days = ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']\n",
    "    return str(days[first_weekday]).capitalize()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02995b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Format the Excel file\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, PatternFill, Border, Side, Alignment\n",
    "from openpyxl.utils import get_column_letter\n",
    "from openpyxl.formatting.rule import Rule\n",
    "from openpyxl.styles.differential import DifferentialStyle\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Define the output path (make sure this file exists or create it first)\n",
    "output_path = \"invoice_day_channel_report_compatible.xlsx\"\n",
    "\n",
    "# Get the first day of the month from user\n",
    "while True:\n",
    "    first_day = get_first_day_of_month(latest_month_year).strip().lower()\n",
    "    if first_day in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']:\n",
    "        break\n",
    "    print('Invalid input! Please enter a valid day name.')\n",
    "\n",
    "# Create a mapping of days to their position in a week (0=Monday to 6=Sunday)\n",
    "day_positions = {\n",
    "    'monday': 0, 'tuesday': 1, 'wednesday': 2, 'thursday': 3,\n",
    "    'friday': 4, 'saturday': 5, 'sunday': 6\n",
    "}\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# Get position of the first day (0-6, where 0 is Monday)\n",
    "first_day_position = day_positions[first_day]\n",
    "\n",
    "def get_week_info(day_of_month, first_day_pos):\n",
    "    \"\"\"Get week information for a given day.\n",
    "    Returns (week_number, is_first_partial_week)\"\"\"\n",
    "    # For days in the first partial week\n",
    "    if first_day_pos > 0:  # If month doesn't start on Monday\n",
    "        days_till_next_monday = 7 - first_day_pos\n",
    "        if day_of_month <= days_till_next_monday:\n",
    "            return 1, True\n",
    "        # Adjust day number to calculate remaining weeks\n",
    "        adjusted_day = day_of_month - days_till_next_monday\n",
    "        return (adjusted_day - 1) // 7 + 2, False\n",
    "    else:  # If month starts on Monday\n",
    "        return (day_of_month - 1) // 7 + 1, False\n",
    "\n",
    "def get_day_name(day_number, first_day_pos):\n",
    "    \"\"\"Get the day name for a given day of month\"\"\"\n",
    "    # Calculate the day of week (0-6, where 0 is Monday)\n",
    "    day_of_week = (first_day_pos + day_number - 1) % 7\n",
    "    return day_names[day_of_week]\n",
    "\n",
    "try:\n",
    "    wb = load_workbook(output_path)\n",
    "    ws = wb.active\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File {output_path} not found. Please ensure the file exists.\")\n",
    "    exit(1)\n",
    "\n",
    "# Get dimensions\n",
    "data_rows = ws.max_row\n",
    "data_cols = ws.max_column\n",
    "\n",
    "# Insert a new column for day names after the Day column\n",
    "ws.insert_cols(3)  # Insert after Day column (column 2)\n",
    "\n",
    "# Define styles\n",
    "header_font = Font(bold=True, color=\"FFFFFF\")\n",
    "header_fill = PatternFill(\"solid\", fgColor=\"4472C4\")\n",
    "subheader_fill = PatternFill(\"solid\", fgColor=\"8EA9DB\")\n",
    "total_fill = PatternFill(\"solid\", fgColor=\"D9E1F2\")\n",
    "border_style = Side(style='thin')\n",
    "border = Border(left=border_style, right=border_style, top=border_style, bottom=border_style)\n",
    "\n",
    "# Insert title row\n",
    "ws.insert_rows(1)\n",
    "title_cell = ws.cell(row=1, column=1)\n",
    "title_cell.value = f\"Invoice Day Channel Report - Generated on {datetime.now().strftime('%Y-%m-%d')}\"\n",
    "title_cell.font = Font(bold=True, size=14)\n",
    "title_cell.alignment = Alignment(horizontal=\"center\")\n",
    "\n",
    "# Set up the day name column headers\n",
    "ws.cell(row=2, column=3).value = \"\"  # Channel level header\n",
    "ws.cell(row=3, column=3).value = \"Day Name\"  # Type level header\n",
    "\n",
    "# Apply formatting to headers\n",
    "for col in range(1, data_cols + 2):  # +2 to account for the new column and title row\n",
    "    # Format the cell in title row\n",
    "    ws.cell(row=1, column=col).border = border\n",
    "    \n",
    "    # Top header (channel)\n",
    "    top_header_cell = ws.cell(row=2, column=col)\n",
    "    top_header_cell.font = header_font\n",
    "    top_header_cell.fill = header_fill\n",
    "    top_header_cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "    top_header_cell.border = border\n",
    "    \n",
    "    # Second header (sheet/target/comparison)\n",
    "    second_header_cell = ws.cell(row=3, column=col)\n",
    "    second_header_cell.font = header_font\n",
    "    second_header_cell.fill = subheader_fill\n",
    "    second_header_cell.alignment = Alignment(horizontal=\"center\", vertical=\"center\")\n",
    "    second_header_cell.border = border\n",
    "\n",
    "# Populate the day name column\n",
    "day_col_idx = 2  # Day column (accounting for title row)\n",
    "day_name_col_idx = 3  # Day Name column\n",
    "data_start_row = 4  # First data row\n",
    "\n",
    "# Add day names for each day number\n",
    "for row in range(data_start_row, data_rows + 2):\n",
    "    day_cell = ws.cell(row=row, column=day_col_idx)\n",
    "    day_name_cell = ws.cell(row=row, column=day_name_col_idx)\n",
    "    \n",
    "    if isinstance(day_cell.value, (int, float)):\n",
    "        # Get the day name for this day number\n",
    "        day_name = get_day_name(int(day_cell.value), first_day_position)\n",
    "        day_name_cell.value = day_name\n",
    "        day_name_cell.alignment = Alignment(horizontal=\"center\")\n",
    "    \n",
    "    # Apply border and fill based on row\n",
    "    day_name_cell.border = border\n",
    "    day_name_cell.fill = PatternFill(\"solid\", fgColor=\"F2F2F2\") if row % 2 == 0 else PatternFill()\n",
    "\n",
    "# Auto-adjust column widths for all columns\n",
    "for col in range(1, data_cols + 2):  # +2 to account for the new column and title row\n",
    "    max_length = 0\n",
    "    for row in range(1, data_rows + 2):\n",
    "        cell_value = ws.cell(row=row, column=col).value\n",
    "        if cell_value:\n",
    "            max_length = max(max_length, len(str(cell_value)))\n",
    "    adjusted_width = max(max_length + 2, 12)  # minimum width of 12\n",
    "    ws.column_dimensions[get_column_letter(col)].width = adjusted_width\n",
    "\n",
    "# Format data cells\n",
    "for row in range(4, data_rows + 2):  # Start after headers and title\n",
    "    # Apply row striping\n",
    "    row_fill = PatternFill(\"solid\", fgColor=\"F2F2F2\") if row % 2 == 0 else PatternFill()\n",
    "    \n",
    "    for col in range(1, data_cols + 2):  # +2 to account for the new column and title row\n",
    "        if col == day_name_col_idx:  # Skip day name column as it's already formatted\n",
    "            continue\n",
    "            \n",
    "        cell = ws.cell(row=row, column=col)\n",
    "        cell.fill = row_fill\n",
    "        \n",
    "        header_value = ws.cell(row=3, column=col).value\n",
    "        \n",
    "        # Format based on content\n",
    "        if isinstance(cell.value, (int, float)):\n",
    "            # Format percentage columns\n",
    "            if header_value in ['v/s Target', 'v/s Last Year', 'v/s Last Month']:\n",
    "                if cell.value == float('inf'):\n",
    "                    cell.value = 'N/A'\n",
    "                else:\n",
    "                    value = int(round(cell.value)) # Raw percentage value, e.g., -10, 25, 150\n",
    "                    \n",
    "                    if header_value == 'v/s Target':\n",
    "                        # For v/s Target, original text display was absolute value + %\n",
    "                        cell.value = f\"{abs(value)}%\" \n",
    "                        # Coloring for v/s Target\n",
    "                        if value >= 100:\n",
    "                            cell.font = Font(color=\"006100\")  # Dark green text\n",
    "                            cell.fill = PatternFill(start_color='C6EFCE', end_color='C6EFCE', fill_type='solid')  # Light green fill\n",
    "                        else:\n",
    "                            cell.font = Font(color=\"9C0006\")  # Dark red text\n",
    "                            cell.fill = PatternFill(start_color='FFC7CE', end_color='FFC7CE', fill_type='solid')  # Light red fill\n",
    "                    else:  # For 'v/s Last Year' and 'v/s Last Month'\n",
    "                        if value > 0:\n",
    "                            cell.value = f\"+{value}%\"\n",
    "                            cell.font = Font(color=\"006100\")  # Dark green text\n",
    "                            cell.fill = PatternFill(start_color='C6EFCE', end_color='C6EFCE', fill_type='solid')  # Light green fill\n",
    "                        elif value < 0:\n",
    "                            cell.value = f\"{value}%\"  # Negative sign is included with 'value'\n",
    "                            cell.font = Font(color=\"9C0006\")  # Dark red text\n",
    "                            cell.fill = PatternFill(start_color='FFC7CE', end_color='FFC7CE', fill_type='solid')  # Light red fill\n",
    "                        else:  # value == 0\n",
    "                            cell.value = \"0%\"\n",
    "                            cell.font = Font(color=\"000000\") # Black text for neutral\n",
    "                            # cell.fill = PatternFill() # No specific fill, row striping applies, or set a neutral one\n",
    "                cell.alignment = Alignment(horizontal=\"center\")\n",
    "            else: # Not a percentage column\n",
    "                cell.number_format = '#,##0'\n",
    "        \n",
    "        cell.border = border\n",
    "        \n",
    "        # Center align Day column\n",
    "        if header_value == 'Day':\n",
    "            cell.alignment = Alignment(horizontal=\"center\")\n",
    "\n",
    "# Group days into weeks and add subtotals\n",
    "data_start_row = 4  # First data row\n",
    "week_ranges = []  # Store (start_row, end_row, week_num) for each week\n",
    "subtotal_rows = []  # Store the row numbers of subtotals for grand total calculation\n",
    "\n",
    "# First, collect all the day rows and their week numbers\n",
    "day_rows = []\n",
    "for row in range(data_start_row, data_rows + 2):\n",
    "    day = ws.cell(row=row, column=day_col_idx).value\n",
    "    if isinstance(day, (int, float)):\n",
    "        # Get week number and whether it's part of the first partial week\n",
    "        week_num, is_partial = get_week_info(int(day), first_day_position)\n",
    "        day_rows.append((row, day, week_num, is_partial))\n",
    "\n",
    "# Now organize them into week ranges\n",
    "current_week = None\n",
    "week_start_row = None\n",
    "is_current_partial = False\n",
    "\n",
    "for i, (row, day, week, is_partial) in enumerate(day_rows):\n",
    "    if current_week != week:\n",
    "        if current_week is not None:\n",
    "            # End the previous week\n",
    "            week_ranges.append((week_start_row, row - 1, current_week, is_current_partial))\n",
    "        # Start a new week\n",
    "        current_week = week\n",
    "        week_start_row = row\n",
    "        is_current_partial = is_partial\n",
    "    \n",
    "    # Handle the last week\n",
    "    if i == len(day_rows) - 1:\n",
    "        week_ranges.append((week_start_row, row, week, is_partial))\n",
    "\n",
    "# Insert subtotal rows\n",
    "rows_added = 0\n",
    "for start_row, end_row, week_num, is_partial in week_ranges:\n",
    "    # Adjusted for previously added subtotal rows\n",
    "    adjusted_start = start_row + rows_added\n",
    "    adjusted_end = end_row + rows_added\n",
    "    \n",
    "    # Insert the subtotal row\n",
    "    ws.insert_rows(adjusted_end + 1)\n",
    "    rows_added += 1\n",
    "    subtotal_rows.append(adjusted_end + 1)  # Store the subtotal row number\n",
    "    \n",
    "    # Format subtotal row\n",
    "    for col in range(1, data_cols + 2):  # +2 to account for the new column and title row\n",
    "        subtotal_cell = ws.cell(row=adjusted_end + 1, column=col)\n",
    "        subtotal_cell.font = Font(bold=True)\n",
    "        subtotal_cell.fill = total_fill\n",
    "        subtotal_cell.border = border\n",
    "        \n",
    "        if col == day_col_idx:\n",
    "            if is_partial:\n",
    "                days_in_partial = 7 - first_day_position\n",
    "                subtitle = f\"Week 1 (Partial: {days_in_partial} days)\"\n",
    "            else:\n",
    "                subtitle = f\"Week {week_num}\"\n",
    "            subtotal_cell.value = f\"{subtitle} Subtotal\"\n",
    "            subtotal_cell.alignment = Alignment(horizontal=\"center\")\n",
    "        \n",
    "        # Add Day Name subtotal cell\n",
    "        elif col == day_name_col_idx:\n",
    "            subtotal_cell.value = \"\"  # Leave empty for subtotals\n",
    "        \n",
    "        elif col > day_name_col_idx:  # Adjust for the Day Name column\n",
    "            header_value = ws.cell(row=3, column=col).value\n",
    "            col_letter = get_column_letter(col)\n",
    "            \n",
    "            if header_value == 'v/s Target':\n",
    "                # Get the column letter for \"Test\" (current month) for this channel - now at column F\n",
    "                sheet1_col = col - 1  # Current month data (Test) is 1 column before v/s Target\n",
    "                sheet1_letter = get_column_letter(sheet1_col)\n",
    "                \n",
    "                # Get the column letter for \"Target\" for this channel - now at column E\n",
    "                target_col = col - 2  # Target data is 2 columns before v/s Target\n",
    "                target_letter = get_column_letter(target_col)\n",
    "                \n",
    "                # Create formula to calculate percentage: (Test) / Target\n",
    "                # Ensure the formula outputs a number, and handle division by zero by outputting 0.\n",
    "                formula = f\"=IF({target_letter}{adjusted_end+1}=0,0,ROUND(({sheet1_letter}{adjusted_end+1})/{target_letter}{adjusted_end+1}*100,0))\"\n",
    "                subtotal_cell.value = formula\n",
    "                subtotal_cell.number_format = '0\\\"%\\\"'  # Apply percentage number format\n",
    "                subtotal_cell.alignment = Alignment(horizontal=\"center\")\n",
    "            \n",
    "            elif header_value == 'v/s Last Year':\n",
    "                # Get the column letter for \"Test\" (current month) for this channel - now at column F\n",
    "                sheet1_col = col - 2  # Current month data (Test) is 2 columns before v/s Last Year\n",
    "                sheet1_letter = get_column_letter(sheet1_col)\n",
    "                \n",
    "                # Get the column letter for \"Raw data May 24\" (last year) for this channel - at column D\n",
    "                may24_col = col - 4  # Last year data (Raw data May 24) is 4 columns before v/s Last Year\n",
    "                may24_letter = get_column_letter(may24_col)\n",
    "                \n",
    "                # Create formula to calculate percentage: (Test - Raw data May 24) / Raw data May 24\n",
    "                # Ensure the formula outputs a number, and handle division by zero by outputting 0.\n",
    "                formula = f\"=IF({may24_letter}{adjusted_end+1}=0,0,ROUND(({sheet1_letter}{adjusted_end+1}-{may24_letter}{adjusted_end+1})/{may24_letter}{adjusted_end+1}*100,0))\"\n",
    "                subtotal_cell.value = formula\n",
    "                subtotal_cell.number_format = '0\\\"%\\\"' # Display as percentage\n",
    "                subtotal_cell.alignment = Alignment(horizontal=\"center\")\n",
    "                \n",
    "            elif header_value == 'v/s Last Month':\n",
    "                # Get the column letter for \"Test\" (current month) for this channel - now at column F\n",
    "                sheet1_col = col - 3  # Current month data (Test) is 3 columns before v/s Last Month\n",
    "                sheet1_letter = get_column_letter(sheet1_col)\n",
    "                \n",
    "                # Get the column letter for \"Raw data April 25\" (last month) for this channel - at column C\n",
    "                april25_col = col - 6  # Last month data (Raw data April 25) is 6 columns before v/s Last Month\n",
    "                april25_letter = get_column_letter(april25_col)\n",
    "                \n",
    "                # Create formula to calculate percentage: (Test - Raw data April 25) / Raw data April 25\n",
    "                # Ensure the formula outputs a number, and handle division by zero by outputting 0 for the numeric part.\n",
    "                # The original formula appended \"%\" making it text.\n",
    "                formula_numeric_part = f\"IF({april25_letter}{adjusted_end+1}=0,0,ROUND(({sheet1_letter}{adjusted_end+1}-{april25_letter}{adjusted_end+1})/{april25_letter}{adjusted_end+1}*100,0))\"\n",
    "                \n",
    "                # The rule for these columns is > 0 is green, < 0 is red.\n",
    "                # The original code for data rows adds a \"+\" sign.\n",
    "                # For consistency with conditional formatting rules (which expect numbers), we'll keep it numeric.\n",
    "                # The display format will be handled by number_format if needed, or Excel's default for numbers.\n",
    "                # However, the original code for subtotal formulas for these columns also appended \"%\".\n",
    "                # Let's make them numeric and apply number format for consistency with 'v/s Target' approach.\n",
    "                formula = f\"=IF({april25_letter}{adjusted_end+1}=0,0,ROUND(({sheet1_letter}{adjusted_end+1}-{april25_letter}{adjusted_end+1})/{april25_letter}{adjusted_end+1}*100,0))\"\n",
    "                subtotal_cell.value = formula\n",
    "                subtotal_cell.number_format = '0\\\"%\\\"' # Display as percentage\n",
    "                subtotal_cell.alignment = Alignment(horizontal=\"center\")\n",
    "                \n",
    "            elif header_value not in ['v/s Target', 'v/s Last Year', 'v/s Last Month']:\n",
    "                # Calculate sum for this week's range\n",
    "                subtotal_cell.value = f\"=SUM({col_letter}{adjusted_start}:{col_letter}{adjusted_end})\"\n",
    "                subtotal_cell.number_format = '#,##0'\n",
    "\n",
    "# Add grand total row\n",
    "grand_total_row = data_rows + rows_added + 2\n",
    "ws.insert_rows(grand_total_row)\n",
    "\n",
    "# Format grand total row\n",
    "for col in range(1, data_cols + 2):  # +2 to account for the new column and title row\n",
    "    grand_total_cell = ws.cell(row=grand_total_row, column=col)\n",
    "    grand_total_cell.font = Font(bold=True)\n",
    "    grand_total_cell.fill = total_fill\n",
    "    grand_total_cell.border = border\n",
    "    \n",
    "    if col == day_col_idx:\n",
    "        grand_total_cell.value = \"Grand Total\"\n",
    "        grand_total_cell.alignment = Alignment(horizontal=\"center\")\n",
    "    elif col == day_name_col_idx:\n",
    "        grand_total_cell.value = \"\"\n",
    "    elif col > day_name_col_idx:  # Adjust for the Day Name column\n",
    "        header_value = ws.cell(row=3, column=col).value\n",
    "        col_letter = get_column_letter(col)\n",
    "        \n",
    "        if header_value == 'v/s Target':\n",
    "            # Get the column letters for Test (column F) and Target (column E) for grand total\n",
    "            sheet1_col = col - 1\n",
    "            sheet1_letter = get_column_letter(sheet1_col)\n",
    "            target_col = col - 2\n",
    "            target_letter = get_column_letter(target_col)\n",
    "            \n",
    "            # Create formula for grand total percentage - numeric output\n",
    "            formula = f\"=IF({target_letter}{grand_total_row}=0,0,ROUND(({sheet1_letter}{grand_total_row})/{target_letter}{grand_total_row}*100,0))\"\n",
    "            grand_total_cell.value = formula\n",
    "            grand_total_cell.number_format = '0\\\"%\\\"'  # Apply percentage number format\n",
    "            grand_total_cell.alignment = Alignment(horizontal=\"center\")\n",
    "            \n",
    "        elif header_value == 'v/s Last Year':\n",
    "            # Get the column letters for Test (column F) and Raw data May 24 (column D) for grand total\n",
    "            sheet1_col = col - 2\n",
    "            sheet1_letter = get_column_letter(sheet1_col)\n",
    "            may24_col = col - 4\n",
    "            may24_letter = get_column_letter(may24_col)\n",
    "            \n",
    "            # Create formula for grand total percentage - numeric output\n",
    "            formula = f\"=IF({may24_letter}{grand_total_row}=0,0,ROUND(({sheet1_letter}{grand_total_row}-{may24_letter}{grand_total_row})/{may24_letter}{grand_total_row}*100,0))\"\n",
    "            grand_total_cell.value = formula\n",
    "            grand_total_cell.number_format = '0\\\"%\\\"' # Display as percentage\n",
    "            grand_total_cell.alignment = Alignment(horizontal=\"center\")\n",
    "            \n",
    "        elif header_value == 'v/s Last Month':\n",
    "            # Get the column letters for Test (column F) and Raw data April 25 (column C) for grand total\n",
    "            sheet1_col = col - 3\n",
    "            sheet1_letter = get_column_letter(sheet1_col)\n",
    "            april25_col = col - 6\n",
    "            april25_letter = get_column_letter(april25_col)\n",
    "            \n",
    "            # Create formula for grand total percentage - numeric output\n",
    "            formula = f\"=IF({april25_letter}{grand_total_row}=0,0,ROUND(({sheet1_letter}{grand_total_row}-{april25_letter}{grand_total_row})/{april25_letter}{grand_total_row}*100,0))\"\n",
    "            grand_total_cell.value = formula\n",
    "            grand_total_cell.number_format = '0\\\"%\\\"' # Display as percentage\n",
    "            grand_total_cell.alignment = Alignment(horizontal=\"center\")\n",
    "            \n",
    "        elif header_value not in ['v/s Target', 'v/s Last Year', 'v/s Last Month']:\n",
    "            # Build formula to sum only the weekly subtotal rows\n",
    "            if subtotal_rows:  # Only if we have subtotal rows\n",
    "                subtotal_ranges = [f\"{col_letter}{row}\" for row in subtotal_rows]\n",
    "                formula = \"=SUM(\" + \",\".join(subtotal_ranges) + \")\"\n",
    "                grand_total_cell.value = formula\n",
    "                grand_total_cell.number_format = '#,##0'\n",
    "\n",
    "# Apply conditional formatting with simpler rules\n",
    "# Define styles for conditional formatting\n",
    "green_fill = PatternFill(start_color='C6EFCE', end_color='C6EFCE', fill_type='solid')\n",
    "red_fill = PatternFill(start_color='FFC7CE', end_color='FFC7CE', fill_type='solid')\n",
    "green_font = Font(color='006100', bold=True)\n",
    "red_font = Font(color='9C0006', bold=True)\n",
    "\n",
    "# Create differential styles\n",
    "green_style = DifferentialStyle(fill=green_fill, font=green_font)\n",
    "red_style = DifferentialStyle(fill=red_fill, font=red_font)\n",
    "\n",
    "# Apply conditional formatting to percentage columns in subtotal and grand total rows\n",
    "percentage_columns = []\n",
    "for col in range(day_name_col_idx + 1, data_cols + 2):\n",
    "    header_value = ws.cell(row=3, column=col).value\n",
    "    if header_value in ['v/s Target', 'v/s Last Year', 'v/s Last Month']:\n",
    "        percentage_columns.append(col)\n",
    "\n",
    "# Apply formatting to subtotal rows\n",
    "for subtotal_row in subtotal_rows:\n",
    "    for col in percentage_columns:\n",
    "        header_value = ws.cell(row=3, column=col).value\n",
    "        cell_range = f\"{get_column_letter(col)}{subtotal_row}\"\n",
    "        \n",
    "        try:\n",
    "            if header_value == 'v/s Target':\n",
    "                # For Target: Green if >= 100, Red if < 100\n",
    "                green_rule = Rule(type=\"cellIs\", operator=\"greaterThanOrEqual\", formula=[100], dxf=green_style)\n",
    "                red_rule = Rule(type=\"cellIs\", operator=\"lessThan\", formula=[100], dxf=red_style)\n",
    "            else:\n",
    "                # For Last Year and Last Month: Green if > 0, Red if < 0\n",
    "                green_rule = Rule(type=\"cellIs\", operator=\"greaterThan\", formula=[0], dxf=green_style)\n",
    "                red_rule = Rule(type=\"cellIs\", operator=\"lessThan\", formula=[0], dxf=red_style)\n",
    "            \n",
    "            ws.conditional_formatting.add(cell_range, green_rule)\n",
    "            ws.conditional_formatting.add(cell_range, red_rule)\n",
    "        except Exception as e:\n",
    "            print(f\"Warning: Could not apply conditional formatting to {cell_range}: {e}\")\n",
    "\n",
    "# Apply formatting to grand total row\n",
    "for col in percentage_columns:\n",
    "    header_value = ws.cell(row=3, column=col).value\n",
    "    cell_range = f\"{get_column_letter(col)}{grand_total_row}\"\n",
    "    \n",
    "    try:\n",
    "        if header_value == 'v/s Target':\n",
    "            # For Target: Green if >= 100, Red if < 100\n",
    "            green_rule = Rule(type=\"cellIs\", operator=\"greaterThanOrEqual\", formula=[100], dxf=green_style)\n",
    "            red_rule = Rule(type=\"cellIs\", operator=\"lessThan\", formula=[100], dxf=red_style)\n",
    "        else:\n",
    "            # For Last Year and Last Month: Green if > 0, Red if < 0\n",
    "            green_rule = Rule(type=\"cellIs\", operator=\"greaterThan\", formula=[0], dxf=green_style)\n",
    "            red_rule = Rule(type=\"cellIs\", operator=\"lessThan\", formula=[0], dxf=red_style)\n",
    "        \n",
    "        ws.conditional_formatting.add(cell_range, green_rule)\n",
    "        ws.conditional_formatting.add(cell_range, red_rule)\n",
    "    except Exception as e:\n",
    "        print(f\"Warning: Could not apply conditional formatting to {cell_range}: {e}\")\n",
    "\n",
    "# Manually merge headers - be careful for future changes\n",
    "try:\n",
    "    # Only merge if we have enough columns\n",
    "    if data_cols >= 24:  # Adjust based on your actual column count\n",
    "        ws.merge_cells('D2:J2')\n",
    "        ws.merge_cells('K2:Q2')\n",
    "        ws.merge_cells('R2:X2')\n",
    "    else:\n",
    "        print(\"Warning: Not enough columns to merge headers as specified\")\n",
    "        ws.merge_cells('D2:J2')\n",
    "        ws.merge_cells('K2:Q2')\n",
    "        ws.merge_cells('R2:X2')\n",
    "except Exception as e:\n",
    "    print(f\"Warning: Could not merge headers: {e}\")\n",
    "\n",
    "# Save the final formatted workbook\n",
    "try:\n",
    "    wb.save(output_path)\n",
    "    print(f\"Created final Excel report at {output_path}\")\n",
    "    print(f\"First day of month was {first_day.capitalize()}, weeks are aligned to start on Monday\")\n",
    "    print(f\"Added day name column next to the Day column for better readability\")\n",
    "except Exception as e:\n",
    "    print(f\"Error saving file: {e}\")\n",
    "    # Try saving with a different name\n",
    "    backup_path = output_path.replace('.xlsx', '_backup.xlsx')\n",
    "    try:\n",
    "        wb.save(backup_path)\n",
    "        print(f\"Saved backup file as {backup_path}\")\n",
    "    except Exception as e2:\n",
    "        print(f\"Could not save backup file either: {e2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69911562",
   "metadata": {},
   "source": [
    "## Session Data Processing\n",
    "Read and display the data from session.xlsx file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1905d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Apply filters with case-insensitive comparison for Category\n",
    "# 1. Remove Gift Card from Category (case-insensitive)\n",
    "# 2. Remove EA and Endless Aisle from CG\n",
    "session_df = session_df[\n",
    "    (~session_df['Category'].str.lower().str.contains('gift card', na=False)) & \n",
    "    (~session_df['CG'].isin(['EA', 'Endless Aisle']))\n",
    "]\n",
    "\n",
    "session_df['Date'] = pd.to_datetime(session_df['Date'], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "# Convert 'Day' column to day number (handles both date and string types)\n",
    "session_df['Day'] = session_df['Date'].dt.day\n",
    "\n",
    "# Select only the important columns\n",
    "session_df = session_df[important_columns]\n",
    "\n",
    "session_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5176c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "month_days = 31"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15d53b",
   "metadata": {},
   "source": [
    "## Channel-wise Session, Purchases, and Purchase Revenue\n",
    "Group the filtered session data by Channel and aggregate Sessions, Purchases, and Purchase revenue for Email, Organic, Paid Perf, and Paid Other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409d5764",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import IPython display to avoid conflicts with overridden display variable\n",
    "from IPython.display import display\n",
    "\n",
    "# Get all unique channels\n",
    "channels_of_interest = sorted(session_df['Channel'].dropna().unique())\n",
    "\n",
    "# Filter for the channels\n",
    "filtered = session_df[session_df['Channel'].isin(channels_of_interest)]\n",
    "\n",
    "# Group by Channel and aggregate\n",
    "agg = filtered.groupby('Channel')[['Sessions', 'Purchases', 'Purchase revenue']].sum().reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(\"Available channels:\")\n",
    "print(channels_of_interest)\n",
    "print(\"\\nAggregated data by Channel (Sessions, Purchases, Purchase revenue):\")\n",
    "display(agg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104ddf03",
   "metadata": {},
   "source": [
    "## Day and Channel-wise Session, Purchases, and Purchase Revenue\n",
    "Group the filtered session data by Day number and Channel, aggregating Sessions, Purchases, and Purchase revenue for Email, Organic, Paid Perf, and Paid Other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31cb2b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Day and Channel, aggregate Sessions, Purchases, and Purchase revenue\n",
    "agg_day_channel = filtered.groupby(['Day', 'Channel'])[['Sessions', 'Purchases', 'Purchase revenue']].sum().reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(\"Aggregated data by Day and Channel (Sessions, Purchases, Purchase revenue):\")\n",
    "display(agg_day_channel)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39f0c11f",
   "metadata": {},
   "source": [
    "## Pivot Table: Day-wise Channel Split for Sessions, Purchases, and Purchase Revenue\n",
    "A table with super columns for Sessions, Purchases, and Purchase revenue, each split by channel (Email, Organic, Paid Perf, Paid Other), and Day as the index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51154481",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Assuming 'filtered' DataFrame is already defined in the environment\n",
    "\n",
    "# Create a complete DataFrame with all days (1-31) for each channel\n",
    "all_days = list(range(1, 32))  # All days in a month (1-31)\n",
    "all_channels = sorted(filtered['Channel'].unique())\n",
    "\n",
    "# Create empty dataframe with all possible day-channel combinations\n",
    "full_month_data = []\n",
    "for day in all_days:\n",
    "    for channel in all_channels:\n",
    "        full_month_data.append({\n",
    "            'Day': day,\n",
    "            'Channel': channel,\n",
    "            'Sessions': 0,\n",
    "            'Purchases': 0,\n",
    "            'Purchase revenue': 0.0\n",
    "        })\n",
    "\n",
    "# Create full month DataFrame\n",
    "full_month_df = pd.DataFrame(full_month_data)\n",
    "\n",
    "# Update with actual data where available\n",
    "actual_data = filtered.groupby(['Day', 'Channel']).agg({\n",
    "    'Sessions': 'sum',\n",
    "    'Purchases': 'sum',\n",
    "    'Purchase revenue': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Merge actual data with full month data\n",
    "full_month_df = pd.merge(\n",
    "    full_month_df,\n",
    "    actual_data,\n",
    "    on=['Day', 'Channel'],\n",
    "    how='left',\n",
    "    suffixes=('_full', '')\n",
    ").fillna(0)\n",
    "\n",
    "# Keep only the columns we need\n",
    "full_month_df = full_month_df[['Day', 'Channel', 'Sessions', 'Purchases', 'Purchase revenue']]\n",
    "\n",
    "# Create the pivot table using the full month data\n",
    "pivot = full_month_df.pivot_table(\n",
    "    index='Day',\n",
    "    columns='Channel',\n",
    "    values=['Sessions', 'Purchases', 'Purchase revenue'],\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Get all channels in sorted order\n",
    "channels_order = sorted(full_month_df['Channel'].unique())\n",
    "metrics_order = ['Sessions', 'Purchases', 'Purchase revenue']\n",
    "\n",
    "# Build MultiIndex columns in the desired order\n",
    "pivot = pivot.reindex(columns=pd.MultiIndex.from_product([metrics_order, channels_order]))\n",
    "\n",
    "# Calculate CVR and AOV for each channel\n",
    "cvr_data = {}\n",
    "aov_data = {}\n",
    "\n",
    "for channel in channels_order:\n",
    "    # Calculate CVR (Conversion Rate) = (Purchases / Sessions) * 100\n",
    "    cvr = (pivot[('Purchases', channel)] / pivot[('Sessions', channel)] * 100).round(2)\n",
    "    cvr_data[channel] = cvr.replace([np.inf, -np.inf], 0)  # Handle division by zero\n",
    "    \n",
    "    # Calculate AOV (Average Order Value) = Purchase revenue / Purchases\n",
    "    aov = (pivot[('Purchase revenue', channel)] / pivot[('Purchases', channel)]).round(2)\n",
    "    aov_data[channel] = aov.replace([np.inf, -np.inf], 0)  # Handle division by zero\n",
    "\n",
    "# Add CVR and AOV to the pivot table\n",
    "for channel in channels_order:\n",
    "    pivot[('CVR', channel)] = cvr_data[channel]\n",
    "    pivot[('AOV', channel)] = aov_data[channel]\n",
    "\n",
    "# Update metrics order to include new columns\n",
    "metrics_order = ['Sessions', 'Purchases', 'Purchase revenue', 'CVR', 'AOV']\n",
    "\n",
    "# Reorder all columns according to the updated metrics\n",
    "pivot = pivot.reindex(columns=pd.MultiIndex.from_product([metrics_order, channels_order]))\n",
    "\n",
    "# Reset index for display\n",
    "pivot = pivot.reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(\"Day-wise channel split with Sessions, Purchases, Purchase revenue, CVR, and AOV (all days 1-31):\")\n",
    "display(pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "986bdfb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Apply styling to the pivot table\n",
    "def style_df(val, props=''):\n",
    "    return props\n",
    "\n",
    "# Create a complete DataFrame with all days for each channel\n",
    "all_days = list(range(1, month_days + 1))  # Use month_days instead of hardcoding 31\n",
    "all_channels = sorted(filtered['Channel'].unique())\n",
    "\n",
    "# Create empty dataframe with all possible day-channel combinations\n",
    "full_month_data = []\n",
    "for day in all_days:\n",
    "    for channel in all_channels:\n",
    "        full_month_data.append({\n",
    "            'Day': day,\n",
    "            'Channel': channel,\n",
    "            'Sessions': 0,\n",
    "            'Purchases': 0,\n",
    "            'Purchase revenue': 0.0\n",
    "        })\n",
    "\n",
    "# Create full month DataFrame\n",
    "full_month_df = pd.DataFrame(full_month_data)\n",
    "\n",
    "# Update with actual data where available\n",
    "actual_data = filtered.groupby(['Day', 'Channel']).agg({\n",
    "    'Sessions': 'sum',\n",
    "    'Purchases': 'sum',\n",
    "    'Purchase revenue': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Merge actual data with full month data\n",
    "full_month_df = pd.merge(\n",
    "    full_month_df,\n",
    "    actual_data,\n",
    "    on=['Day', 'Channel'],\n",
    "    how='left',\n",
    "    suffixes=('_full', '')\n",
    ").fillna(0)\n",
    "\n",
    "# Keep only the columns we need\n",
    "full_month_df = full_month_df[['Day', 'Channel', 'Sessions', 'Purchases', 'Purchase revenue']]\n",
    "\n",
    "# Create the pivot table using the full month data\n",
    "pivot = full_month_df.pivot_table(\n",
    "    index='Day',\n",
    "    columns='Channel',\n",
    "    values=['Sessions', 'Purchases', 'Purchase revenue'],\n",
    "    aggfunc='sum',\n",
    "    fill_value=0\n",
    ")\n",
    "\n",
    "# Get all channels in sorted order\n",
    "channels_order = sorted(full_month_df['Channel'].unique())\n",
    "metrics_order = ['Sessions', 'Purchases', 'Purchase revenue']\n",
    "\n",
    "# Build MultiIndex columns in the desired order\n",
    "pivot = pivot.reindex(columns=pd.MultiIndex.from_product([metrics_order, channels_order]))\n",
    "\n",
    "# Calculate CVR and AOV for each channel\n",
    "cvr_data = {}\n",
    "aov_data = {}\n",
    "\n",
    "for channel in channels_order:\n",
    "    # Calculate CVR (Conversion Rate) = (Purchases / Sessions) * 100\n",
    "    cvr = (pivot[('Purchases', channel)] / pivot[('Sessions', channel)] * 100).round(2)\n",
    "    cvr_data[channel] = cvr.replace([np.inf, -np.inf], 0)  # Handle division by zero\n",
    "    \n",
    "    # Calculate AOV (Average Order Value) = Purchase revenue / Purchases\n",
    "    aov = (pivot[('Purchase revenue', channel)] / pivot[('Purchases', channel)]).round(2)\n",
    "    aov_data[channel] = aov.replace([np.inf, -np.inf], 0)  # Handle division by zero\n",
    "\n",
    "# Add CVR and AOV to the pivot table\n",
    "for channel in channels_order:\n",
    "    pivot[('CVR', channel)] = cvr_data[channel]\n",
    "    pivot[('AOV', channel)] = aov_data[channel]\n",
    "\n",
    "# Update metrics order to include new columns\n",
    "metrics_order = ['Sessions', 'Purchases', 'Purchase revenue', 'CVR', 'AOV']\n",
    "\n",
    "# Reorder all columns according to the updated metrics\n",
    "pivot = pivot.reindex(columns=pd.MultiIndex.from_product([metrics_order, channels_order]))\n",
    "\n",
    "# Reset index for display\n",
    "pivot = pivot.reset_index()\n",
    "\n",
    "# Display the result\n",
    "print(f\"Day-wise channel split with Sessions, Purchases, Purchase revenue, CVR, and AOV (all days 1-{month_days}):\")\n",
    "display(pivot)\n",
    "\n",
    "# Define the styling for different metrics\n",
    "styled_pivot = pivot.style\\\n",
    "    .format({('CVR', channel): '{:.2f}%' for channel in channels_order})\\\n",
    "    .format({('AOV', channel): '${:,.2f}' for channel in channels_order})\\\n",
    "    .format({('Purchase revenue', channel): '${:,.2f}' for channel in channels_order})\\\n",
    "    .format({('Sessions', channel): '{:,.0f}' for channel in channels_order})\\\n",
    "    .format({('Purchases', channel): '{:,.0f}' for channel in channels_order})\n",
    "\n",
    "# Display the styled pivot table\n",
    "display(styled_pivot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efb0883",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export pivot table to Excel with formatting\n",
    "output_path = 'session_channel_report.xlsx'\n",
    "pivot.to_excel(output_path)\n",
    "\n",
    "# Format the Excel file\n",
    "from openpyxl import load_workbook\n",
    "from openpyxl.styles import Font, PatternFill, Border, Side, Alignment\n",
    "from openpyxl.utils import get_column_letter\n",
    "\n",
    "# # Get the first day of the month from user (reuse the same input)\n",
    "# while True:\n",
    "#     first_day = input('Enter the first day of the month (Monday/Tuesday/Wednesday/Thursday/Friday/Saturday/Sunday): ').strip().lower()\n",
    "#     if first_day in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']:\n",
    "#         break\n",
    "#     print('Invalid input! Please enter a valid day name.')\n",
    "\n",
    "# # Create a mapping of days to their position in a week (0=Monday to 6=Sunday)\n",
    "# day_positions = {\n",
    "#     'monday': 0, 'tuesday': 1, 'wednesday': 2, 'thursday': 3,\n",
    "#     'friday': 4, 'saturday': 5, 'sunday': 6\n",
    "# }\n",
    "# day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# # Get position of the first day (0-6, where 0 is Monday)\n",
    "# first_day_position = day_positions[first_day]\n",
    "\n",
    "\n",
    "def get_week_info(day_of_month, first_day_pos):\n",
    "    \"\"\"Get week information for a given day.\n",
    "    Returns (week_number, is_first_partial_week)\"\"\"\n",
    "    if first_day_pos > 0:  # If month doesn't start on Monday\n",
    "        days_till_next_monday = 7 - first_day_pos\n",
    "        if day_of_month <= days_till_next_monday:\n",
    "            return 1, True\n",
    "        adjusted_day = day_of_month - days_till_next_monday\n",
    "        return (adjusted_day - 1) // 7 + 2, False\n",
    "    else:  # If month starts on Monday\n",
    "        return (day_of_month - 1) // 7 + 1, False\n",
    "\n",
    "def get_day_name(day_number, first_day_pos):\n",
    "    \"\"\"Get the day name for a given day of month\"\"\"\n",
    "    day_of_week = (first_day_pos + day_number - 1) % 7\n",
    "    return day_names[day_of_week]\n",
    "\n",
    "wb = load_workbook(output_path)\n",
    "ws = wb.active\n",
    "\n",
    "# Get dimensions\n",
    "data_rows = ws.max_row\n",
    "data_cols = ws.max_column\n",
    "\n",
    "# Insert a new column for day names after the Day column\n",
    "ws.insert_cols(3)\n",
    "\n",
    "# Define styles\n",
    "header_font = Font(bold=True, color=\"FFFFFF\")\n",
    "header_fill = PatternFill(\"solid\", fgColor=\"4472C4\")\n",
    "subheader_fill = PatternFill(\"solid\", fgColor=\"8EA9DB\")\n",
    "total_fill = PatternFill(\"solid\", fgColor=\"D9E1F2\")\n",
    "border_style = Side(style='thin')\n",
    "border = Border(left=border_style, right=border_style, top=border_style, bottom=border_style)\n",
    "\n",
    "# Insert title row\n",
    "ws.insert_rows(1)\n",
    "title_cell = ws.cell(row=1, column=1)\n",
    "title_cell.value = f\"Session Channel Report - Generated on {datetime.now().strftime('%Y-%m-%d')}\"\n",
    "title_cell.font = Font(bold=True, size=14)\n",
    "title_cell.alignment = Alignment(horizontal=\"center\")\n",
    "\n",
    "# Set up headers\n",
    "for col in range(1, data_cols + 2):\n",
    "    # Format cells in title row\n",
    "    ws.cell(row=1, column=col).border = border\n",
    "    \n",
    "    # Top header (metrics)\n",
    "    top_header_cell = ws.cell(row=2, column=col)\n",
    "    top_header_cell.font = header_font\n",
    "    top_header_cell.fill = header_fill\n",
    "    top_header_cell.border = border\n",
    "    top_header_cell.alignment = Alignment(horizontal=\"center\")\n",
    "    \n",
    "    # Second header (channels)\n",
    "    second_header_cell = ws.cell(row=3, column=col)\n",
    "    second_header_cell.font = header_font\n",
    "    second_header_cell.fill = subheader_fill\n",
    "    second_header_cell.border = border\n",
    "    second_header_cell.alignment = Alignment(horizontal=\"center\")\n",
    "\n",
    "# Add day names\n",
    "day_col_idx = 2\n",
    "day_name_col_idx = 3\n",
    "data_start_row = 4\n",
    "\n",
    "# Add day names for each day number\n",
    "for row in range(data_start_row, data_rows + 2):\n",
    "    day_cell = ws.cell(row=row, column=day_col_idx)\n",
    "    day_name_cell = ws.cell(row=row, column=day_name_col_idx)\n",
    "    \n",
    "    if isinstance(day_cell.value, (int, float)):\n",
    "        day_name = get_day_name(int(day_cell.value), first_day_position)\n",
    "        day_name_cell.value = day_name\n",
    "        day_name_cell.alignment = Alignment(horizontal=\"center\")\n",
    "    \n",
    "    day_name_cell.border = border\n",
    "    day_name_cell.fill = PatternFill(\"solid\", fgColor=\"F2F2F2\") if row % 2 == 0 else PatternFill()\n",
    "\n",
    "# Collect day rows and group into weeks\n",
    "day_rows = []\n",
    "for row in range(data_start_row, data_rows + 2):\n",
    "    day = ws.cell(row=row, column=day_col_idx).value\n",
    "    if isinstance(day, (int, float)):\n",
    "        week_num, is_partial = get_week_info(int(day), first_day_position)\n",
    "        day_rows.append((row, day, week_num, is_partial))\n",
    "\n",
    "# Organize into week ranges\n",
    "week_ranges = []\n",
    "subtotal_rows = []\n",
    "current_week = None\n",
    "week_start_row = None\n",
    "is_current_partial = False\n",
    "\n",
    "for i, (row, day, week, is_partial) in enumerate(day_rows):\n",
    "    if current_week != week:\n",
    "        if current_week is not None:\n",
    "            # End the previous week\n",
    "            week_ranges.append((week_start_row, row - 1, current_week, is_current_partial))\n",
    "        # Start a new week\n",
    "        current_week = week\n",
    "        week_start_row = row\n",
    "        is_current_partial = is_partial\n",
    "    \n",
    "    # Handle the last week\n",
    "    if i == len(day_rows) - 1:\n",
    "        week_ranges.append((week_start_row, row, week, is_partial))\n",
    "\n",
    "# Insert subtotal rows\n",
    "rows_added = 0\n",
    "for start_row, end_row, week_num, is_partial in week_ranges:\n",
    "    adjusted_start = start_row + rows_added\n",
    "    adjusted_end = end_row + rows_added\n",
    "    \n",
    "    ws.insert_rows(adjusted_end + 1)\n",
    "    rows_added += 1\n",
    "    subtotal_rows.append(adjusted_end + 1)\n",
    "    \n",
    "    # Format subtotal row\n",
    "    for col in range(1, data_cols + 2):\n",
    "        subtotal_cell = ws.cell(row=adjusted_end + 1, column=col)\n",
    "        subtotal_cell.font = Font(bold=True)\n",
    "        subtotal_cell.fill = total_fill\n",
    "        subtotal_cell.border = border\n",
    "        \n",
    "        if col == day_col_idx:\n",
    "            if is_partial:\n",
    "                days_in_partial = 7 - first_day_position\n",
    "                subtitle = f\"Week 1 (Partial: {days_in_partial} days)\"\n",
    "            else:\n",
    "                subtitle = f\"Week {week_num}\"\n",
    "            subtotal_cell.value = f\"{subtitle} Subtotal\"\n",
    "            subtotal_cell.alignment = Alignment(horizontal=\"center\")\n",
    "        \n",
    "        # Add Day Name subtotal cell\n",
    "        elif col == day_name_col_idx:\n",
    "            subtotal_cell.value = \"\"  # Leave empty for subtotals\n",
    "        \n",
    "        elif col > day_name_col_idx:  # Adjust for the Day Name column\n",
    "            header_value = ws.cell(row=3, column=col).value\n",
    "            col_letter = get_column_letter(col)\n",
    "            \n",
    "            if header_value == 'v/s Target':\n",
    "                # Get the column letter for \"Test\" (current month) for this channel - now at column F\n",
    "                sheet1_col = col - 1  # Current month data (Test) is 1 column before v/s Target\n",
    "                sheet1_letter = get_column_letter(sheet1_col)\n",
    "                \n",
    "                # Get the column letter for \"Target\" for this channel - now at column E\n",
    "                target_col = col - 2  # Target data is 2 columns before v/s Target\n",
    "                target_letter = get_column_letter(target_col)\n",
    "                \n",
    "                # Create formula to calculate percentage: (Test) / Target\n",
    "                # Ensure the formula outputs a number, and handle division by zero by outputting 0.\n",
    "                formula = f\"=IF({target_letter}{adjusted_end+1}=0,0,ROUND(({sheet1_letter}{adjusted_end+1})/{target_letter}{adjusted_end+1}*100,0))\"\n",
    "                subtotal_cell.value = formula\n",
    "                subtotal_cell.number_format = '0\\\"%\\\"'  # Apply percentage number format\n",
    "                subtotal_cell.alignment = Alignment(horizontal=\"center\")\n",
    "            \n",
    "            elif header_value == 'v/s Last Year':\n",
    "                # Get the column letter for \"Test\" (current month) for this channel - now at column F\n",
    "                sheet1_col = col - 2  # Current month data (Test) is 2 columns before v/s Last Year\n",
    "                sheet1_letter = get_column_letter(sheet1_col)\n",
    "                \n",
    "                # Get the column letter for \"Raw data May 24\" (last year) for this channel - at column D\n",
    "                may24_col = col - 4  # Last year data (Raw data May 24) is 4 columns before v/s Last Year\n",
    "                may24_letter = get_column_letter(may24_col)\n",
    "                \n",
    "                # Create formula to calculate percentage: (Test - Raw data May 24) / Raw data May 24\n",
    "                # Ensure the formula outputs a number, and handle division by zero by outputting 0.\n",
    "                formula = f\"=IF({may24_letter}{adjusted_end+1}=0,0,ROUND(({sheet1_letter}{adjusted_end+1}-{may24_letter}{adjusted_end+1})/{may24_letter}{adjusted_end+1}*100,0))\"\n",
    "                subtotal_cell.value = formula\n",
    "                subtotal_cell.number_format = '0\\\"%\\\"' # Display as percentage\n",
    "                subtotal_cell.alignment = Alignment(horizontal=\"center\")\n",
    "                \n",
    "            elif header_value == 'v/s Last Month':\n",
    "                # Get the column letter for \"Test\" (current month) for this channel - now at column F\n",
    "                sheet1_col = col - 3  # Current month data (Test) is 3 columns before v/s Last Month\n",
    "                sheet1_letter = get_column_letter(sheet1_col)\n",
    "                \n",
    "                # Get the column letter for \"Raw data April 25\" (last month) for this channel - at column C\n",
    "                april25_col = col - 6  # Last month data (Raw data April 25) is 6 columns before v/s Last Month\n",
    "                april25_letter = get_column_letter(april25_col)\n",
    "                \n",
    "                # Create formula to calculate percentage: (Test - Raw data April 25) / Raw data April 25\n",
    "                # Ensure the formula outputs a number, and handle division by zero by outputting 0 for the numeric part.\n",
    "                # The original formula appended \"%\" making it text.\n",
    "                formula_numeric_part = f\"IF({april25_letter}{adjusted_end+1}=0,0,ROUND(({sheet1_letter}{adjusted_end+1}-{april25_letter}{adjusted_end+1})/{april25_letter}{adjusted_end+1}*100,0))\"\n",
    "                \n",
    "                # The rule for these columns is > 0 is green, < 0 is red.\n",
    "                # The original code for data rows adds a \"+\" sign.\n",
    "                # For consistency with conditional formatting rules (which expect numbers), we'll keep it numeric.\n",
    "                # The display format will be handled by number_format if needed, or Excel's default for numbers.\n",
    "                # However, the original code for subtotal formulas for these columns also appended \"%\".\n",
    "                # Let's make them numeric and apply number format for consistency with 'v/s Target' approach.\n",
    "                formula = f\"=IF({april25_letter}{adjusted_end+1}=0,0,ROUND(({sheet1_letter}{adjusted_end+1}-{april25_letter}{adjusted_end+1})/{april25_letter}{adjusted_end+1}*100,0))\"\n",
    "                subtotal_cell.value = formula\n",
    "                subtotal_cell.number_format = '0\\\"%\\\"' # Display as percentage\n",
    "                subtotal_cell.alignment = Alignment(horizontal=\"center\")\n",
    "                \n",
    "            elif header_value not in ['v/s Target', 'v/s Last Year', 'v/s Last Month']:\n",
    "                # Calculate sum for this week's range\n",
    "                subtotal_cell.value = f\"=SUM({col_letter}{adjusted_start}:{col_letter}{adjusted_end})\"\n",
    "                subtotal_cell.number_format = '#,##0'\n",
    "\n",
    "# Add grand total row\n",
    "grand_total_row = data_rows + rows_added + 2\n",
    "ws.insert_rows(grand_total_row)\n",
    "\n",
    "# Format grand total row\n",
    "for col in range(1, data_cols + 2):  # +2 to account for the new column and title row\n",
    "    grand_total_cell = ws.cell(row=grand_total_row, column=col)\n",
    "    grand_total_cell.font = Font(bold=True)\n",
    "    grand_total_cell.fill = total_fill\n",
    "    grand_total_cell.border = border\n",
    "    \n",
    "    if col == day_col_idx:\n",
    "        grand_total_cell.value = \"Grand Total\"\n",
    "        grand_total_cell.alignment = Alignment(horizontal=\"center\")\n",
    "    elif col == day_name_col_idx:\n",
    "        grand_total_cell.value = \"\"\n",
    "    elif col > day_name_col_idx:  # Adjust for the Day Name column\n",
    "        header_value = ws.cell(row=3, column=col).value\n",
    "        col_letter = get_column_letter(col)\n",
    "        \n",
    "        if header_value == 'v/s Target':\n",
    "            # Get the column letters for Test (column F) and Target (column E) for grand total\n",
    "            sheet1_col = col - 1\n",
    "            sheet1_letter = get_column_letter(sheet1_col)\n",
    "            target_col = col - 2\n",
    "            target_letter = get_column_letter(target_col)\n",
    "            \n",
    "            # Create formula for grand total percentage - numeric output\n",
    "            formula = f\"=IF({target_letter}{grand_total_row}=0,0,ROUND(({sheet1_letter}{grand_total_row})/{target_letter}{grand_total_row}*100,0))\"\n",
    "            grand_total_cell.value = formula\n",
    "            grand_total_cell.number_format = '0\\\"%\\\"'  # Apply percentage number format\n",
    "            grand_total_cell.alignment = Alignment(horizontal=\"center\")\n",
    "            \n",
    "        elif header_value == 'v/s Last Year':\n",
    "            # Get the column letters for Test (column F) and Raw data May 24 (column D) for grand total\n",
    "            sheet1_col = col - 2\n",
    "            sheet1_letter = get_column_letter(sheet1_col)\n",
    "            may24_col = col - 4\n",
    "            may24_letter = get_column_letter(may24_col)\n",
    "            \n",
    "            # Create formula for grand total percentage - numeric output\n",
    "            formula = f\"=IF({may24_letter}{grand_total_row}=0,0,ROUND(({sheet1_letter}{grand_total_row}-{may24_letter}{grand_total_row})/{may24_letter}{grand_total_row}*100,0))\"\n",
    "            grand_total_cell.value = formula\n",
    "            grand_total_cell.number_format = '0\\\"%\\\"' # Display as percentage\n",
    "            grand_total_cell.alignment = Alignment(horizontal=\"center\")\n",
    "            \n",
    "        elif header_value == 'v/s Last Month':\n",
    "            # Get the column letters for Test (column F) and Raw data April 25 (column C) for grand total\n",
    "            sheet1_col = col - 3\n",
    "            sheet1_letter = get_column_letter(sheet1_col)\n",
    "            april25_col = col - 6\n",
    "            april25_letter = get_column_letter(april25_col)\n",
    "            \n",
    "            # Create formula for grand total percentage - numeric output\n",
    "            formula = f\"=IF({april25_letter}{grand_total_row}=0,0,ROUND(({sheet1_letter}{grand_total_row}-{april25_letter}{grand_total_row})/{april25_letter}{grand_total_row}*100,0))\"\n",
    "            grand_total_cell.value = formula\n",
    "            grand_total_cell.number_format = '0\\\"%\\\"' # Display as percentage\n",
    "            grand_total_cell.alignment = Alignment(horizontal=\"center\")\n",
    "            \n",
    "        elif header_value not in ['v/s Target', 'v/s Last Year', 'v/s Last Month']:\n",
    "            # Build formula to sum only the weekly subtotal rows\n",
    "            if subtotal_rows:  # Only if we have subtotal rows\n",
    "                subtotal_ranges = [f\"{col_letter}{row}\" for row in subtotal_rows]\n",
    "                formula = \"=SUM(\" + \",\".join(subtotal_ranges) + \")\"\n",
    "                grand_total_cell.value = formula\n",
    "                grand_total_cell.number_format = '#,##0'\n",
    "\n",
    "# Format numbers\n",
    "for row in range(4, grand_total_row + 1):\n",
    "    for col in range(4, data_cols + 2):\n",
    "        cell = ws.cell(row=row, column=col)\n",
    "        header = ws.cell(row=3, column=col).value\n",
    "        \n",
    "        if header == 'CVR':\n",
    "            cell.number_format = '0.00%'  # Fixed escape sequence\n",
    "        elif header == 'AOV' or header == 'Purchase revenue':\n",
    "            cell.number_format = '$#,##0.00'  # Fixed escape sequence\n",
    "        elif header in ['Sessions', 'Purchases']:\n",
    "            cell.number_format = '#,##0'\n",
    "\n",
    "# Auto-adjust column widths\n",
    "for col in range(1, data_cols + 2):\n",
    "    max_length = 0\n",
    "    for row in range(1, grand_total_row + 1):\n",
    "        cell_value = ws.cell(row=row, column=col).value\n",
    "        if cell_value:\n",
    "            max_length = max(max_length, len(str(cell_value)))\n",
    "    adjusted_width = max(max_length + 2, 12)\n",
    "    ws.column_dimensions[get_column_letter(col)].width = adjusted_width\n",
    "\n",
    "# Calculate column spans for each metric\n",
    "metrics = ['Sessions', 'Purchases', 'Purchase revenue', 'CVR', 'AOV']\n",
    "channels_count = len(channels_order)\n",
    "start_col = 4  # Start after Day and Day Name columns\n",
    "\n",
    "for metric in metrics:\n",
    "    end_col = start_col + channels_count - 1\n",
    "    \n",
    "    # Set the value in the first cell\n",
    "    cell = ws.cell(row=2, column=start_col)\n",
    "    cell.value = metric\n",
    "    cell.font = header_font\n",
    "    cell.fill = header_fill\n",
    "    cell.alignment = Alignment(horizontal=\"center\")\n",
    "    \n",
    "    # Then merge the cells\n",
    "    ws.merge_cells(start_row=2, start_column=start_col, end_row=2, end_column=end_col)\n",
    "    \n",
    "    # Move to next section\n",
    "    start_col = end_col + 1\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(output_path)\n",
    "print(f\"Created session channel report at {output_path}\")\n",
    "print(f\"First day of month was {first_day.capitalize()}, weeks are aligned to start on Monday\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac7c1d6",
   "metadata": {},
   "source": [
    "## Copy Session Channel Data\n",
    "Copy data from session channel report to invoice day channel report, preserving all formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0d91981",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openpyxl import load_workbook\n",
    "from copy import copy\n",
    "\n",
    "# Copy data from session_channel_report.xlsx to invoice_day_channel_report_compatible.xlsx\n",
    "def copy_session_data():\n",
    "    \"\"\"\n",
    "    Copy session data from session_channel_report.xlsx to invoice_day_channel_report_compatible.xlsx\n",
    "    Starting from cell D2 in source to cell Y2 in destination\n",
    "    \"\"\"\n",
    "    source_path = 'session_channel_report.xlsx'\n",
    "    dest_path = 'invoice_day_channel_report_compatible.xlsx'\n",
    "    \n",
    "    # Load both workbooks\n",
    "    source_wb = load_workbook(source_path,data_only=True)\n",
    "    dest_wb = load_workbook(dest_path)\n",
    "    \n",
    "    source_ws = source_wb.active\n",
    "    dest_ws = dest_wb.active\n",
    "    \n",
    "    # Get the range of data to copy (starts from D2)\n",
    "    source_max_row = source_ws.max_row\n",
    "    source_max_col = source_ws.max_column\n",
    "    \n",
    "    # Copy data from D2 onwards in source to Y2 onwards in destination\n",
    "    source_start_col = 4  # Column D\n",
    "    dest_start_col = 25  # Column Y\n",
    "    \n",
    "    # Copy values and formatting\n",
    "    for row in range(2, source_max_row + 1):\n",
    "        for col_offset in range(source_max_col - source_start_col + 1):\n",
    "            source_col = source_start_col + col_offset\n",
    "            dest_col = dest_start_col + col_offset\n",
    "            \n",
    "            # Get source cell\n",
    "            source_cell = source_ws.cell(row=row, column=source_col)\n",
    "            \n",
    "            # Get destination cell\n",
    "            dest_cell = dest_ws.cell(row=row, column=dest_col)\n",
    "            \n",
    "            # Copy value\n",
    "            dest_cell.value = source_cell.value\n",
    "            \n",
    "            # Copy formatting\n",
    "            if source_cell.has_style:\n",
    "                dest_cell.font = copy(source_cell.font)\n",
    "                dest_cell.fill = copy(source_cell.fill)\n",
    "                dest_cell.border = copy(source_cell.border)\n",
    "                dest_cell.alignment = copy(source_cell.alignment)\n",
    "                dest_cell.number_format = source_cell.number_format\n",
    "    \n",
    "    # Save the destination workbook\n",
    "    dest_wb.save(dest_path)\n",
    "    print(f\"Successfully copied session data from {source_path} to {dest_path}\")\n",
    "\n",
    "# Execute the copy function\n",
    "copy_session_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb270f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "def open_save_close_excel_dynamic(file_path):\n",
    "    try:\n",
    "        \n",
    "        # Open file\n",
    "        os.startfile(file_path)\n",
    "        print(f\"\\nOpened {os.path.basename(file_path)}\")\n",
    "        \n",
    "        # Wait for user input\n",
    "        input(\"Please save and close the file manually, then press Enter to continue...\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error opening file: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404a519f",
   "metadata": {},
   "source": [
    "## Copy Session Channel Data with Merged Cells\n",
    "Copy data from session channel report to invoice day channel report, preserving all formatting including merged cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce644d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def copy_session_data():\n",
    "    \"\"\"\n",
    "    Copy session data from session_channel_report.xlsx to invoice_day_channel_report_compatible.xlsx\n",
    "    Starting from cell D2 in source to cell Y2 in destination, preserving merged cells\n",
    "    \"\"\"\n",
    "    source_path = 'session_channel_report.xlsx'\n",
    "    dest_path = 'invoice_day_channel_report_compatible.xlsx'\n",
    "\n",
    "    # if os.path.exists(source_path):\n",
    "    #     os.startfile(source_path)\n",
    "    \n",
    "    # _=input(\"Open the session_channel_report.xlsx, save it, then close it again and press Enter to continue...\")\n",
    "    if os.path.exists(source_path):\n",
    "        print(f\"Opening {os.path.abspath(source_path)} to ensure it's saved and closed properly...\")\n",
    "        open_save_close_excel_dynamic(os.path.abspath(source_path))\n",
    "\n",
    "    # Load both workbooks\n",
    "    source_wb = load_workbook(source_path, data_only=True)\n",
    "    dest_wb = load_workbook(dest_path)\n",
    "    \n",
    "    source_ws = source_wb.active\n",
    "    dest_ws = dest_wb.active\n",
    "    \n",
    "    # Get the range of data to copy (starts from D2)\n",
    "    source_max_row = source_ws.max_row\n",
    "    source_max_col = source_ws.max_column\n",
    "    \n",
    "    # Copy data from D2 onwards in source to Y2 onwards in destination\n",
    "    source_start_col = 4  # Column D\n",
    "    dest_start_col = 25  # Column Y\n",
    "    \n",
    "    # First, handle any merged cells in the header rows\n",
    "    # Get all merged ranges from source\n",
    "    merged_ranges = source_ws.merged_cells.ranges\n",
    "    \n",
    "    # For each merged range in source that starts with our copied columns\n",
    "    for merged_range in merged_ranges:\n",
    "        if merged_range.min_col >= source_start_col:\n",
    "            # Calculate the offset for the destination\n",
    "            col_offset = dest_start_col - source_start_col\n",
    "            \n",
    "            # Create new merge range coordinates for destination\n",
    "            new_min_col = merged_range.min_col + col_offset\n",
    "            new_max_col = merged_range.max_col + col_offset\n",
    "            new_range = f\"{get_column_letter(new_min_col)}{merged_range.min_row}:{get_column_letter(new_max_col)}{merged_range.max_row}\"\n",
    "            \n",
    "            # Merge the cells in destination\n",
    "            try:\n",
    "                dest_ws.merge_cells(new_range)\n",
    "                \n",
    "                # Copy the value from the top-left cell of the merge range\n",
    "                source_value = source_ws.cell(merged_range.min_row, merged_range.min_col).value\n",
    "                dest_ws.cell(merged_range.min_row, new_min_col).value = source_value\n",
    "                \n",
    "                # Copy formatting from the first cell of merge range\n",
    "                source_cell = source_ws.cell(merged_range.min_row, merged_range.min_col)\n",
    "                dest_cell = dest_ws.cell(merged_range.min_row, new_min_col)\n",
    "                \n",
    "                if source_cell.has_style:\n",
    "                    dest_cell.font = copy(source_cell.font)\n",
    "                    dest_cell.fill = copy(source_cell.fill)\n",
    "                    dest_cell.border = copy(source_cell.border)\n",
    "                    dest_cell.alignment = copy(source_cell.alignment)\n",
    "                    dest_cell.number_format = source_cell.number_format\n",
    "            except ValueError:\n",
    "                # If merge range already exists, just update the value and formatting\n",
    "                dest_ws.cell(merged_range.min_row, new_min_col).value = source_value\n",
    "    \n",
    "    # Now copy the rest of the data and formatting\n",
    "    for row in range(2, source_max_row + 1):\n",
    "        for col_offset in range(source_max_col - source_start_col + 1):\n",
    "            source_col = source_start_col + col_offset\n",
    "            dest_col = dest_start_col + col_offset\n",
    "            \n",
    "            # Skip if this cell is part of a merged range\n",
    "            if any(merged_range.min_row <= row <= merged_range.max_row and \n",
    "                  merged_range.min_col <= source_col <= merged_range.max_col \n",
    "                  for merged_range in merged_ranges):\n",
    "                continue\n",
    "            \n",
    "            # Get source cell\n",
    "            source_cell = source_ws.cell(row=row, column=source_col)\n",
    "            \n",
    "            # Get destination cell\n",
    "            dest_cell = dest_ws.cell(row=row, column=dest_col)\n",
    "            \n",
    "            # Copy value\n",
    "            dest_cell.value = source_cell.value\n",
    "            \n",
    "            # Copy formatting if it has any\n",
    "            if source_cell.has_style:\n",
    "                dest_cell.font = copy(source_cell.font)\n",
    "                dest_cell.fill = copy(source_cell.fill)\n",
    "                dest_cell.border = copy(source_cell.border)\n",
    "                dest_cell.alignment = copy(source_cell.alignment)\n",
    "                dest_cell.number_format = source_cell.number_format\n",
    "    \n",
    "    # Save the destination workbook\n",
    "    dest_wb.save(dest_path)\n",
    "    print(f\"Successfully copied session data from {source_path} to {dest_path}\")\n",
    "\n",
    "# Execute the copy function\n",
    "copy_session_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c014d9",
   "metadata": {},
   "source": [
    "## Final Processing\n",
    "Delete session_channel_report.xlsx and hide the first column in invoice_day_channel_report_compatible.xlsx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a86ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from openpyxl import load_workbook\n",
    "\n",
    "# Step 1: Delete session_channel_report.xlsx\n",
    "if os.path.exists('session_channel_report.xlsx'):\n",
    "    os.remove('session_channel_report.xlsx')\n",
    "    print(\"Deleted 'session_channel_report.xlsx'\")\n",
    "else:\n",
    "    print(\"'session_channel_report.xlsx' not found, skipping deletion\")\n",
    "\n",
    "# Step 2: Hide the first column in invoice_day_channel_report_compatible.xlsx\n",
    "report_path = 'invoice_day_channel_report_compatible.xlsx'\n",
    "\n",
    "# Load the workbook\n",
    "wb = load_workbook(report_path)\n",
    "ws = wb.active\n",
    "\n",
    "# Hide the first column (column A)\n",
    "ws.column_dimensions['A'].hidden = True\n",
    "ws.freeze_panes = 'D4'  # Freeze the first three rows and the first three columns\n",
    "\n",
    "# Save the workbook\n",
    "wb.save(report_path)\n",
    "print(f\"Hidden the first column in '{report_path}'\")\n",
    "print(\"All processing complete!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b568e024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automated Path Configuration for Weekly Analysis\n",
    "import os\n",
    "import glob\n",
    "import calendar\n",
    "import pandas as pd\n",
    "\n",
    "def get_month_year_combinations(latest_month_year):\n",
    "    \"\"\"\n",
    "    Get the latest month, last month, and last year combinations\n",
    "    \"\"\"\n",
    "    # Parse the latest month-year\n",
    "    month_name, year = latest_month_year.split('-')\n",
    "    year = int(year)\n",
    "    month_num = list(calendar.month_name).index(month_name)\n",
    "    \n",
    "    # Calculate last month\n",
    "    if month_num == 1:  # January\n",
    "        last_month_num = 12\n",
    "        last_month_year_num = year - 1\n",
    "    else:\n",
    "        last_month_num = month_num - 1\n",
    "        last_month_year_num = year\n",
    "    \n",
    "    # Calculate last year same month\n",
    "    last_year_month_num = month_num\n",
    "    last_year_year_num = year - 1\n",
    "    \n",
    "    # Convert back to names\n",
    "    last_month_name = calendar.month_name[last_month_num]\n",
    "    last_year_month_name = calendar.month_name[last_year_month_num]\n",
    "    \n",
    "    return {\n",
    "        'latest': {'month': month_name, 'year': year, 'folder': f\"{month_name}-{year}\"},\n",
    "        'last_month': {'month': last_month_name, 'year': last_month_year_num, 'folder': f\"{last_month_name}-{last_month_year_num}\"},\n",
    "        'last_year': {'month': last_year_month_name, 'year': last_year_year_num, 'folder': f\"{last_year_month_name}-{last_year_year_num}\"}\n",
    "    }\n",
    "\n",
    "def find_file_by_keyword(folder_path, keyword):\n",
    "    \"\"\"\n",
    "    Find a file in the folder that contains the keyword in its name\n",
    "    \"\"\"\n",
    "    if not os.path.exists(folder_path):\n",
    "        return None\n",
    "    \n",
    "    files = os.listdir(folder_path)\n",
    "    for file in files:\n",
    "        if keyword.lower() in file.lower() and file.endswith('.xlsx'):\n",
    "            return os.path.join(folder_path, file)\n",
    "    return None\n",
    "\n",
    "def get_sheet_name_with_keyword(file_path, keyword):\n",
    "    \"\"\"\n",
    "    Get the sheet name that contains the keyword\n",
    "    \"\"\"\n",
    "    try:\n",
    "        xl = pd.ExcelFile(file_path)\n",
    "        for sheet_name in xl.sheet_names:\n",
    "            if keyword.lower() in sheet_name.lower():\n",
    "                return sheet_name\n",
    "        # If no sheet with keyword found, return the first sheet\n",
    "        return xl.sheet_names[0] if xl.sheet_names else None\n",
    "    except:\n",
    "        return None\n",
    "\n",
    "def setup_automated_paths_weekly(latest_month_year, dsr_folder_path=None):\n",
    "    \"\"\"\n",
    "    Setup all paths automatically for weekly analysis\n",
    "    \n",
    "    Parameters:\n",
    "    latest_month_year: str - Format: \"June-2025\"\n",
    "    dsr_folder_path: str - Full path to DSR folder (e.g., \"C:/Users/Username/Documents/DSR\")\n",
    "                           If None, defaults to \"DSR\" in current directory\n",
    "    \n",
    "    Returns:\n",
    "    dict containing all the required paths and configurations\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get month-year combinations\n",
    "    dates = get_month_year_combinations(latest_month_year)\n",
    "    \n",
    "    # Base DSR folder path - use provided path or default to current directory\n",
    "    if dsr_folder_path is None:\n",
    "        dsr_path = os.path.join(os.getcwd(), \"DSR\")\n",
    "    else:\n",
    "        dsr_path = os.path.abspath(dsr_folder_path)\n",
    "        \n",
    "    print(f\"🔍 Looking for DSR folder at: {dsr_path}\")\n",
    "    \n",
    "    # Prepare results\n",
    "    sheet_info = []\n",
    "    sessions_info = []\n",
    "    target_info = {}\n",
    "    \n",
    "    # Process each period (last_month, last_year, latest)\n",
    "    periods = ['last_month', 'last_year', 'latest']\n",
    "    display_names = [\n",
    "        f\"{dates['last_month']['month']} {dates['last_month']['year'] % 100}\",  # May 25\n",
    "        f\"{dates['last_year']['month']} {dates['last_year']['year'] % 100}\",   # June 24\n",
    "        f\"{dates['latest']['month']} {dates['latest']['year'] % 100}\"          # June 25\n",
    "    ]\n",
    "    \n",
    "    for i, period in enumerate(periods):\n",
    "        period_data = dates[period]\n",
    "        folder_path = os.path.join(dsr_path, period_data['folder'])\n",
    "        \n",
    "        # Find invoice file\n",
    "        invoice_file = find_file_by_keyword(folder_path, 'invoice')\n",
    "        if invoice_file:\n",
    "            # Get the first sheet (since invoice files have only one sheet)\n",
    "            try:\n",
    "                xl = pd.ExcelFile(invoice_file)\n",
    "                sheet_name = xl.sheet_names[0] if xl.sheet_names else 'Sheet1'\n",
    "            except:\n",
    "                sheet_name = 'Sheet1'\n",
    "            \n",
    "            # Make path relative to current working directory\n",
    "            rel_path = os.path.relpath(invoice_file, os.getcwd())\n",
    "            sheet_info.append((rel_path, sheet_name, display_names[i]))\n",
    "        \n",
    "        # Find traffic/session file\n",
    "        traffic_file = find_file_by_keyword(folder_path, 'traffic')\n",
    "        if traffic_file:\n",
    "            download_sheet = get_sheet_name_with_keyword(traffic_file, 'download')\n",
    "            if not download_sheet:\n",
    "                # If no download sheet found, get the first sheet\n",
    "                try:\n",
    "                    xl = pd.ExcelFile(traffic_file)\n",
    "                    download_sheet = xl.sheet_names[0] if xl.sheet_names else 'Sheet1'\n",
    "                except:\n",
    "                    download_sheet = 'Sheet1'\n",
    "            \n",
    "            # Make path relative to current working directory\n",
    "            rel_path = os.path.relpath(traffic_file, os.getcwd())\n",
    "            sessions_info.append((rel_path, download_sheet, display_names[i]))\n",
    "    \n",
    "    # Setup target information (using latest month)\n",
    "    latest_folder = os.path.join(dsr_path, dates['latest']['folder'])\n",
    "    target_file = find_file_by_keyword(latest_folder, 'target')\n",
    "    if target_file:\n",
    "        target_sheet = get_sheet_name_with_keyword(target_file, 'target')\n",
    "        if not target_sheet:\n",
    "            target_sheet = 'Target'  # Default if not found\n",
    "        \n",
    "        target_info = {\n",
    "            'path': os.path.relpath(target_file, os.getcwd()),\n",
    "            'sheet': target_sheet\n",
    "        }\n",
    "    \n",
    "    return {\n",
    "        'sheet_info': sheet_info,\n",
    "        'sessions_info': sessions_info,\n",
    "        'target_info': target_info,\n",
    "        'dates': dates\n",
    "    }\n",
    "\n",
    "# Get user input for the latest month and DSR path\n",
    "print(\"📊 Weekly Analysis - Automated Path Configuration\")\n",
    "print(\"=\" * 50)\n",
    "print(\"Please enter the latest month in format 'Month-Year' (e.g., 'June-2025'):\")\n",
    "print(\"You'll also be asked for the DSR folder path if it's not in the default location.\")\n",
    "print(\"Note: Make sure the DSR folder exists with the appropriate month folders.\")\n",
    "print(\"This will configure both invoice data and session data automatically.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef9a14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Automated Configuration\n",
    "latest_month_year = latest_month_year.strip()\n",
    "dsr_folder_path = dsr_folder_path\n",
    "\n",
    "# Setup all paths automatically\n",
    "try:\n",
    "    config = setup_automated_paths_weekly(latest_month_year, dsr_folder_path)\n",
    "    \n",
    "    # Extract configuration\n",
    "    sheet_info = config['sheet_info']\n",
    "    sessions_info = config['sessions_info']\n",
    "    target_config = config['target_info']\n",
    "    \n",
    "    print(f\"\\n✅ Weekly Analysis Configuration successful!\")\n",
    "    if dsr_folder_path:\n",
    "        print(f\"📁 Using DSR folder: {dsr_folder_path}\")\n",
    "    print(f\"📁 Found {len(sheet_info)} invoice files:\")\n",
    "    for i, (path, sheet, display) in enumerate(sheet_info):\n",
    "        print(f\"   {i+1}. {display}: {path} -> {sheet}\")\n",
    "    \n",
    "    print(f\"\\n📊 Found {len(sessions_info)} session/traffic files:\")\n",
    "    for i, (path, sheet, display) in enumerate(sessions_info):\n",
    "        print(f\"   {i+1}. {display}: {path} -> {sheet}\")\n",
    "    \n",
    "    if target_config:\n",
    "        print(f\"\\n🎯 Target file: {target_config['path']} -> {target_config['sheet']}\")\n",
    "        TARGET_PATH = target_config['path']\n",
    "        TARGET_SHEET = target_config['sheet']\n",
    "    else:\n",
    "        print(\"\\n⚠️  No target file found - using fallback\")\n",
    "        TARGET_PATH = 'test2/Target_June_25.xlsx'\n",
    "        TARGET_SHEET = 'Target-June25'\n",
    "    \n",
    "    print(f\"\\n🚀 Ready for weekly analysis with automated paths!\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"❌ Error in automated setup: {e}\")\n",
    "    print(\"🔄 Falling back to manual configuration...\")\n",
    "    \n",
    "    # Fallback to manual configuration\n",
    "    sheet_info = [\n",
    "        ('test2/may25-final.xlsx', 'Sheet1', 'May 25'),   # Last month raw sheet\n",
    "        ('test2/June24_Invoice.xlsx', 'Raw data June 24', 'June 24'),        # Last year raw sheet\n",
    "        ('test2/June25.xlsx', 'Sheet1', 'June 25')                # Latest month raw sheet\n",
    "    ]\n",
    "    \n",
    "    sessions_info = [\n",
    "        ('test2/May_2025_Daily traffic (2).xlsx', 'download - 2025-01-08T160122.10', 'May 25'), # Last month session\n",
    "        ('test2/June Traffic -2024.xlsx', 'download - 2025-06-03T09524 (2)', 'June 24'),  # Last year session\n",
    "        ('test2/June_2025_Daily traffic.xlsx', 'download - 2025-01-08T160122.10', 'June 25')   # Current month session\n",
    "    ]\n",
    "    \n",
    "    TARGET_PATH = 'test2/Target_June_25.xlsx'\n",
    "    TARGET_SHEET = 'Target-June25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a083c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get necessary imports\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font, PatternFill, Border, Side, Alignment, numbers\n",
    "from openpyxl.utils import get_column_letter\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "from copy import copy  # For copying Excel cell styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9357e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target Excel file \n",
    "output_path = 'weekly.xlsx'\n",
    "\n",
    "# ✅ USING AUTOMATED CONFIGURATION\n",
    "# sheet_info, sessions_info, TARGET_PATH, and TARGET_SHEET are now configured automatically above\n",
    "# If automation failed, they fall back to manual configuration\n",
    "\n",
    "# Verify configuration is loaded\n",
    "if 'sheet_info' not in globals():\n",
    "    print(\"⚠️  sheet_info not found - please run the automated configuration cells above\")\n",
    "if 'sessions_info' not in globals():\n",
    "    print(\"⚠️  sessions_info not found - please run the automated configuration cells above\")\n",
    "\n",
    "# Get latest invoice data for max day calculation\n",
    "latest_path, latest_sheet, latest_display = sheet_info[-1]\n",
    "latest_df = pd.read_excel(latest_path, sheet_name=latest_sheet)\n",
    "max_invoice_day = pd.to_datetime(latest_df['InvoiceDate'], dayfirst=True, errors='coerce').dt.day.max()\n",
    "\n",
    "print(f\"📊 Configuration Summary:\")\n",
    "print(f\"   Sheet Info: {len(sheet_info)} files configured\")\n",
    "print(f\"   Sessions Info: {len(sessions_info)} files configured\") \n",
    "print(f\"   Target: {TARGET_PATH} -> {TARGET_SHEET}\")\n",
    "print(f\"   Max Invoice Day: {max_invoice_day}\")\n",
    "\n",
    "# Create unique identifiers by combining file path and sheet name\n",
    "LAST_MONTH_ID = f\"{sheet_info[0][0]}_{sheet_info[0][1]}\"\n",
    "LAST_YEAR_ID = f\"{sheet_info[1][0]}_{sheet_info[1][1]}\"\n",
    "CURRENT_ID = f\"{sheet_info[2][0]}_{sheet_info[2][1]}\"\n",
    "\n",
    "# Dynamic constants extracted from sheet_info for easy reference\n",
    "LAST_MONTH_PATH = sheet_info[0][0]      # File path for last month\n",
    "LAST_MONTH_SHEET = sheet_info[0][1]     # Sheet name for last month\n",
    "LAST_MONTH_DISPLAY = sheet_info[0][2]   # Display name for last month\n",
    "\n",
    "LAST_YEAR_PATH = sheet_info[1][0]       # File path for last year\n",
    "LAST_YEAR_SHEET = sheet_info[1][1]      # Sheet name for last year\n",
    "LAST_YEAR_DISPLAY = sheet_info[1][2]    # Display name for last year\n",
    "\n",
    "CURRENT_PATH = sheet_info[2][0]         # File path for current month\n",
    "CURRENT_SHEET = sheet_info[2][1]        # Sheet name for current month\n",
    "CURRENT_DISPLAY = sheet_info[2][2]      # Display name for current month\n",
    "\n",
    "# Create dynamic periods list from sheet_info display names\n",
    "periods = [LAST_MONTH_DISPLAY, LAST_YEAR_DISPLAY, CURRENT_DISPLAY]\n",
    "\n",
    "print(\"📊 Dynamic Configuration Loaded:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Last Month:   {LAST_MONTH_DISPLAY} (ID: {LAST_MONTH_ID})\")\n",
    "print(f\"Last Year:    {LAST_YEAR_DISPLAY} (ID: {LAST_YEAR_ID})\")  \n",
    "print(f\"Current:      {CURRENT_DISPLAY} (ID: {CURRENT_ID})\")\n",
    "print(f\"Periods:      {periods}\")\n",
    "print(\"=\" * 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06edad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target sums by day and channel using constants - WITH DEBUG OUTPUT\n",
    "print(\"🔍 DEBUGGING TARGET DATA STRUCTURE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "target_df = pd.read_excel(TARGET_PATH, sheet_name=TARGET_SHEET)\n",
    "print(f\"📊 Raw Target Data Shape: {target_df.shape}\")\n",
    "print(f\"📋 Target Data Columns: {list(target_df.columns)}\")\n",
    "print(\"\\n📅 First 10 rows of Target Data:\")\n",
    "print(target_df.head(10))\n",
    "\n",
    "print(\"\\n🏷️ Unique Channels in Target Data:\")\n",
    "print(target_df['Channel'].unique())\n",
    "\n",
    "print(\"\\n🏷️ Unique Categories in Target Data:\")\n",
    "if 'Category' in target_df.columns:\n",
    "    print(target_df['Category'].unique())\n",
    "else:\n",
    "    print(\"No 'Category' column found in target data\")\n",
    "\n",
    "# Modified to include 'Category' in the grouping if it exists\n",
    "if 'Category' in target_df.columns:\n",
    "    target_sums = target_df.groupby(['Date', 'Channel', 'Category'])['Target'].sum().unstack(level=['Channel', 'Category'], fill_value=0).round(6)\n",
    "else:\n",
    "    target_sums = target_df.groupby(['Date', 'Channel'])['Target'].sum().unstack(level='Channel', fill_value=0).round(6)\n",
    "\n",
    "print(f\"\\n📊 Processed Target Sums Shape: {target_sums.shape}\")\n",
    "print(\"\\n📋 Target Sums Sample:\")\n",
    "print(target_sums.head())\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ada2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📅 Week Analysis Configuration - User Input Based\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "print(\"🗓️  WEEK ANALYSIS CONFIGURATION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"📝 Choose your preferred starting day for weekly analysis:\")\n",
    "print(\"   Options: Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday\")\n",
    "print()\n",
    "\n",
    "# Get the first day of the month from user\n",
    "while True:\n",
    "    first_day = first_day.strip().lower()\n",
    "    if first_day in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']:\n",
    "        break\n",
    "    print('Invalid input! Please enter a valid day name.')\n",
    "\n",
    "# Create a mapping of days to their position in a week (0=Monday to 6=Sunday)\n",
    "day_positions = {\n",
    "    'monday': 0, 'tuesday': 1, 'wednesday': 2, 'thursday': 3,\n",
    "    'friday': 4, 'saturday': 5, 'sunday': 6\n",
    "}\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# Get position of the first day (0-6, where 0 is Monday)\n",
    "first_day_position = day_positions[first_day]\n",
    "start_day = day_names[first_day_position].capitalize()\n",
    "\n",
    "print(f\"✅ First day of month set to: {start_day}\")\n",
    "print(f\"📊 Configuration: Week analysis starts based on {start_day} as first day\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def get_week_info(day_of_month, first_day_pos):\n",
    "    \"\"\"Get week information for a given day.\n",
    "    Returns (week_number, is_first_partial_week)\"\"\"\n",
    "    # For days in the first partial week\n",
    "    if first_day_pos > 0:  # If month doesn't start on Monday\n",
    "        days_till_next_monday = 7 - first_day_pos\n",
    "        if day_of_month <= days_till_next_monday:\n",
    "            return 1, True\n",
    "        # Adjust day number to calculate remaining weeks\n",
    "        adjusted_day = day_of_month - days_till_next_monday\n",
    "        return (adjusted_day - 1) // 7 + 2, False\n",
    "    else:  # If month starts on Monday\n",
    "        return (day_of_month - 1) // 7 + 1, False\n",
    "\n",
    "def get_week_number(day_of_month, first_day_pos):\n",
    "    \"\"\"Get week number for a given day of month\"\"\"\n",
    "    week_num, _ = get_week_info(day_of_month, first_day_pos)\n",
    "    return week_num\n",
    "\n",
    "def get_week_label(week_num):\n",
    "    \"\"\"Get descriptive week label\"\"\"\n",
    "    return f\"Week {week_num}\"\n",
    "\n",
    "def get_day_name(day_number, first_day_pos):\n",
    "    \"\"\"Get the day name for a given day of month\"\"\"\n",
    "    # Calculate the day of week (0-6, where 0 is Monday)\n",
    "    day_of_week = (first_day_pos + day_number - 1) % 7\n",
    "    return day_names[day_of_week]\n",
    "\n",
    "# Test the calculation\n",
    "print(f\"\\n📊 Week Calculation Test (First day: {start_day})\")\n",
    "print(\"=\" * 50)\n",
    "for day in range(1, 16):  # Show first 15 days\n",
    "    week_num = get_week_number(day, first_day_position)\n",
    "    week_label = get_week_label(week_num)\n",
    "    day_name = get_day_name(day, first_day_position)\n",
    "    print(f\"Day {day:2d} ({day_name:9s}) → {week_label}\")\n",
    "\n",
    "# Calculate total weeks for a typical 31-day month\n",
    "max_weeks = max([get_week_number(day, first_day_position) for day in range(1, 32)])\n",
    "print(f\"\\n📈 Total weeks in a 31-day month: {max_weeks}\")\n",
    "print(f\"📋 Analysis will group days based on {start_day} as first day of month\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Store variables for use in other cells\n",
    "start_day_num = first_day_position  # For compatibility with existing code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5351c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect week-wise and TYPE-wise sums for each sheet using simplified week calculation\n",
    "results = []\n",
    "type_results = []\n",
    "idg_results = []  # New list for IDG results\n",
    "\n",
    "for path, sheet, display_name in sheet_info:\n",
    "    df = pd.read_excel(path, sheet_name=sheet)\n",
    "    filtered_df = df[~df['idg'].isin(['FOC', 'Remove', 'WRT'])].copy()\n",
    "    filtered_df['InvoiceDay'] = pd.to_datetime(filtered_df['InvoiceDate'], dayfirst=True, errors='coerce').dt.day\n",
    "\n",
    "\n",
    "    original_len = len(filtered_df)\n",
    "    filtered_df = filtered_df[filtered_df['InvoiceDay'] <= max_invoice_day]\n",
    "    print(f\"📉 {display_name}: Filtered {original_len - len(filtered_df)} rows with InvoiceDay > {max_invoice_day}\")\n",
    "\n",
    "\n",
    "    \n",
    "    # Add week number calculation using the simplified function\n",
    "    filtered_df['WeekNumber'] = filtered_df['InvoiceDay'].apply(\n",
    "        lambda day: get_week_number(day, first_day_position)\n",
    "    )\n",
    "    \n",
    "    # Map CC to Jumbo.ae in the TYPE column\n",
    "    filtered_df['TYPE'] = filtered_df['TYPE'].replace('CC', 'Jumbo.ae')\n",
    "    \n",
    "    # Week-wise sum - use a unique identifier combining file path and sheet name\n",
    "    unique_id = f\"{path}_{sheet}\"\n",
    "    invoice_week_sum = filtered_df.groupby('WeekNumber')['Amount Invoiced W.O. VAT'].sum()\n",
    "    results.append((unique_id, invoice_week_sum, display_name))\n",
    "    \n",
    "    # TYPE-wise sum for Jumbo.ae and EA by week - use unique identifier\n",
    "    filtered_type = filtered_df[filtered_df['TYPE'].isin(['Jumbo.ae', 'EA'])]\n",
    "    sum_by_week_type = filtered_type.groupby(['WeekNumber', 'TYPE'])['Amount Invoiced W.O. VAT'].sum().unstack(fill_value=0)\n",
    "    type_results.append((unique_id, sum_by_week_type, display_name))\n",
    "    \n",
    "    # IDG-wise sum by week (new addition) - use unique identifier\n",
    "    sum_by_week_idg = filtered_df.pivot_table(\n",
    "        values='Amount Invoiced W.O. VAT',\n",
    "        index='WeekNumber',\n",
    "        columns='idg',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    )\n",
    "    idg_results.append((unique_id, display_name, sum_by_week_idg))\n",
    "\n",
    "type_results\n",
    "\n",
    "# Target Data Processing Functions with Channel Filtering and Debug Output\n",
    "print(\"🎯 TARGET DATA PROCESSING WITH CHANNEL FILTERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def process_target_data_by_week_and_channel(channel_filter=None):\n",
    "    \"\"\"\n",
    "    Process target data and group by week and IDG (Category), with optional channel filtering\n",
    "    \n",
    "    Args:\n",
    "        channel_filter: str, optional - Filter by 'Jumbo.ae' or 'EA' or None for all\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with weeks as index and IDG (Category) as columns\n",
    "    \"\"\"\n",
    "    print(f\"\\n🔄 Processing target data for channel: {channel_filter or 'ALL CHANNELS'}\")\n",
    "    \n",
    "    # Read target data\n",
    "    target_df = pd.read_excel(TARGET_PATH, sheet_name=TARGET_SHEET)\n",
    "    \n",
    "    print(f\"📊 Original target data shape: {target_df.shape}\")\n",
    "    \n",
    "    # Apply channel filter if specified\n",
    "    if channel_filter:\n",
    "        filtered_target = target_df[target_df['Channel'] == channel_filter].copy()\n",
    "        print(f\"🔍 After {channel_filter} filter: {filtered_target.shape}\")\n",
    "        \n",
    "        if filtered_target.empty:\n",
    "            print(f\"⚠️ WARNING: No target data found for channel '{channel_filter}'\")\n",
    "            print(f\"📅 Available channels: {target_df['Channel'].unique()}\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        filtered_target = target_df.copy()\n",
    "    \n",
    "    # Use the 'Date' column directly as 'Day' as it contains day numbers\n",
    "    filtered_target['Day'] = filtered_target['Date']\n",
    "    \n",
    "    # Ensure 'Day' column is numeric and handle potential errors (e.g., non-numeric values)\n",
    "    filtered_target['Day'] = pd.to_numeric(filtered_target['Day'], errors='coerce')\n",
    "\n",
    "    # Remove rows with invalid dates (where 'Day' could not be converted to numeric)\n",
    "    before_date_filter = len(filtered_target)\n",
    "    filtered_target = filtered_target.dropna(subset=['Day'])\n",
    "    after_date_filter = len(filtered_target)\n",
    "    \n",
    "    if before_date_filter != after_date_filter:\n",
    "        print(f\"⚠️ Removed {before_date_filter - after_date_filter} rows with invalid 'Day' values (non-numeric or empty).\")\n",
    "    \n",
    "    # Convert 'Day' to integer type after cleaning\n",
    "    if not filtered_target.empty:\n",
    "        filtered_target['Day'] = filtered_target['Day'].astype(int)\n",
    "\n",
    "    original_len = len(filtered_target)\n",
    "    filtered_target = filtered_target[filtered_target['Day'] <= max_invoice_day]\n",
    "    print(f\"📉 {display_name}: Filtered {original_len - len(filtered_target)} rows with Day > {max_invoice_day}\")\n",
    "    # Add week number calculation\n",
    "    filtered_target['WeekNumber'] = filtered_target['Day'].apply(\n",
    "        lambda day: get_week_number(day, first_day_position)\n",
    "    )\n",
    "    \n",
    "    print(f\"📅 Date range in target: {filtered_target['Day'].min()} to {filtered_target['Day'].max()}\")\n",
    "    print(f\"📋 Week range: {filtered_target['WeekNumber'].min()} to {filtered_target['WeekNumber'].max()}\")\n",
    "    \n",
    "    # Check if Category column exists and use it, otherwise use Channel as IDG\n",
    "    if 'Category' in filtered_target.columns:\n",
    "        print(f\"🏷️ Using 'Category' column for IDG grouping\")\n",
    "        print(f\"📅 Available categories: {filtered_target['Category'].unique()}\")\n",
    "        \n",
    "        # Group by Week and Category to get target by week and IDG\n",
    "        target_by_week = filtered_target.groupby(['WeekNumber', 'Category'])['Target'].sum().unstack(level='Category', fill_value=0)\n",
    "    else:\n",
    "        print(f\"🏷️ No 'Category' column found, using 'Channel' for IDG grouping\")\n",
    "        \n",
    "        # Group by Week and Channel to get target by week\n",
    "        target_by_week = filtered_target.groupby(['WeekNumber', 'Channel'])['Target'].sum().unstack(level='Channel', fill_value=0)\n",
    "    \n",
    "    # Clean column names\n",
    "    target_by_week.columns.name = None\n",
    "    \n",
    "    print(f\"📊 Final target pivot shape: {target_by_week.shape}\")\n",
    "    print(f\"📋 Target IDGs/Categories: {list(target_by_week.columns)}\")\n",
    "    \n",
    "    return target_by_week\n",
    "\n",
    "# Test target processing for all channels\n",
    "print(\"\\n🔬 TESTING TARGET DATA PROCESSING:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Import IPython display to avoid conflicts with overridden display variable\n",
    "from IPython.display import display\n",
    "\n",
    "# Test 1: All channels\n",
    "all_channels_target = process_target_data_by_week_and_channel()\n",
    "if not all_channels_target.empty:\n",
    "    print(\"\\n📋 ALL CHANNELS TARGET DATA:\")\n",
    "    display(all_channels_target.round(2))\n",
    "\n",
    "# Test 2: Jumbo.ae only  \n",
    "jumbo_target = process_target_data_by_week_and_channel('Jumbo.ae')\n",
    "if not jumbo_target.empty:\n",
    "    print(\"\\n📋 JUMBO.AE TARGET DATA:\")\n",
    "    display(jumbo_target.round(2))\n",
    "\n",
    "# Test 3: EA only\n",
    "ea_target = process_target_data_by_week_and_channel('EA')\n",
    "if not ea_target.empty:\n",
    "    print(\"\\n📋 EA TARGET DATA:\")\n",
    "    display(ea_target.round(2))\n",
    "\n",
    "print(\"\\n=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf20411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first sheet info\n",
    "first_path, first_sheet, first_display = sheet_info[0]\n",
    "\n",
    "# Read and process the data\n",
    "df = pd.read_excel(first_path, sheet_name=first_sheet)\n",
    "\n",
    "# Filter out unwanted IDG values and create pivot table\n",
    "filtered_df = df[~df['idg'].isin(['FOC', 'Remove', 'WRT'])].copy()\n",
    "filtered_df['InvoiceDay'] = pd.to_datetime(filtered_df['InvoiceDate'], dayfirst=True, errors='coerce').dt.day\n",
    "\n",
    "# Create comprehensive IDG pivot table function for reusability\n",
    "\n",
    "def process_sheet_data_by_type(path, sheet_name, display_name, type_filter=None):\n",
    "    \"\"\"Process a single sheet and return IDG pivot by week, optionally filtered by TYPE\"\"\"\n",
    "    df = pd.read_excel(path, sheet_name=sheet_name)\n",
    "    filtered_df = df[~df['idg'].isin(['FOC', 'Remove', 'WRT'])].copy()\n",
    "    \n",
    "    # Apply TYPE filter if specified\n",
    "    if type_filter:\n",
    "        # Map CC to Jumbo.ae first\n",
    "        filtered_df['TYPE'] = filtered_df['TYPE'].replace('CC', 'Jumbo.ae')\n",
    "        filtered_df = filtered_df[filtered_df['TYPE'] == type_filter]\n",
    "    \n",
    "    filtered_df['InvoiceDay'] = pd.to_datetime(filtered_df['InvoiceDate'], dayfirst=True, errors='coerce').dt.day\n",
    "\n",
    "    original_len = len(filtered_df)\n",
    "    filtered_df = filtered_df[filtered_df['InvoiceDay'] <= max_invoice_day]\n",
    "    print(f\"📉 {display_name}: Filtered {original_len - len(filtered_df)} rows with InvoiceDay > {max_invoice_day}\")\n",
    "    \n",
    "    # Add week number calculation using simplified function\n",
    "    filtered_df['WeekNumber'] = filtered_df['InvoiceDay'].apply(\n",
    "        lambda day: get_week_number(day, first_day_position)\n",
    "    )\n",
    "    \n",
    "    # Create pivot table with IDG on rows and weeks on columns\n",
    "    idg_pivot = filtered_df.pivot_table(\n",
    "        values='Amount Invoiced W.O. VAT',\n",
    "        index='idg',\n",
    "        columns='WeekNumber',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    return idg_pivot\n",
    "\n",
    "def create_comprehensive_pivot_table(sheet_info, periods, type_filter=None, table_name=\"IDG\"):\n",
    "    \"\"\"Create a comprehensive pivot table with weeks as super columns and periods as sub-columns, including target data\"\"\"\n",
    "    \n",
    "    print(f\"\\n🔄 Creating {table_name} Pivot Table with Target Data\")\n",
    "    print(f\"🏷️ Type Filter: {type_filter or 'None (All Types)'}\")\n",
    "    \n",
    "    # Process target data based on type filter\n",
    "    # Map type_filter to appropriate channel for target data\n",
    "    target_channel_filter = None\n",
    "    if type_filter == \"EA\":\n",
    "        target_channel_filter = \"EA\"\n",
    "    elif type_filter == \"Jumbo.ae\":\n",
    "        target_channel_filter = \"Jumbo.ae\"\n",
    "    # For Overall analysis (type_filter=None), we use all channels\n",
    "    \n",
    "    print(f\"🎯 Processing target data with channel filter: {target_channel_filter or 'ALL CHANNELS'}\")\n",
    "    target_by_week = process_target_data_by_week_and_channel(target_channel_filter)\n",
    "    \n",
    "    # Process all sheets with optional TYPE filter\n",
    "    # Using display_name as the key in the dictionary instead of sheet_name\n",
    "    sheet_data = {}\n",
    "    for path, sheet_name, display_name in sheet_info:\n",
    "        print(f\"📄 Processing {display_name} data...\")\n",
    "        sheet_data[display_name] = process_sheet_data_by_type(path, sheet_name, display_name, type_filter)\n",
    "    \n",
    "    # Get all unique IDG values across all sheets and target data\n",
    "    all_idgs = set()\n",
    "    for data in sheet_data.values():\n",
    "        all_idgs.update(data.index)\n",
    "    \n",
    "    # Add IDGs from target data if available\n",
    "    if not target_by_week.empty:\n",
    "        all_idgs.update(target_by_week.columns)\n",
    "        print(f\"🎯 Target IDGs found: {list(target_by_week.columns)}\")\n",
    "    else:\n",
    "        print(f\"⚠️ No target data available for filter: {target_channel_filter}\")\n",
    "    \n",
    "    all_idgs = sorted(list(all_idgs))\n",
    "    print(f\"📋 Combined IDGs: {all_idgs}\")\n",
    "    \n",
    "    # Calculate maximum week number across all data\n",
    "    max_week = 1\n",
    "    for data in sheet_data.values():\n",
    "        if len(data.columns) > 0:\n",
    "            max_week = max(max_week, max(data.columns))\n",
    "    \n",
    "    if not target_by_week.empty and len(target_by_week.index) > 0:\n",
    "        max_week = max(max_week, max(target_by_week.index))\n",
    "    \n",
    "    print(f\"📅 Maximum week number: {max_week}\")\n",
    "    \n",
    "    # Create the comprehensive pivot table\n",
    "    weeks = list(range(1, max_week + 1))\n",
    "    \n",
    "    # Create multi-level column index with target, comparison columns and totals\n",
    "    # Order: Last Month, Last Year, Target, Current Month, vs Target %, vs Last Year %, vs Last Month %\n",
    "    column_tuples = []\n",
    "    for week in weeks:\n",
    "        week_label = get_week_label(week)\n",
    "        # Add period columns in specific order\n",
    "        column_tuples.append((week_label, LAST_MONTH_DISPLAY))\n",
    "        column_tuples.append((week_label, LAST_YEAR_DISPLAY))\n",
    "        column_tuples.append((week_label, 'Target'))\n",
    "        column_tuples.append((week_label, CURRENT_DISPLAY))\n",
    "        # Add comparison columns\n",
    "        column_tuples.append((week_label, 'v/s Target %'))\n",
    "        column_tuples.append((week_label, 'v/s Last Year %'))\n",
    "        column_tuples.append((week_label, 'v/s Last Month %'))\n",
    "    # Add Total columns in same order\n",
    "    column_tuples.append(('Total', LAST_MONTH_DISPLAY))\n",
    "    column_tuples.append(('Total', LAST_YEAR_DISPLAY))\n",
    "    column_tuples.append(('Total', 'Target'))\n",
    "    column_tuples.append(('Total', CURRENT_DISPLAY))\n",
    "    column_tuples.append(('Total', 'v/s Target %'))\n",
    "    column_tuples.append(('Total', 'v/s Last Year %'))\n",
    "    column_tuples.append(('Total', 'v/s Last Month %'))\n",
    "    \n",
    "    multi_columns = pd.MultiIndex.from_tuples(column_tuples, names=['Week', 'Period'])\n",
    "    \n",
    "    # Create the final dataframe\n",
    "    final_df = pd.DataFrame(index=all_idgs, columns=multi_columns)\n",
    "    \n",
    "    # Fill the dataframe with data and calculate comparisons\n",
    "    for idg in all_idgs:\n",
    "        for week in weeks:\n",
    "            week_label = get_week_label(week)\n",
    "            \n",
    "            # Fill period data\n",
    "            for period in periods:\n",
    "                if period in sheet_data and idg in sheet_data[period].index and week in sheet_data[period].columns:\n",
    "                    final_df.loc[idg, (week_label, period)] = sheet_data[period].loc[idg, week]\n",
    "                else:\n",
    "                    final_df.loc[idg, (week_label, period)] = 0\n",
    "            \n",
    "            # Fill target data\n",
    "            if not target_by_week.empty and week in target_by_week.index and idg in target_by_week.columns:\n",
    "                final_df.loc[idg, (week_label, 'Target')] = target_by_week.loc[week, idg]\n",
    "            else:\n",
    "                final_df.loc[idg, (week_label, 'Target')] = 0\n",
    "            \n",
    "            # Calculate comparison percentages for each IDG and week\n",
    "            current_val = final_df.loc[idg, (week_label, CURRENT_DISPLAY)]\n",
    "            last_year_val = final_df.loc[idg, (week_label, LAST_YEAR_DISPLAY)]\n",
    "            last_month_val = final_df.loc[idg, (week_label, LAST_MONTH_DISPLAY)]\n",
    "            target_val = final_df.loc[idg, (week_label, 'Target')]\n",
    "            \n",
    "            # v/s Target %\n",
    "            if target_val != 0:\n",
    "                vs_target = (current_val / target_val * 100)  # Changed formula\n",
    "                final_df.loc[idg, (week_label, 'v/s Target %')] = round(vs_target, 2)\n",
    "            else:\n",
    "                final_df.loc[idg, (week_label, 'v/s Target %')] = 0 if current_val == 0 else float('inf') # Or handle as per requirement for 0 target\n",
    "            \n",
    "            # v/s Last Year %\n",
    "            if last_year_val != 0:\n",
    "                vs_last_year = ((current_val - last_year_val) / last_year_val * 100)\n",
    "                final_df.loc[idg, (week_label, 'v/s Last Year %')] = round(vs_last_year, 2)\n",
    "            else:\n",
    "                final_df.loc[idg, (week_label, 'v/s Last Year %')] = 0 if current_val == 0 else float('inf')\n",
    "            \n",
    "            # v/s Last Month %\n",
    "            if last_month_val != 0:\n",
    "                vs_last_month = ((current_val - last_month_val) / last_month_val * 100)\n",
    "                final_df.loc[idg, (week_label, 'v/s Last Month %')] = round(vs_last_month, 2)\n",
    "            else:\n",
    "                final_df.loc[idg, (week_label, 'v/s Last Month %')] = 0 if current_val == 0 else float('inf')\n",
    "    \n",
    "    # Fill NaN values with 0\n",
    "    final_df = final_df.fillna(0)\n",
    "    \n",
    "    # Calculate Total columns for each IDG\n",
    "    for idg in all_idgs:\n",
    "        # Calculate totals for each period across all weeks\n",
    "        for period in periods:\n",
    "            period_cols = [col for col in final_df.columns if col[1] == period and col[0] != 'Total']\n",
    "            total_value = final_df.loc[idg, period_cols].sum()\n",
    "            final_df.loc[idg, ('Total', period)] = total_value\n",
    "        \n",
    "        # Calculate total for target\n",
    "        target_cols = [col for col in final_df.columns if col[1] == 'Target' and col[0] != 'Total']\n",
    "        total_target = final_df.loc[idg, target_cols].sum()\n",
    "        final_df.loc[idg, ('Total', 'Target')] = total_target\n",
    "        \n",
    "        # Calculate total comparison percentages\n",
    "        total_current = final_df.loc[idg, ('Total', CURRENT_DISPLAY)]\n",
    "        total_last_year = final_df.loc[idg, ('Total', LAST_YEAR_DISPLAY)]\n",
    "        total_last_month = final_df.loc[idg, ('Total', LAST_MONTH_DISPLAY)]\n",
    "        total_target = final_df.loc[idg, ('Total', 'Target')]\n",
    "        \n",
    "        # Total v/s Target %\n",
    "        if total_target != 0:\n",
    "            total_vs_target = (total_current / total_target * 100)  # Changed formula\n",
    "            final_df.loc[idg, ('Total', 'v/s Target %')] = round(total_vs_target, 2)\n",
    "        else:\n",
    "            final_df.loc[idg, ('Total', 'v/s Target %')] = 0 if total_current == 0 else float('inf') # Or handle as per requirement for 0 target\n",
    "        \n",
    "        # Total v/s Last Year %\n",
    "        if total_last_year != 0:\n",
    "            total_vs_last_year = ((total_current - total_last_year) / total_last_year * 100)\n",
    "            final_df.loc[idg, ('Total', 'v/s Last Year %')] = round(total_vs_last_year, 2)\n",
    "        else:\n",
    "            final_df.loc[idg, ('Total', 'v/s Last Year %')] = 0 if total_current == 0 else float('inf')\n",
    "        \n",
    "        # Total v/s Last Month %\n",
    "        if total_last_month != 0:\n",
    "            total_vs_last_month = ((total_current - total_last_month) / total_last_month * 100)\n",
    "            final_df.loc[idg, ('Total', 'v/s Last Month %')] = round(total_vs_last_month, 2)\n",
    "        else:\n",
    "            final_df.loc[idg, ('Total', 'v/s Last Month %')] = 0 if total_current == 0 else float('inf')\n",
    "    \n",
    "    # Add Total row for all IDGs combined\n",
    "    total_row_data = {}\n",
    "    for col in final_df.columns:\n",
    "        if 'v/s' in col[1]:  # For percentage columns, calculate weighted averages\n",
    "            if col[1] in ['v/s Target %', 'v/s Last Year %', 'v/s Last Month %']:\n",
    "                # Calculate overall percentage for the total row\n",
    "                if col[0] == 'Total':  # Total column\n",
    "                    total_current = final_df[('Total', CURRENT_DISPLAY)].sum()\n",
    "                    total_base = 0\n",
    "                    if col[1] == 'v/s Target %':\n",
    "                        total_base = final_df[('Total', 'Target')].sum()\n",
    "                    elif col[1] == 'v/s Last Year %':\n",
    "                        total_base = final_df[('Total', LAST_YEAR_DISPLAY)].sum()\n",
    "                    else:  # v/s Last Month %\n",
    "                        total_base = final_df[('Total', LAST_MONTH_DISPLAY)].sum()\n",
    "                    \n",
    "                    if total_base != 0:\n",
    "                        if col[1] == 'v/s Target %':\n",
    "                            total_percentage = (total_current / total_base * 100) # Changed formula\n",
    "                        else:\n",
    "                            total_percentage = ((total_current - total_base) / total_base * 100)\n",
    "                        total_row_data[col] = round(total_percentage, 2)\n",
    "                    else:\n",
    "                        total_row_data[col] = 0\n",
    "                else:  # Week-wise percentage columns\n",
    "                    week_label = col[0]\n",
    "                    week_current = final_df[(week_label, CURRENT_DISPLAY)].sum()\n",
    "                    week_base = 0\n",
    "                    if col[1] == 'v/s Target %':\n",
    "                        week_base = final_df[(week_label, 'Target')].sum()\n",
    "                    elif col[1] == 'v/s Last Year %':\n",
    "                        week_base = final_df[(week_label, LAST_YEAR_DISPLAY)].sum()\n",
    "                    else:  # v/s Last Month %\n",
    "                        week_base = final_df[(week_label, LAST_MONTH_DISPLAY)].sum()\n",
    "                    \n",
    "                    if week_base != 0:\n",
    "                        if col[1] == 'v/s Target %':\n",
    "                            week_percentage = (week_current / week_base * 100) # Changed formula\n",
    "                        else:\n",
    "                            week_percentage = ((week_current - week_base) / week_base * 100)\n",
    "                        total_row_data[col] = round(week_percentage, 2)\n",
    "                    else:\n",
    "                        total_row_data[col] = 0\n",
    "        else:\n",
    "            # For amount columns, sum all IDGs\n",
    "            total_row_data[col] = final_df[col].sum()\n",
    "    \n",
    "    # Create total row as a DataFrame and concatenate\n",
    "    total_row_df = pd.DataFrame([total_row_data], index=['Total'])\n",
    "    final_df = pd.concat([final_df, total_row_df])\n",
    "    \n",
    "    print(f\"✅ {table_name} pivot table created successfully!\")\n",
    "    print(f\"📊 Final shape: {final_df.shape}\")\n",
    "    \n",
    "    return final_df, all_idgs, max_week\n",
    "\n",
    "# Create three pivot tables: Overall, EA only, and Jumbo.ae only with Target Data\n",
    "print(\"🔄 Creating Multiple Pivot Tables WITH TARGET DATA AND PROPER FILTERING...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Overall IDG Pivot Table (all data)\n",
    "print(\"\\n📊 1. OVERALL IDG ANALYSIS (All Types) - WITH TARGET DATA\")\n",
    "print(\"-\" * 55)\n",
    "global_idg_pivot, all_idgs_global, max_week_global = create_comprehensive_pivot_table(\n",
    "    sheet_info, periods, type_filter=None, table_name=\"Overall IDG\"\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 Data Shape: {global_idg_pivot.shape}\")\n",
    "print(f\"🏷️ IDG Categories: {len(all_idgs_global)} (+ Total row)\")\n",
    "print(f\"📅 Periods: {periods} + Target + Comparisons\")\n",
    "print(f\"📋 Weeks analyzed: {max_week_global} (Starting day: {start_day}) + Total column\")\n",
    "\n",
    "# Summary statistics by period for overall\n",
    "print(\"\\n📊 SUMMARY BY PERIOD (Overall):\")\n",
    "for period in periods:\n",
    "    period_total = global_idg_pivot.loc['Total', ('Total', period)]\n",
    "    print(f\"  {period}: {period_total:,.2f}\")\n",
    "target_total = global_idg_pivot.loc['Total', ('Total', 'Target')]\n",
    "print(f\"  Target: {target_total:,.2f}\")\n",
    "\n",
    "print(\"\\n📋 Overall IDG Pivot Table (with Target):\")\n",
    "display(global_idg_pivot.round(2))\n",
    "\n",
    "# 2. EA Only Pivot Table\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"📊 2. EA ONLY ANALYSIS - WITH TARGET DATA\")\n",
    "print(\"-\" * 45)\n",
    "ea_idg_pivot, all_idgs_ea, max_week_ea = create_comprehensive_pivot_table(\n",
    "    sheet_info, periods, type_filter=\"EA\", table_name=\"EA IDG\"\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 Data Shape: {ea_idg_pivot.shape}\")\n",
    "print(f\"🏷️ IDG Categories: {len(all_idgs_ea)} (+ Total row)\")\n",
    "print(f\"📅 Periods: {periods} + Target + Comparisons\")\n",
    "print(f\"📋 Weeks analyzed: {max_week_ea} (Starting day: {start_day}) + Total column\")\n",
    "\n",
    "# Summary statistics by period for EA\n",
    "print(\"\\n📊 SUMMARY BY PERIOD (EA Only):\")\n",
    "for period in periods:\n",
    "    period_total = ea_idg_pivot.loc['Total', ('Total', period)]\n",
    "    print(f\"  {period}: {period_total:,.2f}\")\n",
    "target_total_ea = ea_idg_pivot.loc['Total', ('Total', 'Target')]\n",
    "print(f\"  Target: {target_total_ea:,.2f}\")\n",
    "\n",
    "print(\"\\n📋 EA Only IDG Pivot Table (with Target):\")\n",
    "display(ea_idg_pivot.round(2))\n",
    "\n",
    "# 3. Jumbo.ae Only Pivot Table\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"📊 3. JUMBO.AE ONLY ANALYSIS - WITH TARGET DATA\")\n",
    "print(\"-\" * 50)\n",
    "jumbo_idg_pivot, all_idgs_jumbo, max_week_jumbo = create_comprehensive_pivot_table(\n",
    "    sheet_info, periods, type_filter=\"Jumbo.ae\", table_name=\"Jumbo.ae IDG\"\n",
    ")\n",
    "\n",
    "print(f\"\\n📊 Data Shape: {jumbo_idg_pivot.shape}\")\n",
    "print(f\"🏷️ IDG Categories: {len(all_idgs_jumbo)} (+ Total row)\")\n",
    "print(f\"📅 Periods: {periods} + Target + Comparisons\")\n",
    "print(f\"📋 Weeks analyzed: {max_week_jumbo} (Starting day: {start_day}) + Total column\")\n",
    "\n",
    "# Summary statistics by period for Jumbo.ae\n",
    "print(\"\\n📊 SUMMARY BY PERIOD (Jumbo.ae Only):\")\n",
    "for period in periods:\n",
    "    period_total = jumbo_idg_pivot.loc['Total', ('Total', period)]\n",
    "    print(f\"  {period}: {period_total:,.2f}\")\n",
    "target_total_jumbo = jumbo_idg_pivot.loc['Total', ('Total', 'Target')]\n",
    "print(f\"  Target: {target_total_jumbo:,.2f}\")\n",
    "\n",
    "print(\"\\n📋 Jumbo.ae Only IDG Pivot Table (with Target):\")\n",
    "display(jumbo_idg_pivot.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✅ ALL PIVOT TABLES WITH TARGET DATA CREATED SUCCESSFULLY!\")\n",
    "print(\"📊 Summary:\")\n",
    "print(f\"   • Overall Analysis: {len(all_idgs_global)} IDGs, {max_week_global} weeks\")\n",
    "print(f\"   • EA Analysis: {len(all_idgs_ea)} IDGs, {max_week_ea} weeks\")\n",
    "print(f\"   • Jumbo.ae Analysis: {len(all_idgs_jumbo)} IDGs, {max_week_jumbo} weeks\")\n",
    "print(f\"   • Each table includes: {len(periods)} periods + Target + vs Target % + comparisons + totals\")\n",
    "print(f\"   • Column order: Last Month, Last Year, Target, Current Month, vs Target %, vs Last Year %, vs Last Month %\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02896dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDG Analysis Report - Multiple Pivot Tables\n",
    "\n",
    "# Additional pivot table views for all three analyses\n",
    "\n",
    "# Weekly Analysis Views\n",
    "\n",
    "# 1. Show first few weeks detailed view for Overall analysis\n",
    "print(\"📊 OVERALL ANALYSIS - First 3 Weeks IDG Data\")\n",
    "print(\"=\" * 50)\n",
    "first_weeks_cols = []\n",
    "for week in range(1, min(4, max_week_global + 1)):  # First 3 weeks or max available\n",
    "    week_label = get_week_label(week)\n",
    "    for period in periods:  # Use dynamic periods instead of hardcoded values\n",
    "        first_weeks_cols.append((week_label, period))\n",
    "\n",
    "if first_weeks_cols:  # Only if we have data\n",
    "    first_weeks_data = global_idg_pivot[first_weeks_cols]\n",
    "    display(first_weeks_data.round(2))\n",
    "else:\n",
    "    print(\"No week data available\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "# 2. Weekly totals comparison for Overall analysis\n",
    "print(\"📈 OVERALL ANALYSIS - Weekly Totals Comparison\")\n",
    "print(\"=\" * 45)\n",
    "weekly_totals = pd.DataFrame(index=range(1, max_week_global + 1), columns=periods)  # Use dynamic periods\n",
    "\n",
    "for week in range(1, max_week_global + 1):\n",
    "    week_label = get_week_label(week)\n",
    "    for period in periods:  # Use dynamic periods\n",
    "        week_period_cols = [(week_label, period)]\n",
    "        weekly_total = global_idg_pivot[week_period_cols].sum().sum()\n",
    "        weekly_totals.loc[week, period] = weekly_total\n",
    "\n",
    "# Convert to numeric and add growth percentages\n",
    "weekly_totals = weekly_totals.astype(float)\n",
    "weekly_totals['Current_vs_LastYear_%'] = ((weekly_totals[CURRENT_DISPLAY] - weekly_totals[LAST_YEAR_DISPLAY]) / weekly_totals[LAST_YEAR_DISPLAY] * 100).round(2)\n",
    "weekly_totals['Current_vs_LastMonth_%'] = ((weekly_totals[CURRENT_DISPLAY] - weekly_totals[LAST_MONTH_DISPLAY]) / weekly_totals[LAST_MONTH_DISPLAY] * 100).round(2)\n",
    "\n",
    "# Add week labels for better readability\n",
    "weekly_totals.index = [get_week_label(week) for week in range(1, max_week_global + 1)]\n",
    "\n",
    "display(weekly_totals.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "# 3. IDG totals by period (summary pivot) for Overall analysis\n",
    "print(\"📋 OVERALL ANALYSIS - IDG Totals by Period (Week-based)\")\n",
    "print(\"=\" * 55)\n",
    "idg_period_summary = pd.DataFrame(index=all_idgs_global, columns=periods)  # Use dynamic periods\n",
    "\n",
    "for idg in all_idgs_global:\n",
    "    for period in periods:  # Use dynamic periods\n",
    "        period_cols = [col for col in global_idg_pivot.columns if col[1] == period]\n",
    "        idg_period_summary.loc[idg, period] = global_idg_pivot.loc[idg, period_cols].sum()\n",
    "\n",
    "# Convert to numeric and add totals\n",
    "idg_period_summary = idg_period_summary.astype(float)\n",
    "idg_period_summary['Total'] = idg_period_summary.sum(axis=1)\n",
    "idg_period_summary.loc['Total'] = idg_period_summary.sum()\n",
    "\n",
    "display(idg_period_summary.round(2))\n",
    "\n",
    "# 4. Quick comparison between the three analyses\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"📊 COMPARISON SUMMARY - All Three Analyses\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create summary comparison\n",
    "comparison_summary = pd.DataFrame({\n",
    "    'Analysis_Type': ['Overall', 'EA Only', 'Jumbo.ae Only'],\n",
    "    'IDG_Count': [len(all_idgs_global), len(all_idgs_ea), len(all_idgs_jumbo)],\n",
    "    'Max_Weeks': [max_week_global, max_week_ea, max_week_jumbo]\n",
    "})\n",
    "\n",
    "# Add period totals for each analysis\n",
    "for period in periods:\n",
    "    comparison_summary[f'{period}_Total'] = [\n",
    "        global_idg_pivot.loc['Total', ('Total', period)],\n",
    "        ea_idg_pivot.loc['Total', ('Total', period)],\n",
    "        jumbo_idg_pivot.loc['Total', ('Total', period)]\n",
    "    ]\n",
    "\n",
    "print(\"Summary of All Three Pivot Table Analyses:\")\n",
    "display(comparison_summary.round(2))\n",
    "\n",
    "print(\"\\n📈 Key Insights:\")\n",
    "print(f\"• Overall analysis covers {len(all_idgs_global)} IDG categories across {max_week_global} weeks\")\n",
    "print(f\"• EA analysis covers {len(all_idgs_ea)} IDG categories across {max_week_ea} weeks\")\n",
    "print(f\"• Jumbo.ae analysis covers {len(all_idgs_jumbo)} IDG categories across {max_week_jumbo} weeks\")\n",
    "print(f\"• Each analysis includes {len(periods)} periods: {', '.join(periods)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly Comparison Analysis - Focused View for All Three Analyses\n",
    "print(\"📊 COMPREHENSIVE GROWTH COMPARISON ANALYSIS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "def analyze_growth_patterns(pivot_table, all_idgs, max_week, analysis_name):\n",
    "    \"\"\"Analyze growth patterns for a given pivot table\"\"\"\n",
    "    print(f\"\\n🔍 {analysis_name.upper()} ANALYSIS - Growth Patterns\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Create a focused view showing only comparison percentages\n",
    "    comparison_cols = []\n",
    "    for week in range(1, max_week + 1):\n",
    "        week_label = get_week_label(week)\n",
    "        comparison_cols.extend([\n",
    "            (week_label, 'v/s Last Year %'),\n",
    "            (week_label, 'v/s Last Month %')\n",
    "        ])\n",
    "    \n",
    "    if comparison_cols:\n",
    "        comparison_data = pivot_table[comparison_cols]\n",
    "        print(f\"\\n📈 {analysis_name} - Growth Percentages by Week:\")\n",
    "        display(comparison_data.round(2))\n",
    "        \n",
    "        # Calculate average growth rates\n",
    "        print(f\"\\n📊 {analysis_name} - Average Growth Rates Across All Weeks:\")\n",
    "        print(\"-\" * 45)\n",
    "        \n",
    "        # Get all v/s Last Year columns\n",
    "        last_year_cols = [col for col in comparison_data.columns if 'v/s Last Year %' in col[1]]\n",
    "        last_month_cols = [col for col in comparison_data.columns if 'v/s Last Month %' in col[1]]\n",
    "        \n",
    "        for idg in all_idgs:\n",
    "            avg_vs_last_year = comparison_data.loc[idg, last_year_cols].replace([float('inf'), -float('inf')], 0).mean()\n",
    "            avg_vs_last_month = comparison_data.loc[idg, last_month_cols].replace([float('inf'), -float('inf')], 0).mean()\n",
    "            print(f\"{idg:15s} | Avg vs Last Year: {avg_vs_last_year:6.1f}% | Avg vs Last Month: {avg_vs_last_month:6.1f}%\")\n",
    "        \n",
    "        # Weekly summary of overall performance\n",
    "        print(f\"\\n📋 {analysis_name} - Weekly Performance Summary (All IDGs Combined):\")\n",
    "        print(\"-\" * 55)\n",
    "        \n",
    "        weekly_performance = pd.DataFrame(index=range(1, max_week + 1), \n",
    "                                        columns=['vs_Last_Year_%', 'vs_Last_Month_%'])\n",
    "        \n",
    "        for week in range(1, max_week + 1):\n",
    "            week_label = get_week_label(week)\n",
    "            \n",
    "            # Calculate total amounts for the week using dynamic period names\n",
    "            current_total = pivot_table[(week_label, CURRENT_DISPLAY)].sum()\n",
    "            last_year_total = pivot_table[(week_label, LAST_YEAR_DISPLAY)].sum()\n",
    "            last_month_total = pivot_table[(week_label, LAST_MONTH_DISPLAY)].sum()\n",
    "            \n",
    "            # Calculate overall percentage changes\n",
    "            if last_year_total != 0:\n",
    "                vs_last_year = ((current_total - last_year_total) / last_year_total * 100)\n",
    "                weekly_performance.loc[week, 'vs_Last_Year_%'] = round(vs_last_year, 2)\n",
    "            else:\n",
    "                weekly_performance.loc[week, 'vs_Last_Year_%'] = 0\n",
    "                \n",
    "            if last_month_total != 0:\n",
    "                vs_last_month = ((current_total - last_month_total) / last_month_total * 100)\n",
    "                weekly_performance.loc[week, 'vs_Last_Month_%'] = round(vs_last_month, 2)\n",
    "            else:\n",
    "                weekly_performance.loc[week, 'vs_Last_Month_%'] = 0\n",
    "        \n",
    "        # Add week labels for better readability\n",
    "        weekly_performance.index = [get_week_label(week) for week in range(1, max_week + 1)]\n",
    "        \n",
    "        display(weekly_performance)\n",
    "        \n",
    "        return weekly_performance\n",
    "    else:\n",
    "        print(f\"No comparison data available for {analysis_name}\")\n",
    "        return None\n",
    "\n",
    "# Analyze all three pivot tables\n",
    "overall_performance = analyze_growth_patterns(global_idg_pivot, all_idgs_global, max_week_global, \"Overall\")\n",
    "ea_performance = analyze_growth_patterns(ea_idg_pivot, all_idgs_ea, max_week_ea, \"EA Only\")\n",
    "jumbo_performance = analyze_growth_patterns(jumbo_idg_pivot, all_idgs_jumbo, max_week_jumbo, \"Jumbo.ae Only\")\n",
    "\n",
    "# Cross-analysis comparison\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"🔄 CROSS-ANALYSIS PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if overall_performance is not None and ea_performance is not None and jumbo_performance is not None:\n",
    "    # Compare average performance across all analyses\n",
    "    cross_comparison = pd.DataFrame({\n",
    "        'Analysis': ['Overall', 'EA Only', 'Jumbo.ae Only'],\n",
    "        'Avg_Growth_vs_Last_Year_%': [\n",
    "            overall_performance['vs_Last_Year_%'].mean(),\n",
    "            ea_performance['vs_Last_Year_%'].mean(),\n",
    "            jumbo_performance['vs_Last_Year_%'].mean()\n",
    "        ],\n",
    "        'Avg_Growth_vs_Last_Month_%': [\n",
    "            overall_performance['vs_Last_Month_%'].mean(),\n",
    "            ea_performance['vs_Last_Month_%'].mean(),\n",
    "            jumbo_performance['vs_Last_Month_%'].mean()\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(\"📊 Average Growth Rates Comparison:\")\n",
    "    display(cross_comparison.round(2))\n",
    "    \n",
    "    # Best and worst performing analysis types\n",
    "    best_vs_year = cross_comparison.loc[cross_comparison['Avg_Growth_vs_Last_Year_%'].idxmax(), 'Analysis']\n",
    "    best_vs_month = cross_comparison.loc[cross_comparison['Avg_Growth_vs_Last_Month_%'].idxmax(), 'Analysis']\n",
    "    \n",
    "    print(f\"\\n✅ Performance Highlights:\")\n",
    "    print(f\"• Best performing vs Last Year: {best_vs_year}\")\n",
    "    print(f\"• Best performing vs Last Month: {best_vs_month}\")\n",
    "else:\n",
    "    print(\"Could not complete cross-analysis comparison\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"✅ COMPREHENSIVE GROWTH ANALYSIS COMPLETE\")\n",
    "print(\"📊 All three pivot tables analyzed for growth patterns\")\n",
    "print(\"📈 Weekly performance trends calculated and compared\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cec4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export All IDG Pivot Tables to Excel - Combined in Single Sheet\n",
    "print(\"📤 EXPORTING ALL THREE PIVOT TABLES TO SINGLE EXCEL SHEET...\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Create Excel writer object\n",
    "output_file = 'IDG_Weekly_Analysis_Combined.xlsx'\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    \n",
    "    # Create combined sheet with all three analyses\n",
    "    print(\"📊 Creating Combined IDG Analysis Sheet...\")\n",
    "    \n",
    "    # Create a workbook and worksheet - ensure we have a proper worksheet\n",
    "    workbook = writer.book\n",
    "    # Remove default sheet if it exists\n",
    "    if workbook.worksheets:\n",
    "        workbook.remove(workbook.active)\n",
    "    \n",
    "    # Create our main worksheet\n",
    "    worksheet = workbook.create_sheet('Combined_IDG_Analysis', 0)\n",
    "    \n",
    "    # Define styles for different sections\n",
    "    main_title_font = Font(bold=True, size=14, color='FFFFFF')\n",
    "    main_title_fill = PatternFill(start_color='1F4E79', end_color='1F4E79', fill_type='solid')\n",
    "    \n",
    "    section_header_font = Font(bold=True, size=12, color='FFFFFF')\n",
    "    section_header_fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')\n",
    "    \n",
    "    column_header_font = Font(bold=True, size=10, color='FFFFFF')\n",
    "    column_header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')\n",
    "    \n",
    "    idg_name_font = Font(bold=True, size=9)\n",
    "    idg_name_fill = PatternFill(start_color='F2F2F2', end_color='F2F2F2', fill_type='solid')\n",
    "    \n",
    "    total_row_font = Font(bold=True, size=10)\n",
    "    total_row_fill = PatternFill(start_color='FFE699', end_color='FFE699', fill_type='solid')\n",
    "    \n",
    "    subheader_font = Font(bold=True, size=9, color='FFFFFF')\n",
    "    subheader_fill = PatternFill(start_color='5B9BD5', end_color='5B9BD5', fill_type='solid')\n",
    "    \n",
    "    row_header_font = Font(bold=True, size=9)\n",
    "    row_header_fill = PatternFill(start_color='E7E6E6', end_color='E7E6E6', fill_type='solid')\n",
    "    \n",
    "    number_format = '#,##0.00'\n",
    "    thin_border = Border(\n",
    "        left=Side(style='thin'), right=Side(style='thin'),\n",
    "        top=Side(style='thin'), bottom=Side(style='thin')\n",
    "    )\n",
    "    \n",
    "    # Function to write monthly total data (just Total column) to a dedicated worksheet\n",
    "    def write_monthly_total_to_sheet(pivot_df, analysis_title, worksheet):\n",
    "        # Extract only the Total column data\n",
    "        total_data = pivot_df[\"Total\"]\n",
    "        \n",
    "        # Section title for the sheet\n",
    "        worksheet.cell(row=1, column=1, value=analysis_title)\n",
    "        title_cell = worksheet.cell(row=1, column=1)\n",
    "        title_cell.font = section_header_font\n",
    "        title_cell.fill = section_header_fill\n",
    "        title_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "        \n",
    "        # Merge cells for the title across all columns\n",
    "        num_cols = len(total_data.columns)\n",
    "        worksheet.merge_cells(start_row=1, start_column=1, \n",
    "                            end_row=1, end_column=num_cols + 1) # +1 for the IDG column\n",
    "        \n",
    "        # Apply border to title\n",
    "        for col_idx_merge in range(1, num_cols + 2):\n",
    "            worksheet.cell(row=1, column=col_idx_merge).border = thin_border\n",
    "        \n",
    "        current_row = 2 # Start headers from row 2\n",
    "        \n",
    "        # Write column headers - just \"IDG\" and the period names from Total\n",
    "        worksheet.cell(row=current_row, column=1, value=\"IDG\")\n",
    "        idg_header_cell = worksheet.cell(row=current_row, column=1)\n",
    "        idg_header_cell.font = column_header_font\n",
    "        idg_header_cell.fill = column_header_fill\n",
    "        idg_header_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "        idg_header_cell.border = thin_border\n",
    "        \n",
    "        col_idx = 2\n",
    "        for period in total_data.columns:\n",
    "            worksheet.cell(row=current_row, column=col_idx, value=period)\n",
    "            header_cell = worksheet.cell(row=current_row, column=col_idx)\n",
    "            header_cell.font = column_header_font\n",
    "            header_cell.fill = column_header_fill\n",
    "            header_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            header_cell.border = thin_border\n",
    "            col_idx += 1\n",
    "        \n",
    "        current_row += 1\n",
    "        \n",
    "        # Write data rows\n",
    "        for idg_name in total_data.index:\n",
    "            worksheet.cell(row=current_row, column=1, value=idg_name)\n",
    "            name_cell = worksheet.cell(row=current_row, column=1)\n",
    "            if idg_name == 'Total':\n",
    "                name_cell.font = total_row_font\n",
    "                name_cell.fill = total_row_fill\n",
    "            else:\n",
    "                name_cell.font = idg_name_font\n",
    "                name_cell.fill = idg_name_fill\n",
    "            name_cell.alignment = Alignment(horizontal='left', vertical='center')\n",
    "            name_cell.border = thin_border\n",
    "            \n",
    "            col_idx = 2\n",
    "            for period in total_data.columns:\n",
    "                value = total_data.loc[idg_name, period]\n",
    "                worksheet.cell(row=current_row, column=col_idx, value=value)\n",
    "                data_cell = worksheet.cell(row=current_row, column=col_idx)\n",
    "                \n",
    "                if idg_name == 'Total':\n",
    "                    data_cell.font = total_row_font\n",
    "                    data_cell.fill = total_row_fill\n",
    "                else:\n",
    "                    data_cell.font = Font(size=9)\n",
    "                \n",
    "                # Format percentage columns\n",
    "                if 'v/s' in period and '%' in period:\n",
    "                    data_cell.number_format = '0.00\"%\"'\n",
    "                    if isinstance(value, (int, float)) and value != float('inf') and value != float('-inf') and value != 0:\n",
    "                        if period == 'v/s Target %':\n",
    "                            if value >= 100:\n",
    "                                data_cell.font = Font(color='008000', size=9, bold=idg_name=='Total')\n",
    "                            else:\n",
    "                                data_cell.font = Font(color='FF0000', size=9, bold=idg_name=='Total')\n",
    "                        else:\n",
    "                            if value > 0:\n",
    "                                data_cell.font = Font(color='008000', size=9, bold=idg_name=='Total')\n",
    "                            elif value < 0:\n",
    "                                data_cell.font = Font(color='FF0000', size=9, bold=idg_name=='Total')\n",
    "                else:\n",
    "                    data_cell.number_format = number_format\n",
    "                \n",
    "                data_cell.alignment = Alignment(horizontal='right', vertical='center')\n",
    "                data_cell.border = thin_border\n",
    "                col_idx += 1\n",
    "            current_row += 1\n",
    "            \n",
    "        # Auto-adjust column widths for this worksheet\n",
    "        for col_letter_idx in range(1, worksheet.max_column + 1):\n",
    "            max_length = 0\n",
    "            column_letter = get_column_letter(col_letter_idx)\n",
    "            for row_idx in range(1, worksheet.max_row + 1):\n",
    "                try:\n",
    "                    cell_value = str(worksheet.cell(row=row_idx, column=col_letter_idx).value)\n",
    "                    if len(cell_value) > max_length:\n",
    "                        max_length = len(cell_value)\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 2, 30) # Max width of 30\n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "        # Freeze panes for this worksheet (IDG name and headers)\n",
    "        worksheet.freeze_panes = 'B3' # Headers and IDG column frozen\n",
    "    \n",
    "    # MODIFIED Function to write a single pivot table to a dedicated worksheet\n",
    "    def write_pivot_table_to_sheet(pivot_df, analysis_title, worksheet):\n",
    "        # Section title for the sheet\n",
    "        worksheet.cell(row=1, column=1, value=analysis_title)\n",
    "        title_cell = worksheet.cell(row=1, column=1)\n",
    "        title_cell.font = section_header_font # Use section_header_font for individual sheet titles\n",
    "        title_cell.fill = section_header_fill\n",
    "        title_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "        \n",
    "        # Merge cells for the title across all columns of the pivot table\n",
    "        num_cols = len(pivot_df.columns)\n",
    "        worksheet.merge_cells(start_row=1, start_column=1, \n",
    "                            end_row=1, end_column=num_cols + 1) # +1 for the IDG column\n",
    "        \n",
    "        # Apply border to title\n",
    "        for col_idx_merge in range(1, num_cols + 2):\n",
    "            worksheet.cell(row=1, column=col_idx_merge).border = thin_border\n",
    "        \n",
    "        current_row = 2 # Start headers from row 2\n",
    "        \n",
    "        # Write column headers (multi-level)\n",
    "        # First level headers (Week labels)\n",
    "        col_idx = 2  # Start from column 2 (column 1 is for IDG names)\n",
    "        for week_label in pivot_df.columns.get_level_values(0).unique():\n",
    "            week_cols = [col for col in pivot_df.columns if col[0] == week_label]\n",
    "            num_sub_cols = len(week_cols)\n",
    "            \n",
    "            worksheet.cell(row=current_row, column=col_idx, value=week_label)\n",
    "            week_cell = worksheet.cell(row=current_row, column=col_idx)\n",
    "            week_cell.font = column_header_font\n",
    "            week_cell.fill = column_header_fill\n",
    "            week_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            week_cell.border = thin_border\n",
    "            \n",
    "            if num_sub_cols > 1:\n",
    "                worksheet.merge_cells(start_row=current_row, start_column=col_idx,\n",
    "                                    end_row=current_row, end_column=col_idx + num_sub_cols - 1)\n",
    "                for i in range(num_sub_cols):\n",
    "                    cell = worksheet.cell(row=current_row, column=col_idx + i)\n",
    "                    cell.font = column_header_font\n",
    "                    cell.fill = column_header_fill\n",
    "                    cell.border = thin_border\n",
    "            col_idx += num_sub_cols\n",
    "        \n",
    "        current_row += 1\n",
    "        \n",
    "        # Second level headers (Period names)\n",
    "        worksheet.cell(row=current_row, column=1, value=\"IDG\")\n",
    "        idg_header_cell = worksheet.cell(row=current_row, column=1)\n",
    "        idg_header_cell.font = column_header_font\n",
    "        idg_header_cell.fill = column_header_fill\n",
    "        idg_header_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "        idg_header_cell.border = thin_border\n",
    "        \n",
    "        col_idx = 2\n",
    "        for col_multi_idx in pivot_df.columns:\n",
    "            worksheet.cell(row=current_row, column=col_idx, value=col_multi_idx[1])\n",
    "            sub_header_cell = worksheet.cell(row=current_row, column=col_idx)\n",
    "            sub_header_cell.font = column_header_font\n",
    "            sub_header_cell.fill = column_header_fill\n",
    "            sub_header_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            sub_header_cell.border = thin_border\n",
    "            col_idx += 1\n",
    "        \n",
    "        current_row += 1\n",
    "        \n",
    "        # Write data rows\n",
    "        for idg_name in pivot_df.index:\n",
    "            worksheet.cell(row=current_row, column=1, value=idg_name)\n",
    "            name_cell = worksheet.cell(row=current_row, column=1)\n",
    "            if idg_name == 'Total':\n",
    "                name_cell.font = Font(bold=True, size=10)\n",
    "                name_cell.fill = PatternFill(start_color='FFE699', end_color='FFE699', fill_type='solid')\n",
    "            else:\n",
    "                name_cell.font = idg_name_font\n",
    "                name_cell.fill = idg_name_fill\n",
    "            name_cell.alignment = Alignment(horizontal='left', vertical='center')\n",
    "            name_cell.border = thin_border\n",
    "            \n",
    "            col_idx = 2\n",
    "            for col_multi_idx in pivot_df.columns:\n",
    "                value = pivot_df.loc[idg_name, col_multi_idx]\n",
    "                worksheet.cell(row=current_row, column=col_idx, value=value)\n",
    "                data_cell = worksheet.cell(row=current_row, column=col_idx)\n",
    "                \n",
    "                if idg_name == 'Total':\n",
    "                    data_cell.font = Font(bold=True, size=9)\n",
    "                    data_cell.fill = PatternFill(start_color='FFE699', end_color='FFE699', fill_type='solid')\n",
    "                else:\n",
    "                    data_cell.font = Font(size=9)\n",
    "                \n",
    "                if 'v/s' in col_multi_idx[1] and '%' in col_multi_idx[1]:\n",
    "                    data_cell.number_format = '0.00\"%\"'\n",
    "                    if isinstance(value, (int, float)) and value != float('inf') and value != float('-inf') and value != 0 : # Check for valid numeric value\n",
    "                        if col_multi_idx[1] == 'v/s Target %':\n",
    "                            if value >= 100:\n",
    "                                data_cell.font = Font(color='008000', size=9, bold=idg_name=='Total')\n",
    "                            else:\n",
    "                                data_cell.font = Font(color='FF0000', size=9, bold=idg_name=='Total')\n",
    "                        else:\n",
    "                            if value > 0:\n",
    "                                data_cell.font = Font(color='008000', size=9, bold=idg_name=='Total')\n",
    "                            elif value < 0:\n",
    "                                data_cell.font = Font(color='FF0000', size=9, bold=idg_name=='Total')\n",
    "                else:\n",
    "                    data_cell.number_format = number_format\n",
    "                \n",
    "                data_cell.alignment = Alignment(horizontal='right', vertical='center')\n",
    "                data_cell.border = thin_border\n",
    "                col_idx += 1\n",
    "            current_row += 1\n",
    "            \n",
    "        # Auto-adjust column widths for this worksheet\n",
    "        for col_letter_idx in range(1, worksheet.max_column + 1):\n",
    "            max_length = 0\n",
    "            column_letter = get_column_letter(col_letter_idx)\n",
    "            for row_idx in range(1, worksheet.max_row + 1):\n",
    "                try:\n",
    "                    cell_value = str(worksheet.cell(row=row_idx, column=col_letter_idx).value)\n",
    "                    if len(cell_value) > max_length:\n",
    "                        max_length = len(cell_value)\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 2, 30) # Max width of 30, increased padding\n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "        # Freeze panes for this worksheet (IDG name and headers)\n",
    "        # Freeze row 3 (headers) and column 1 (IDG names)\n",
    "        worksheet.freeze_panes = 'B1' # Top 3 rows and 1st column frozen\n",
    "\n",
    "    # Main Excel writing block\n",
    "    # Remove default sheet if it exists\n",
    "    if workbook.worksheets:\n",
    "        workbook.remove(workbook.active)\n",
    "    \n",
    "    # Data for sheets - including both detailed and monthly summary sheets\n",
    "    analyses_to_export = [\n",
    "        {\"name\": \"Overall_IDG_Analysis\", \"title\": f\"OVERALL IDG ANALYSIS ({max_invoice_day} days)\", \"data\": global_idg_pivot, \"type\": \"detailed\"},\n",
    "        {\"name\": \"EA_IDG_Analysis\", \"title\": f\"EA ONLY IDG ANALYSIS ({max_invoice_day} days)\", \"data\": ea_idg_pivot, \"type\": \"detailed\"},\n",
    "        {\"name\": \"JumboAE_IDG_Analysis\", \"title\": f\"JUMBO.AE ONLY IDG ANALYSIS ({max_invoice_day} days)\", \"data\": jumbo_idg_pivot, \"type\": \"detailed\"},\n",
    "        {\"name\": \"Monthly_Overall_IDG_Analysis\", \"title\": f\"MONTHLY OVERALL IDG ANALYSIS ({max_invoice_day} days)\", \"data\": global_idg_pivot, \"type\": \"monthly\"},\n",
    "        {\"name\": \"Monthly_EA_IDG_Analysis\", \"title\": f\"MONTHLY EA ONLY IDG ANALYSIS ({max_invoice_day} days)\", \"data\": ea_idg_pivot, \"type\": \"monthly\"},\n",
    "        {\"name\": \"Monthly_JumboAE_IDG_Analysis\", \"title\": f\"MONTHLY JUMBO.AE ONLY IDG ANALYSIS ({max_invoice_day} days)\", \"data\": jumbo_idg_pivot, \"type\": \"monthly\"},\n",
    "    ]\n",
    "\n",
    "    sheet_idx_counter = 0\n",
    "    for analysis in analyses_to_export:\n",
    "        print(f\"  📊 Writing {analysis['title']} to sheet: {analysis['name']}...\")\n",
    "        ws = workbook.create_sheet(analysis['name'], sheet_idx_counter)\n",
    "        \n",
    "        if analysis['type'] == 'detailed':\n",
    "            write_pivot_table_to_sheet(analysis['data'].round(2), analysis['title'], ws)\n",
    "        elif analysis['type'] == 'monthly':\n",
    "            write_monthly_total_to_sheet(analysis['data'].round(2), analysis['title'], ws)\n",
    "        \n",
    "        sheet_idx_counter += 1\n",
    "    \n",
    "    # Create additional supporting sheets (Summary Dashboard, Weekly Totals)\n",
    "    # These will be created after the individual analysis sheets.\n",
    "    \n",
    "    # 2. Summary Dashboard Sheet\n",
    "    print(\"📊 Creating Summary Dashboard...\")\n",
    "    summary_data = {\n",
    "        'Analysis_Type': ['Overall', 'EA Only', 'Jumbo.ae Only'],\n",
    "        'IDG_Categories': [len(all_idgs_global), len(all_idgs_ea), len(all_idgs_jumbo)],\n",
    "        'Weeks_Analyzed': [max_week_global, max_week_ea, max_week_jumbo]\n",
    "    }\n",
    "    \n",
    "    # Add period totals for each analysis\n",
    "    for period in periods:\n",
    "        summary_data[f'{period}_Total'] = [\n",
    "            global_idg_pivot.loc['Total', ('Total', period)],\n",
    "            ea_idg_pivot.loc['Total', ('Total', period)],\n",
    "            jumbo_idg_pivot.loc['Total', ('Total', period)]\n",
    "        ]\n",
    "    \n",
    "    # Add growth percentages\n",
    "    summary_data[f'Growth_vs_{LAST_YEAR_DISPLAY}_%'] = [\n",
    "        global_idg_pivot.loc['Total', ('Total', 'v/s Last Year %')],\n",
    "        ea_idg_pivot.loc['Total', ('Total', 'v/s Last Year %')],\n",
    "        jumbo_idg_pivot.loc['Total', ('Total', 'v/s Last Year %')]\n",
    "    ]\n",
    "    \n",
    "    summary_data[f'Growth_vs_{LAST_MONTH_DISPLAY}_%'] = [\n",
    "        global_idg_pivot.loc['Total', ('Total', 'v/s Last Month %')],\n",
    "        ea_idg_pivot.loc['Total', ('Total', 'v/s Last Month %')],\n",
    "        jumbo_idg_pivot.loc['Total', ('Total', 'v/s Last Month %')]\n",
    "    ]\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.round(2).to_excel(writer, sheet_name='Summary_Dashboard', index=False)\n",
    "    \n",
    "    # 3. Weekly Totals Summary (Overall)\n",
    "    print(\"📊 Creating Weekly Totals Summary...\")\n",
    "    weekly_totals = pd.DataFrame(index=range(1, max_week_global + 1), columns=periods)\n",
    "    \n",
    "    for week in range(1, max_week_global + 1):\n",
    "        week_label = get_week_label(week)\n",
    "        for period in periods:\n",
    "            week_period_cols = [(week_label, period)]\n",
    "            weekly_total = global_idg_pivot[week_period_cols].sum().sum()\n",
    "            weekly_totals.loc[week, period] = weekly_total\n",
    "    \n",
    "    # Add growth percentages using dynamic period names\n",
    "    weekly_totals = weekly_totals.astype(float)\n",
    "    weekly_totals['Growth_vs_LastYear_%'] = ((weekly_totals[CURRENT_DISPLAY] - weekly_totals[LAST_YEAR_DISPLAY]) / weekly_totals[LAST_YEAR_DISPLAY] * 100).round(2)\n",
    "    weekly_totals['Growth_vs_LastMonth_%'] = ((weekly_totals[CURRENT_DISPLAY] - weekly_totals[LAST_MONTH_DISPLAY]) / weekly_totals[LAST_MONTH_DISPLAY] * 100).round(2)\n",
    "    \n",
    "    # Add week labels\n",
    "    weekly_totals.index = [get_week_label(week) for week in range(1, max_week_global + 1)]\n",
    "    \n",
    "    # Export weekly totals\n",
    "    weekly_totals.round(2).to_excel(writer, sheet_name='Weekly_Totals', index=True)\n",
    "\n",
    "print(f\"\\n✅ EXCEL EXPORT COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"📎 File: {output_file}\")\n",
    "print(\"\\n📊 SHEETS CREATED:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"📄 1. Overall_IDG_Analysis - Overall IDG Analysis table\")\n",
    "print(\"📄 2. EA_IDG_Analysis - EA Only IDG Analysis table\")\n",
    "print(\"📄 3. JumboAE_IDG_Analysis - Jumbo.ae Only IDG Analysis table\")\n",
    "print(\"📄 4. Monthly_Overall_IDG_Analysis - Monthly Overall IDG Total Analysis\")\n",
    "print(\"📄 5. Monthly_EA_IDG_Analysis - Monthly EA Only IDG Total Analysis\")\n",
    "print(\"📄 6. Monthly_JumboAE_IDG_Analysis - Monthly Jumbo.ae Only IDG Total Analysis\")\n",
    "print(f\"📄 7. Summary_Dashboard - Overview of all analyses\") # Adjusted numbering\n",
    "print(f\"📄 8. Weekly_Totals - Weekly summary with growth\")   # Adjusted numbering\n",
    "\n",
    "print(f\"\\n🎆 FEATURES APPLIED TO EACH ANALYSIS SHEET:\")\n",
    "print(f\"• Dedicated sheet for each analysis: Overall, EA, Jumbo.ae\")\n",
    "print(f\"• Professional multi-level header formatting\")\n",
    "print(f\"• Color-coded percentages (Green: positive, Red: negative)\")\n",
    "print(f\"• Highlighted Total columns and rows\")\n",
    "print(f\"• Auto-adjusted column widths for readability\")\n",
    "print(f\"• Frozen panes for easy navigation\")\n",
    "print(f\"• Consistent number formatting across all sheets\")\n",
    "print(f\"• Comprehensive analysis covering all three data types\")\n",
    "print(f\"• NEW: Monthly summary sheets with Total column data only\")\n",
    "\n",
    "print(f\"\\n📊 ANALYSIS COVERAGE:\")\n",
    "print(f\"• Overall: {len(all_idgs_global)} IDGs across {max_week_global} weeks\")\n",
    "print(f\"• EA Only: {len(all_idgs_ea)} IDGs across {max_week_ea} weeks\")\n",
    "print(f\"• Jumbo.ae: {len(all_idgs_jumbo)} IDGs across {max_week_jumbo} weeks\")\n",
    "print(f\"• Periods: {', '.join(periods)}\")\n",
    "print(f\"• Week calculation based on: {start_day} as first day\")\n",
    "\n",
    "print(f\"\\n💾 File saved as: {output_file}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c10156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic constants for sessions\n",
    "LAST_MONTH_SESSION_PATH = sessions_info[0][0]\n",
    "LAST_MONTH_SESSION_SHEET = sessions_info[0][1]\n",
    "LAST_MONTH_SESSION_DISPLAY = sessions_info[0][2]\n",
    "\n",
    "LAST_YEAR_SESSION_PATH = sessions_info[1][0]\n",
    "LAST_YEAR_SESSION_SHEET = sessions_info[1][1]\n",
    "LAST_YEAR_SESSION_DISPLAY = sessions_info[1][2]\n",
    "\n",
    "CURRENT_SESSION_PATH = sessions_info[2][0]\n",
    "CURRENT_SESSION_SHEET = sessions_info[2][1]\n",
    "CURRENT_SESSION_DISPLAY = sessions_info[2][2]\n",
    "\n",
    "# Metrics to include in the pivot table\n",
    "METRICS_TO_AGGREGATE = ['Sessions', 'Purchases', 'Purchase revenue']\n",
    "\n",
    "def create_master_sessions_pivot(sessions_info, cg_filter=None):\n",
    "    \"\"\"\n",
    "    Create master sessions pivot table with optional CG column filtering\n",
    "    \n",
    "    Parameters:\n",
    "    sessions_info: List of tuples containing (path, sheet, display_name)\n",
    "    cg_filter: String indicating filter type:\n",
    "               - None: No filter (default)\n",
    "               - \"EA_only\": Only include \"EA\" or \"Endless Aisle\" \n",
    "               - \"non_EA\": Exclude \"EA\" or \"Endless Aisle\"\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Master pivot table with calculated metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"📊 SESSIONS DATA ANALYSIS - WEEKLY MASTER PIVOT\")\n",
    "    if cg_filter == \"EA_only\":\n",
    "        print(\"🔍 Filter: EA/Endless Aisle ONLY\")\n",
    "    elif cg_filter == \"non_EA\":\n",
    "        print(\"🔍 Filter: NON-EA/Endless Aisle\")\n",
    "    else:\n",
    "        print(\"🔍 Filter: NO FILTER\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    processed_sessions_data = {}\n",
    "    all_channels = set()\n",
    "    max_week_overall = 0\n",
    "\n",
    "    # Read and process sessions data from all three periods\n",
    "    for i, (path, sheet, display_name) in enumerate(sessions_info):\n",
    "        print(f\"\\n📄 Processing {display_name} Sessions Data:\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        try:\n",
    "            # Read the sessions data\n",
    "            sessions_df = pd.read_excel(path, sheet_name=sheet)\n",
    "            print(f\"  Raw Shape: {sessions_df.shape}\")\n",
    "            print(f\"  Raw Columns: {list(sessions_df.columns)}\")\n",
    "            \n",
    "            # Filter out \"Gift Card\" from Category column if it exists\n",
    "            if 'Category' in sessions_df.columns:\n",
    "                sessions_df = sessions_df[sessions_df['Category'] != 'Gift Card ']\n",
    "                print(f\"  Shape after filtering 'Gift Card': {sessions_df.shape}\")\n",
    "            \n",
    "            # Apply CG filter if specified\n",
    "            if cg_filter and 'CG' in sessions_df.columns:\n",
    "                if cg_filter == \"EA_only\":\n",
    "                    sessions_df = sessions_df[sessions_df['CG'].isin(['EA', 'Endless Aisle'])]\n",
    "                    print(f\"  Shape after EA filter: {sessions_df.shape}\")\n",
    "                elif cg_filter == \"non_EA\":\n",
    "                    sessions_df = sessions_df[~sessions_df['CG'].isin(['EA', 'Endless Aisle'])]\n",
    "                    print(f\"  Shape after non-EA filter: {sessions_df.shape}\")\n",
    "            elif cg_filter and 'CG' not in sessions_df.columns:\n",
    "                print(f\"  Warning: CG column not found, filter '{cg_filter}' cannot be applied\")\n",
    "            \n",
    "            # Convert the string to datetime format first\n",
    "            sessions_df['Date'] = pd.to_datetime(sessions_df['Date'], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "            # Then extract the day\n",
    "            sessions_df['Day'] = sessions_df['Date'].dt.day\n",
    "            \n",
    "\n",
    "\n",
    "            sessions_df = sessions_df.dropna(subset=['Day']) \n",
    "            if sessions_df.empty:\n",
    "                print(f\"  No valid 'Day' data after conversion for {display_name}.\")\n",
    "                processed_sessions_data[display_name] = pd.DataFrame()\n",
    "                continue\n",
    "\n",
    "            sessions_df['Day'] = sessions_df['Day'].astype(int)\n",
    "\n",
    "            original_len = len(sessions_df)\n",
    "            sessions_df = sessions_df[sessions_df['Day'] <= max_invoice_day]\n",
    "            print(f\"📉 {display_name}: Filtered {original_len - len(sessions_df)} rows with Day > {max_invoice_day}\")\n",
    "\n",
    "            # Add WeekNumber column (ensure get_week_number and first_day_position are defined in a previous cell)\n",
    "            sessions_df['WeekNumber'] = sessions_df['Day'].apply(\n",
    "                lambda day: get_week_number(day, first_day_position) \n",
    "            )\n",
    "            \n",
    "            # Check which of the desired metrics are available in the current DataFrame\n",
    "            available_metrics = [m for m in METRICS_TO_AGGREGATE if m in sessions_df.columns]\n",
    "            if not available_metrics:\n",
    "                print(f\"  No metrics ({', '.join(METRICS_TO_AGGREGATE)}) found in {display_name}. Skipping.\")\n",
    "                processed_sessions_data[display_name] = pd.DataFrame()\n",
    "                continue\n",
    "            \n",
    "            print(f\"  Available metrics for {display_name}: {available_metrics}\")\n",
    "\n",
    "            # Select relevant columns for aggregation\n",
    "            cols_for_aggregation = ['Channel', 'WeekNumber'] + available_metrics\n",
    "            temp_df = sessions_df[cols_for_aggregation].copy()\n",
    "\n",
    "            # Group by Channel and WeekNumber, and sum the available metrics\n",
    "            aggregated_data_for_period = temp_df.groupby(['Channel', 'WeekNumber'])[available_metrics].sum().fillna(0)\n",
    "            \n",
    "            processed_sessions_data[display_name] = aggregated_data_for_period\n",
    "            if not aggregated_data_for_period.empty:\n",
    "                all_channels.update(aggregated_data_for_period.index.get_level_values('Channel').unique())\n",
    "                # Ensure WeekNumber exists in index before calling max()\n",
    "                if 'WeekNumber' in aggregated_data_for_period.index.names:\n",
    "                    current_max_week_in_period = aggregated_data_for_period.index.get_level_values('WeekNumber').max()\n",
    "                    if pd.notna(current_max_week_in_period) and current_max_week_in_period > max_week_overall:\n",
    "                        max_week_overall = int(current_max_week_in_period)\n",
    "                else: # Handle case where WeekNumber might not be in index (e.g. if groupby results in empty df for some reason)\n",
    "                     current_max_week_in_period = 0\n",
    "            else:\n",
    "                current_max_week_in_period = 0\n",
    "            \n",
    "            print(f\"  Processed {display_name} successfully. Max week: {current_max_week_in_period if current_max_week_in_period > 0 else 'N/A'}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing {display_name}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            processed_sessions_data[display_name] = pd.DataFrame()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"📊 CREATING FINAL COMPREHENSIVE SESSIONS MASTER PIVOT TABLE\")\n",
    "\n",
    "    if not processed_sessions_data or not all_channels:\n",
    "        print(\"⚠️ No session data successfully processed or no channels found. Cannot create master pivot table.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    sorted_channels = sorted(list(all_channels))\n",
    "    session_periods_display_names = [LAST_MONTH_SESSION_DISPLAY, LAST_YEAR_SESSION_DISPLAY, CURRENT_SESSION_DISPLAY]\n",
    "    \n",
    "    column_tuples = []\n",
    "    if max_week_overall > 0:\n",
    "        weeks_for_pivot = list(range(1, int(max_week_overall) + 1))\n",
    "        \n",
    "        # Add weekly columns first\n",
    "        for week_num in weeks_for_pivot:\n",
    "            week_label = get_week_label(week_num) # Ensure get_week_label is available\n",
    "            for metric_name in METRICS_TO_AGGREGATE: # Use the full list of desired metrics\n",
    "                for period_display_name in session_periods_display_names:\n",
    "                    column_tuples.append((week_label, metric_name, period_display_name))\n",
    "        \n",
    "        # Add Total columns at the end (after all weeks)\n",
    "        for metric_name in METRICS_TO_AGGREGATE:\n",
    "            for period_display_name in session_periods_display_names:\n",
    "                column_tuples.append((\"Total\", metric_name, period_display_name))\n",
    "    \n",
    "        if not column_tuples:\n",
    "             print(\"⚠️ No weeks or metrics to create columns for. Pivot table will be empty or incomplete.\")\n",
    "             master_sessions_pivot_df = pd.DataFrame(index=sorted_channels)\n",
    "        else:\n",
    "            multi_columns = pd.MultiIndex.from_tuples(column_tuples, names=['Week', 'Metric', 'Period'])\n",
    "            master_sessions_pivot_df = pd.DataFrame(index=sorted_channels, columns=multi_columns)\n",
    "            master_sessions_pivot_df = master_sessions_pivot_df.fillna(0) # Initialize with 0\n",
    "\n",
    "            for channel_val in sorted_channels:\n",
    "                for week_num in weeks_for_pivot:\n",
    "                    week_label = get_week_label(week_num)\n",
    "                    for period_display_name in session_periods_display_names:\n",
    "                        if period_display_name in processed_sessions_data:\n",
    "                            period_aggregated_data = processed_sessions_data[period_display_name]\n",
    "                            if not period_aggregated_data.empty and (channel_val, week_num) in period_aggregated_data.index:\n",
    "                                data_series_for_channel_week = period_aggregated_data.loc[(channel_val, week_num)]\n",
    "                                for metric_name in METRICS_TO_AGGREGATE:\n",
    "                                    if metric_name in data_series_for_channel_week.index: # Check if metric was available for this period\n",
    "                                        value = data_series_for_channel_week[metric_name]\n",
    "                                        master_sessions_pivot_df.loc[channel_val, (week_label, metric_name, period_display_name)] = value\n",
    "    else:\n",
    "        print(\"⚠️ No weeks found in session data across all periods. Cannot create master pivot table.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Calculate CVR and AOV if the DataFrame is not empty and has the required structure\n",
    "    if not master_sessions_pivot_df.empty and isinstance(master_sessions_pivot_df.columns, pd.MultiIndex) and master_sessions_pivot_df.columns.nlevels == 3:\n",
    "\n",
    "        # Collect unique (week_label, period_name) combinations that have base metrics\n",
    "        processed_combinations = set()\n",
    "        for col_tuple in master_sessions_pivot_df.columns:\n",
    "            week_label, metric, period_name = col_tuple\n",
    "            if metric in METRICS_TO_AGGREGATE:\n",
    "                processed_combinations.add((week_label, period_name))\n",
    "\n",
    "        for week_label, period_name in processed_combinations:\n",
    "            sessions_col_tuple = (week_label, 'Sessions', period_name)\n",
    "            purchases_col_tuple = (week_label, 'Purchases', period_name)\n",
    "            revenue_col_tuple = (week_label, 'Purchase revenue', period_name)\n",
    "\n",
    "            # Check if all base metric columns exist for this combination\n",
    "            if not (sessions_col_tuple in master_sessions_pivot_df.columns and \\\n",
    "                    purchases_col_tuple in master_sessions_pivot_df.columns and \\\n",
    "                    revenue_col_tuple in master_sessions_pivot_df.columns):\n",
    "                continue\n",
    "\n",
    "            sessions_s = master_sessions_pivot_df[sessions_col_tuple]\n",
    "            purchases_s = master_sessions_pivot_df[purchases_col_tuple]\n",
    "            purchase_revenue_s = master_sessions_pivot_df[revenue_col_tuple]\n",
    "\n",
    "            # Calculate CVR (Purchases / Sessions)\n",
    "            cvr = purchases_s / sessions_s\n",
    "            master_sessions_pivot_df[(week_label, 'CVR', period_name)] = cvr.fillna(0).replace([float('inf'), -float('inf')], 0)\n",
    "\n",
    "            # Calculate AOV (Purchase Revenue / Purchases)\n",
    "            aov = purchase_revenue_s / purchases_s\n",
    "            master_sessions_pivot_df[(week_label, 'AOV', period_name)] = aov.fillna(0).replace([float('inf'), -float('inf')], 0)\n",
    "\n",
    "        # Calculate Total columns (sum of all weeks for each metric/period)\n",
    "        print(\"📊 Calculating Total columns (sum of all weeks)...\")\n",
    "        for period_name in session_periods_display_names:\n",
    "            for metric_name in METRICS_TO_AGGREGATE:\n",
    "                # Find all week columns for this metric and period\n",
    "                week_columns = [(week_label, metric_name, period_name) \n",
    "                              for week_label, _, _ in master_sessions_pivot_df.columns \n",
    "                              if week_label != \"Total\" and (week_label, metric_name, period_name) in master_sessions_pivot_df.columns]\n",
    "                \n",
    "                if week_columns:\n",
    "                    # Sum all week columns for this metric/period\n",
    "                    total_values = master_sessions_pivot_df[week_columns].sum(axis=1)\n",
    "                    master_sessions_pivot_df[(\"Total\", metric_name, period_name)] = total_values\n",
    "            \n",
    "            # Calculate Total CVR and AOV\n",
    "            total_sessions_col = (\"Total\", 'Sessions', period_name)\n",
    "            total_purchases_col = (\"Total\", 'Purchases', period_name)\n",
    "            total_revenue_col = (\"Total\", 'Purchase revenue', period_name)\n",
    "            \n",
    "            if (total_sessions_col in master_sessions_pivot_df.columns and \n",
    "                total_purchases_col in master_sessions_pivot_df.columns):\n",
    "                # Calculate Total CVR\n",
    "                total_sessions = master_sessions_pivot_df[total_sessions_col]\n",
    "                total_purchases = master_sessions_pivot_df[total_purchases_col]\n",
    "                total_cvr = total_purchases / total_sessions\n",
    "                master_sessions_pivot_df[(\"Total\", 'CVR', period_name)] = total_cvr.fillna(0).replace([float('inf'), -float('inf')], 0)\n",
    "            \n",
    "            if (total_purchases_col in master_sessions_pivot_df.columns and \n",
    "                total_revenue_col in master_sessions_pivot_df.columns):\n",
    "                # Calculate Total AOV\n",
    "                total_purchases = master_sessions_pivot_df[total_purchases_col]\n",
    "                total_revenue = master_sessions_pivot_df[total_revenue_col]\n",
    "                total_aov = total_revenue / total_purchases\n",
    "                master_sessions_pivot_df[(\"Total\", 'AOV', period_name)] = total_aov.fillna(0).replace([float('inf'), -float('inf')], 0)\n",
    "\n",
    "        # Re-sort columns to ensure proper ordering: weeks first, then Total, with proper metric ordering\n",
    "        all_metrics_ordered = METRICS_TO_AGGREGATE + ['CVR', 'AOV']\n",
    "        \n",
    "        # Get unique week labels and sort them (excluding Total)\n",
    "        unique_week_labels = [col[0] for col in master_sessions_pivot_df.columns if col[0] != \"Total\"]\n",
    "        unique_week_labels_sorted = sorted(list(set(unique_week_labels)))\n",
    "\n",
    "        # Get ordered periods\n",
    "        period_order_from_sessions_info = [s_info[2] for s_info in sessions_info] \n",
    "        actual_periods_in_df = list(master_sessions_pivot_df.columns.get_level_values('Period').unique())\n",
    "        ordered_periods = [p for p in period_order_from_sessions_info if p in actual_periods_in_df]\n",
    "        for p_df in actual_periods_in_df:\n",
    "            if p_df not in ordered_periods:\n",
    "                ordered_periods.append(p_df)\n",
    "\n",
    "        new_column_tuples = []\n",
    "        \n",
    "        # Add all week columns first\n",
    "        for week_l in unique_week_labels_sorted:\n",
    "            for metric_n in all_metrics_ordered:\n",
    "                for period_dn in ordered_periods: \n",
    "                    if (week_l, metric_n, period_dn) in master_sessions_pivot_df.columns:\n",
    "                        new_column_tuples.append((week_l, metric_n, period_dn))\n",
    "        \n",
    "        # Add Total columns at the end\n",
    "        for metric_n in all_metrics_ordered:\n",
    "            for period_dn in ordered_periods: \n",
    "                if (\"Total\", metric_n, period_dn) in master_sessions_pivot_df.columns:\n",
    "                    new_column_tuples.append((\"Total\", metric_n, period_dn))\n",
    "        \n",
    "        if new_column_tuples:\n",
    "            master_sessions_pivot_df = master_sessions_pivot_df.reindex(columns=pd.MultiIndex.from_tuples(new_column_tuples))\n",
    "    \n",
    "    # Add Grand Total row\n",
    "    if not master_sessions_pivot_df.empty:\n",
    "        print(\"📊 Adding Grand Total row...\")\n",
    "        \n",
    "        # Create grand total row\n",
    "        grand_total_row = pd.DataFrame(index=['Grand Total'], columns=master_sessions_pivot_df.columns)\n",
    "        \n",
    "        # Calculate totals for each column\n",
    "        for col in master_sessions_pivot_df.columns:\n",
    "            week_label, metric, period_name = col\n",
    "            \n",
    "            if metric in ['Sessions', 'Purchases', 'Purchase revenue']:\n",
    "                # Sum these metrics\n",
    "                grand_total_row.loc['Grand Total', col] = master_sessions_pivot_df[col].sum()\n",
    "            elif metric == 'CVR':\n",
    "                # Calculate overall CVR = Total Purchases / Total Sessions\n",
    "                if week_label == \"Total\":\n",
    "                    # For Total column, use the Total Sessions and Total Purchases\n",
    "                    total_sessions_col = (\"Total\", 'Sessions', period_name)\n",
    "                    total_purchases_col = (\"Total\", 'Purchases', period_name)\n",
    "                else:\n",
    "                    # For week columns, use that specific week\n",
    "                    total_sessions_col = (week_label, 'Sessions', period_name)\n",
    "                    total_purchases_col = (week_label, 'Purchases', period_name)\n",
    "                \n",
    "                if total_sessions_col in master_sessions_pivot_df.columns and total_purchases_col in master_sessions_pivot_df.columns:\n",
    "                    total_sessions = master_sessions_pivot_df[total_sessions_col].sum()\n",
    "                    total_purchases = master_sessions_pivot_df[total_purchases_col].sum()\n",
    "                    \n",
    "                    if total_sessions > 0:\n",
    "                        grand_total_row.loc['Grand Total', col] = total_purchases / total_sessions\n",
    "                    else:\n",
    "                        grand_total_row.loc['Grand Total', col] = 0\n",
    "                else:\n",
    "                    grand_total_row.loc['Grand Total', col] = 0\n",
    "            elif metric == 'AOV':\n",
    "                # Calculate overall AOV = Total Revenue / Total Purchases\n",
    "                if week_label == \"Total\":\n",
    "                    # For Total column, use the Total Revenue and Total Purchases\n",
    "                    total_revenue_col = (\"Total\", 'Purchase revenue', period_name)\n",
    "                    total_purchases_col = (\"Total\", 'Purchases', period_name)\n",
    "                else:\n",
    "                    # For week columns, use that specific week\n",
    "                    total_revenue_col = (week_label, 'Purchase revenue', period_name)\n",
    "                    total_purchases_col = (week_label, 'Purchases', period_name)\n",
    "                \n",
    "                if total_revenue_col in master_sessions_pivot_df.columns and total_purchases_col in master_sessions_pivot_df.columns:\n",
    "                    total_revenue = master_sessions_pivot_df[total_revenue_col].sum()\n",
    "                    total_purchases = master_sessions_pivot_df[total_purchases_col].sum()\n",
    "                    \n",
    "                    if total_purchases > 0:\n",
    "                        grand_total_row.loc['Grand Total', col] = total_revenue / total_purchases\n",
    "                    else:\n",
    "                        grand_total_row.loc['Grand Total', col] = 0\n",
    "                else:\n",
    "                    grand_total_row.loc['Grand Total', col] = 0\n",
    "        \n",
    "        # Append grand total row to the main dataframe\n",
    "        master_sessions_pivot_df = pd.concat([master_sessions_pivot_df, grand_total_row.fillna(0)])\n",
    "        print(\"✅ Grand Total row added successfully\")\n",
    "    \n",
    "    return master_sessions_pivot_df.fillna(0)\n",
    "\n",
    "# Generate all three pivot tables\n",
    "print(\"🚀 GENERATING ALL THREE PIVOT TABLES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. No filter pivot\n",
    "print(\"\\n1️⃣ CREATING NO FILTER PIVOT TABLE\")\n",
    "master_sessions_pivot_no_filter = create_master_sessions_pivot(sessions_info, cg_filter=None)\n",
    "\n",
    "# 2. EA only pivot\n",
    "print(\"\\n2️⃣ CREATING EA ONLY PIVOT TABLE\")\n",
    "master_sessions_pivot_ea_only = create_master_sessions_pivot(sessions_info, cg_filter=\"EA_only\")\n",
    "\n",
    "# 3. Non-EA pivot\n",
    "print(\"\\n3️⃣ CREATING NON-EA PIVOT TABLE\")\n",
    "master_sessions_pivot_non_ea = create_master_sessions_pivot(sessions_info, cg_filter=\"non_EA\")\n",
    "\n",
    "# Display all three pivot tables\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"📊 DISPLAYING ALL PIVOT TABLES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\n🔍 NO FILTER PIVOT TABLE:\")\n",
    "print(\"-\" * 40)\n",
    "display(master_sessions_pivot_no_filter)\n",
    "\n",
    "print(\"\\n🔍 EA ONLY PIVOT TABLE:\")\n",
    "print(\"-\" * 40)\n",
    "display(master_sessions_pivot_ea_only)\n",
    "\n",
    "print(\"\\n🔍 NON-EA PIVOT TABLE:\")\n",
    "print(\"-\" * 40)\n",
    "display(master_sessions_pivot_non_ea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export sessions pivot tables to Excel with professional formatting\n",
    "print(\"📤 EXPORTING BEAUTIFULLY FORMATTED SESSIONS PIVOT TABLES TO EXCEL...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "output_file = 'IDG_Weekly_Analysis_Combined.xlsx'\n",
    "\n",
    "try:\n",
    "    # Load existing workbook\n",
    "    from openpyxl import load_workbook\n",
    "    from openpyxl.styles import Font, PatternFill, Border, Side, Alignment, numbers\n",
    "    from openpyxl.utils import get_column_letter\n",
    "    wb = load_workbook(output_file)\n",
    "    \n",
    "    # Define styles for formatting consistency with previous tables\n",
    "    section_header_font = Font(bold=True, size=14, color='FFFFFF')\n",
    "    section_header_fill = PatternFill(start_color='1F4E79', end_color='1F4E79', fill_type='solid')\n",
    "    \n",
    "    column_header_font = Font(bold=True, size=10, color='FFFFFF')\n",
    "    column_header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')\n",
    "    \n",
    "    subheader_font = Font(bold=True, size=10, color='FFFFFF')\n",
    "    subheader_fill = PatternFill(start_color='5B9BD5', end_color='5B9BD5', fill_type='solid')\n",
    "    \n",
    "    row_header_font = Font(bold=True, size=9)\n",
    "    row_header_fill = PatternFill(start_color='F2F2F2', end_color='F2F2F2', fill_type='solid')\n",
    "    \n",
    "    total_row_font = Font(bold=True, size=10)\n",
    "    total_row_fill = PatternFill(start_color='FFE699', end_color='FFE699', fill_type='solid')\n",
    "    \n",
    "    thin_border = Border(\n",
    "        left=Side(style='thin'), right=Side(style='thin'),\n",
    "        top=Side(style='thin'), bottom=Side(style='thin')\n",
    "    )\n",
    "    \n",
    "    def write_sessions_monthly_total_to_sheet(pivot_df, sheet_name):\n",
    "        \"\"\"\n",
    "        Write only the Total column from sessions pivot to monthly sheet with multi-level headers\n",
    "        \"\"\"\n",
    "        print(f\"Writing monthly sessions total data to sheet: {sheet_name}\")\n",
    "        \n",
    "        if sheet_name in wb.sheetnames:\n",
    "            # Get the existing sheet\n",
    "            ws = wb[sheet_name]\n",
    "            \n",
    "            # Extract only the Total column data\n",
    "            total_data = pivot_df[\"Total\"]\n",
    "            \n",
    "            # Find the first empty row\n",
    "            last_row = ws.max_row\n",
    "            start_row = last_row + 3  # Leave two blank rows for spacing\n",
    "            \n",
    "            # Determine column spans for Total data\n",
    "            total_columns = len(total_data.columns) + 1  # +1 for the row headers column\n",
    "            \n",
    "            # Write section header with professional formatting\n",
    "            ws.cell(row=start_row, column=1, value=\"SESSIONS MONTHLY ANALYSIS\")\n",
    "            header_cell = ws.cell(row=start_row, column=1)\n",
    "            header_cell.font = section_header_font\n",
    "            header_cell.fill = section_header_fill\n",
    "            header_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            \n",
    "            # Merge cells for the header\n",
    "            ws.merge_cells(start_row=start_row, start_column=1, end_row=start_row, end_column=total_columns)\n",
    "            \n",
    "            # Apply borders to all merged header cells\n",
    "            for col_idx in range(1, total_columns + 1):\n",
    "                cell = ws.cell(row=start_row, column=col_idx)\n",
    "                cell.border = thin_border\n",
    "            \n",
    "            # Track current row after header\n",
    "            current_row = start_row + 1\n",
    "            \n",
    "            # Create multi-level headers\n",
    "            # First, organize the columns into a hierarchy: Metric -> Period\n",
    "            header_hierarchy = {}\n",
    "            for metric_period in total_data.columns:\n",
    "                metric, period = metric_period\n",
    "                if metric not in header_hierarchy:\n",
    "                    header_hierarchy[metric] = []\n",
    "                header_hierarchy[metric].append(period)\n",
    "            \n",
    "            # Row 1: Metric headers (top level)\n",
    "            col_idx = 2  # Start from column 2 (column 1 is for row labels)\n",
    "            metric_start_columns = {}  # To track where each metric starts\n",
    "            \n",
    "            for metric in header_hierarchy:\n",
    "                metric_start_columns[metric] = col_idx\n",
    "                \n",
    "                # Calculate total columns for this metric\n",
    "                metric_periods = header_hierarchy[metric]\n",
    "                metric_cols = len(metric_periods)\n",
    "                \n",
    "                # Write metric header and merge cells\n",
    "                ws.cell(row=current_row, column=col_idx, value=metric)\n",
    "                metric_cell = ws.cell(row=current_row, column=col_idx)\n",
    "                metric_cell.font = column_header_font\n",
    "                metric_cell.fill = column_header_fill\n",
    "                metric_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "                metric_cell.border = thin_border\n",
    "                \n",
    "                # Merge cells if needed\n",
    "                if metric_cols > 1:\n",
    "                    ws.merge_cells(start_row=current_row, start_column=col_idx, \n",
    "                                  end_row=current_row, end_column=col_idx + metric_cols - 1)\n",
    "                    \n",
    "                    # Apply styles to all merged cells\n",
    "                    for i in range(metric_cols):\n",
    "                        merged_cell = ws.cell(row=current_row, column=col_idx + i)\n",
    "                        merged_cell.border = thin_border\n",
    "                        merged_cell.font = column_header_font\n",
    "                        merged_cell.fill = column_header_fill\n",
    "                \n",
    "                # Move to next position\n",
    "                col_idx += metric_cols\n",
    "            \n",
    "            # Add \"Channel\" header for first column\n",
    "            ws.cell(row=current_row, column=1, value=\"Channel\")\n",
    "            channel_header = ws.cell(row=current_row, column=1)\n",
    "            channel_header.font = column_header_font\n",
    "            channel_header.fill = column_header_fill\n",
    "            channel_header.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            channel_header.border = thin_border\n",
    "            ws.merge_cells(start_row=current_row, start_column=1, \n",
    "                          end_row=current_row + 1, end_column=1)  # Merge across both header rows\n",
    "            \n",
    "            # Row 2: Period headers (bottom level)\n",
    "            current_row += 1\n",
    "            col_idx = 2  # Reset column index\n",
    "            \n",
    "            for metric_period in total_data.columns:\n",
    "                period = metric_period[1]  # Second part (period)\n",
    "                \n",
    "                # Write period header\n",
    "                ws.cell(row=current_row, column=col_idx, value=period)\n",
    "                period_cell = ws.cell(row=current_row, column=col_idx)\n",
    "                period_cell.font = subheader_font\n",
    "                period_cell.fill = subheader_fill\n",
    "                period_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "                period_cell.border = thin_border\n",
    "                \n",
    "                col_idx += 1\n",
    "            \n",
    "            # Move to next row for data\n",
    "            current_row += 1\n",
    "            \n",
    "            # Write data rows\n",
    "            for channel in total_data.index:\n",
    "                # Write channel name\n",
    "                ws.cell(row=current_row, column=1, value=str(channel))\n",
    "                row_header_cell = ws.cell(row=current_row, column=1)\n",
    "                \n",
    "                # Special formatting for Grand Total\n",
    "                if channel == \"Grand Total\":\n",
    "                    row_header_cell.font = total_row_font\n",
    "                    row_header_cell.fill = total_row_fill\n",
    "                else:\n",
    "                    row_header_cell.font = row_header_font\n",
    "                    row_header_cell.fill = row_header_fill\n",
    "                    \n",
    "                row_header_cell.alignment = Alignment(horizontal='left', vertical='center')\n",
    "                row_header_cell.border = thin_border\n",
    "                \n",
    "                # Write data values\n",
    "                col_idx = 2\n",
    "                for metric_period in total_data.columns:\n",
    "                    value = total_data.loc[channel, metric_period]\n",
    "                    ws.cell(row=current_row, column=col_idx, value=value)\n",
    "                    data_cell = ws.cell(row=current_row, column=col_idx)\n",
    "                    \n",
    "                    # Apply cell formatting based on content\n",
    "                    if channel == \"Grand Total\":\n",
    "                        data_cell.font = Font(bold=True, size=9)\n",
    "                        data_cell.fill = total_row_fill\n",
    "                    else:\n",
    "                        data_cell.font = Font(size=9)\n",
    "                    \n",
    "                    # Format numbers based on metric type\n",
    "                    metric = metric_period[0]  # First part (metric)\n",
    "                    period = metric_period[1]  # Second part (period)\n",
    "                    \n",
    "                    if 'CVR' in metric:\n",
    "                        data_cell.number_format = '0.00%'\n",
    "                    elif 'AOV' in metric:\n",
    "                        data_cell.number_format = '#,##0.00'\n",
    "                    elif 'revenue' in metric.lower():\n",
    "                        data_cell.number_format = '#,##0.00'\n",
    "                    elif '%' in period:  # Growth percentages\n",
    "                        data_cell.number_format = '0.00\"%\"'\n",
    "                        # Color code growth percentages\n",
    "                        if isinstance(value, (int, float)) and value != float('inf') and value != float('-inf') and value != 0:\n",
    "                            if value > 0:\n",
    "                                data_cell.font = Font(color='008000', size=9, bold=channel=='Grand Total')\n",
    "                            elif value < 0:\n",
    "                                data_cell.font = Font(color='FF0000', size=9, bold=channel=='Grand Total')\n",
    "                    else:\n",
    "                        data_cell.number_format = '#,##0'\n",
    "                    \n",
    "                    # Apply borders and alignment\n",
    "                    data_cell.alignment = Alignment(horizontal='right', vertical='center')\n",
    "                    data_cell.border = thin_border\n",
    "                    \n",
    "                    col_idx += 1\n",
    "                \n",
    "                current_row += 1\n",
    "            \n",
    "            # Auto-adjust column widths for better readability\n",
    "            for col_idx in range(1, total_columns + 1):\n",
    "                col_letter = get_column_letter(col_idx)\n",
    "                max_length = 0\n",
    "                for row_idx in range(start_row, current_row):\n",
    "                    cell = ws.cell(row=row_idx, column=col_idx)\n",
    "                    if cell.value:\n",
    "                        try:\n",
    "                            cell_length = len(str(cell.value))\n",
    "                            if cell_length > max_length:\n",
    "                                max_length = cell_length\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                # Set width with padding, limit max width\n",
    "                adjusted_width = min(max_length + 3, 25)\n",
    "                ws.column_dimensions[col_letter].width = adjusted_width\n",
    "            \n",
    "            print(f\"✅ Monthly sessions total data written to {sheet_name} successfully!\")\n",
    "        else:\n",
    "            print(f\"❌ Sheet {sheet_name} not found in workbook\")\n",
    "    \n",
    "    def write_sessions_pivot_to_sheet(pivot_df, sheet_name):\n",
    "        print(f\"Writing beautifully formatted sessions data to sheet: {sheet_name}\")\n",
    "        \n",
    "        if sheet_name in wb.sheetnames:\n",
    "            # Get the existing sheet\n",
    "            ws = wb[sheet_name]\n",
    "            \n",
    "            # Find the first empty row (assuming data starts from row 1)\n",
    "            last_row = ws.max_row\n",
    "            start_row = last_row + 3  # Leave two blank rows for spacing\n",
    "            \n",
    "            # Determine column spans\n",
    "            total_columns = len(pivot_df.columns) + 1  # +1 for the row headers column\n",
    "            \n",
    "            # Write section header with professional formatting\n",
    "            ws.cell(row=start_row, column=1, value=\"SESSIONS ANALYSIS\")\n",
    "            header_cell = ws.cell(row=start_row, column=1)\n",
    "            header_cell.font = section_header_font\n",
    "            header_cell.fill = section_header_fill\n",
    "            header_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            \n",
    "            # Merge cells for the header\n",
    "            ws.merge_cells(start_row=start_row, start_column=1, end_row=start_row, end_column=total_columns)\n",
    "            \n",
    "            # Apply borders to all merged header cells\n",
    "            for col_idx in range(1, total_columns + 1):\n",
    "                cell = ws.cell(row=start_row, column=col_idx)\n",
    "                cell.border = thin_border\n",
    "            \n",
    "            # Track current row after header\n",
    "            current_row = start_row + 1\n",
    "            \n",
    "            # Create true multi-level headers (3 levels: Week, Metric, Period)\n",
    "            \n",
    "            # First, organize the columns into a hierarchy: Week -> Metric -> Period\n",
    "            header_hierarchy = {}\n",
    "            for col in pivot_df.columns:\n",
    "                week, metric, period = col\n",
    "                if week not in header_hierarchy:\n",
    "                    header_hierarchy[week] = {}\n",
    "                if metric not in header_hierarchy[week]:\n",
    "                    header_hierarchy[week][metric] = []\n",
    "                header_hierarchy[week][metric].append(period)\n",
    "            \n",
    "            # Row 1: Week headers (top level)\n",
    "            col_idx = 2  # Start from column 2 (column 1 is for row labels)\n",
    "            week_start_columns = {}  # To track where each week starts\n",
    "            \n",
    "            for week in header_hierarchy:\n",
    "                week_start_columns[week] = col_idx\n",
    "                \n",
    "                # Calculate total columns for this week\n",
    "                week_total_cols = 0\n",
    "                for metric in header_hierarchy[week]:\n",
    "                    week_total_cols += len(header_hierarchy[week][metric])\n",
    "                \n",
    "                # Write week header and merge cells\n",
    "                ws.cell(row=current_row, column=col_idx, value=week)\n",
    "                week_cell = ws.cell(row=current_row, column=col_idx)\n",
    "                week_cell.font = column_header_font\n",
    "                week_cell.fill = column_header_fill\n",
    "                week_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "                week_cell.border = thin_border\n",
    "                \n",
    "                # Merge cells if needed\n",
    "                if week_total_cols > 1:\n",
    "                    ws.merge_cells(start_row=current_row, start_column=col_idx, \n",
    "                                  end_row=current_row, end_column=col_idx + week_total_cols - 1)\n",
    "                    \n",
    "                    # Apply styles to all merged cells\n",
    "                    for i in range(week_total_cols):\n",
    "                        merged_cell = ws.cell(row=current_row, column=col_idx + i)\n",
    "                        merged_cell.border = thin_border\n",
    "                        merged_cell.font = column_header_font\n",
    "                        merged_cell.fill = column_header_fill\n",
    "                \n",
    "                # Move to next position\n",
    "                col_idx += week_total_cols\n",
    "            \n",
    "            # Add \"Channel\" header for first column\n",
    "            ws.cell(row=current_row, column=1, value=\"Channel\")\n",
    "            channel_header = ws.cell(row=current_row, column=1)\n",
    "            channel_header.font = column_header_font\n",
    "            channel_header.fill = column_header_fill\n",
    "            channel_header.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            channel_header.border = thin_border\n",
    "            ws.merge_cells(start_row=current_row, start_column=1, \n",
    "                          end_row=current_row + 2, end_column=1)  # Merge across all 3 header rows\n",
    "            \n",
    "            # Row 2: Metric headers (middle level)\n",
    "            current_row += 1\n",
    "            \n",
    "            for week in header_hierarchy:\n",
    "                metric_start_col = week_start_columns[week]\n",
    "                \n",
    "                for metric in header_hierarchy[week]:\n",
    "                    # Calculate how many columns this metric spans\n",
    "                    metric_periods = header_hierarchy[week][metric]\n",
    "                    metric_cols = len(metric_periods)\n",
    "                    \n",
    "                    # Write metric header\n",
    "                    ws.cell(row=current_row, column=metric_start_col, value=metric)\n",
    "                    metric_cell = ws.cell(row=current_row, column=metric_start_col)\n",
    "                    metric_cell.font = column_header_font\n",
    "                    metric_cell.fill = subheader_fill  # Slightly different shade than the week\n",
    "                    metric_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "                    metric_cell.border = thin_border\n",
    "                    \n",
    "                    # Merge cells if needed\n",
    "                    if metric_cols > 1:\n",
    "                        ws.merge_cells(start_row=current_row, start_column=metric_start_col, \n",
    "                                      end_row=current_row, end_column=metric_start_col + metric_cols - 1)\n",
    "                        \n",
    "                        # Apply styles to all merged cells\n",
    "                        for i in range(metric_cols):\n",
    "                            merged_cell = ws.cell(row=current_row, column=metric_start_col + i)\n",
    "                            merged_cell.border = thin_border\n",
    "                            merged_cell.font = column_header_font\n",
    "                            merged_cell.fill = subheader_fill\n",
    "                    \n",
    "                    # Move to next position\n",
    "                    metric_start_col += metric_cols\n",
    "            \n",
    "            # Row 3: Period headers (bottom level)\n",
    "            current_row += 1\n",
    "            col_idx = 2  # Reset column index\n",
    "            \n",
    "            for col in pivot_df.columns:\n",
    "                period = col[2]  # Third level\n",
    "                \n",
    "                # Write period header\n",
    "                ws.cell(row=current_row, column=col_idx, value=period)\n",
    "                period_cell = ws.cell(row=current_row, column=col_idx)\n",
    "                period_cell.font = subheader_font\n",
    "                period_cell.fill = PatternFill(start_color='B4C6E7', end_color='B4C6E7', fill_type='solid')  # Lighter blue\n",
    "                period_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "                period_cell.border = thin_border\n",
    "                \n",
    "                col_idx += 1\n",
    "            \n",
    "            # Move to next row for data\n",
    "            current_row += 1\n",
    "            \n",
    "            # Write data rows\n",
    "            for idx in pivot_df.index:\n",
    "                # Write row header (Channel name)\n",
    "                ws.cell(row=current_row, column=1, value=str(idx))\n",
    "                row_header_cell = ws.cell(row=current_row, column=1)\n",
    "                \n",
    "                # Special formatting for Grand Total\n",
    "                if idx == \"Grand Total\":\n",
    "                    row_header_cell.font = total_row_font\n",
    "                    row_header_cell.fill = total_row_fill\n",
    "                else:\n",
    "                    row_header_cell.font = row_header_font\n",
    "                    row_header_cell.fill = row_header_fill\n",
    "                    \n",
    "                row_header_cell.alignment = Alignment(horizontal='left', vertical='center')\n",
    "                row_header_cell.border = thin_border\n",
    "                \n",
    "                # Write data values\n",
    "                col_idx = 2\n",
    "                for col in pivot_df.columns:\n",
    "                    value = pivot_df.loc[idx, col]\n",
    "                    ws.cell(row=current_row, column=col_idx, value=value)\n",
    "                    data_cell = ws.cell(row=current_row, column=col_idx)\n",
    "                    \n",
    "                    # Apply cell formatting based on content\n",
    "                    if idx == \"Grand Total\":\n",
    "                        data_cell.font = Font(bold=True, size=9)\n",
    "                        data_cell.fill = total_row_fill\n",
    "                    else:\n",
    "                        data_cell.font = Font(size=9)\n",
    "                    \n",
    "                    # Format numbers based on metric type\n",
    "                    metric = col[1]  # Second level (metric)\n",
    "                    if 'CVR' in metric:\n",
    "                        data_cell.number_format = '0.00%'\n",
    "                        # No conditional coloring per user request\n",
    "                    elif 'AOV' in metric:\n",
    "                        data_cell.number_format = '#,##0.00'\n",
    "                    elif 'revenue' in metric.lower():\n",
    "                        data_cell.number_format = '#,##0.00'\n",
    "                    else:\n",
    "                        data_cell.number_format = '#,##0'\n",
    "                    \n",
    "                    # Apply borders and alignment\n",
    "                    data_cell.alignment = Alignment(horizontal='right', vertical='center')\n",
    "                    data_cell.border = thin_border\n",
    "                    \n",
    "                    col_idx += 1\n",
    "                \n",
    "                current_row += 1\n",
    "            \n",
    "            # Auto-adjust column widths for better readability\n",
    "            for col_idx in range(1, total_columns + 1):\n",
    "                col_letter = get_column_letter(col_idx)\n",
    "                max_length = 0\n",
    "                for row_idx in range(start_row, current_row):\n",
    "                    cell = ws.cell(row=row_idx, column=col_idx)\n",
    "                    if cell.value:\n",
    "                        try:\n",
    "                            cell_length = len(str(cell.value))\n",
    "                            if cell_length > max_length:\n",
    "                                max_length = cell_length\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                # Set width with padding, limit max width\n",
    "                adjusted_width = min(max_length + 3, 25)\n",
    "                ws.column_dimensions[col_letter].width = adjusted_width\n",
    "            \n",
    "            print(f\"✅ Beautifully formatted sessions data written to {sheet_name} successfully!\")\n",
    "        else:\n",
    "            print(f\"❌ Sheet {sheet_name} not found in workbook\")\n",
    "\n",
    "    # Write each pivot table to its respective detailed sheet\n",
    "    write_sessions_pivot_to_sheet(master_sessions_pivot_no_filter, \"Overall_IDG_Analysis\")\n",
    "    write_sessions_pivot_to_sheet(master_sessions_pivot_ea_only, \"EA_IDG_Analysis\")\n",
    "    write_sessions_pivot_to_sheet(master_sessions_pivot_non_ea, \"JumboAE_IDG_Analysis\")\n",
    "    \n",
    "    # Write Total column data to respective monthly sheets\n",
    "    write_sessions_monthly_total_to_sheet(master_sessions_pivot_no_filter, \"Monthly_Overall_IDG_Analysis\")\n",
    "    write_sessions_monthly_total_to_sheet(master_sessions_pivot_ea_only, \"Monthly_EA_IDG_Analysis\")\n",
    "    write_sessions_monthly_total_to_sheet(master_sessions_pivot_non_ea, \"Monthly_JumboAE_IDG_Analysis\")\n",
    "\n",
    "    # Save the workbook\n",
    "    wb.save(output_file)\n",
    "    print(f\"\\n✅ Successfully appended beautifully formatted sessions data to {output_file}\")\n",
    "    print(\"📊 Sessions analysis has been added to:\")\n",
    "    print(\"  • Overall_IDG_Analysis sheet (detailed)\")\n",
    "    print(\"  • EA_IDG_Analysis sheet (detailed)\")\n",
    "    print(\"  • JumboAE_IDG_Analysis sheet (detailed)\")\n",
    "    print(\"  • Monthly_Overall_IDG_Analysis sheet (totals only)\")\n",
    "    print(\"  • Monthly_EA_IDG_Analysis sheet (totals only)\")\n",
    "    print(\"  • Monthly_JumboAE_IDG_Analysis sheet (totals only)\")\n",
    "    \n",
    "    print(\"\\n🎨 Formatting Features Applied:\")\n",
    "    print(\"  • Professional color-coded headers and sections\")\n",
    "    print(\"  • Multi-level column headers with proper alignment\")\n",
    "    print(\"  • Highlighted Grand Total row\")\n",
    "    print(\"  • Color-coded growth percentages (green/red)\")\n",
    "    print(\"  • Consistent borders and cell styling\")\n",
    "    print(\"  • Auto-adjusted column widths\")\n",
    "    print(\"  • Proper number formatting for different metrics\")\n",
    "    print(\"  • Clean visual separation between sections\")\n",
    "    print(\"  • NEW: Monthly sheets with Total column data only\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error while exporting to Excel: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()  # Print full traceback for better debugging\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd09bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Open the comprehensive Excel file automatically (Windows)\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Update to use the correct comprehensive file name\n",
    "output_file = 'IDG_Weekly_Analysis_Combined.xlsx'\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"🎉 COMPLETE IDG WEEKLY ANALYSIS EXPORT FINISHED!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"📊 ANALYSIS SUMMARY:\")\n",
    "print(f\"• 📈 Overall Analysis: {len(all_idgs_global)} IDGs across {max_week_global} weeks\")\n",
    "print(f\"• 🏢 EA Only Analysis: {len(all_idgs_ea)} IDGs across {max_week_ea} weeks\")\n",
    "print(f\"• 🛍️ Jumbo.ae Analysis: {len(all_idgs_jumbo)} IDGs across {max_week_jumbo} weeks\")\n",
    "print(f\"• 📅 Periods Analyzed: {', '.join(periods)}\")\n",
    "print(f\"• 🗺️ Week Calculation: Based on {start_day} as first day of month\")\n",
    "print(f\"• 📎 Export File: {output_file}\")\n",
    "print(\"\\n🏆 All pivot tables created with comprehensive analysis!\")\n",
    "print(\"📊 Ready for business insights and decision making!\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62e0e789",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from copy import copy\n",
    "\n",
    "from openpyxl import Workbook\n",
    "\n",
    "def copy_all_sheets_from_combined():\n",
    "    \"\"\"\n",
    "    Copy all sheets from IDG_Weekly_Analysis_Combined.xlsx to invoice_day_channel_report_compatible.xlsx\n",
    "    Preserving the existing Sheet1 data and appending all other sheets\n",
    "    \"\"\"\n",
    "    source_path = 'IDG_Weekly_Analysis_Combined.xlsx'\n",
    "    dest_path = 'invoice_day_channel_report_compatible.xlsx'\n",
    "    \n",
    "    print(f\"Starting to copy sheets from {source_path} to {dest_path}\")\n",
    "    \n",
    "    # Check if source file exists\n",
    "    if not os.path.exists(source_path):\n",
    "        print(f\"Error: Source file {source_path} not found!\")\n",
    "        return\n",
    "       \n",
    "    if os.path.exists(source_path):\n",
    "        print(f\"Opening {os.path.abspath(source_path)} to ensure it's saved and closed properly...\")\n",
    "        open_save_close_excel_dynamic(os.path.abspath(source_path))\n",
    "\n",
    "    try:\n",
    "        # Load both workbooks\n",
    "        source_wb = load_workbook(source_path, data_only=True)\n",
    "        \n",
    "        # Check if destination file exists, if not create it with a basic sheet\n",
    "        if os.path.exists(dest_path):\n",
    "            dest_wb = load_workbook(dest_path)\n",
    "        else:\n",
    "            dest_wb = Workbook()\n",
    "            print(f\"Created new destination file: {dest_path}\")\n",
    "        \n",
    "        # Get all sheet names from source workbook\n",
    "        source_sheet_names = source_wb.sheetnames\n",
    "        existing_dest_sheet_names = dest_wb.sheetnames\n",
    "        \n",
    "        print(f\"Source sheets to copy: {source_sheet_names}\")\n",
    "        print(f\"Existing destination sheets: {existing_dest_sheet_names}\")\n",
    "        \n",
    "        # Copy each sheet from source to destination\n",
    "        for sheet_name in source_sheet_names:\n",
    "            source_ws = source_wb[sheet_name]\n",
    "            \n",
    "            # Create a unique sheet name if it already exists in destination\n",
    "            new_sheet_name = sheet_name\n",
    "            counter = 1\n",
    "            while new_sheet_name in dest_wb.sheetnames:\n",
    "                new_sheet_name = f\"{sheet_name}_{counter}\"\n",
    "                counter += 1\n",
    "            \n",
    "            # Create new worksheet in destination\n",
    "            dest_ws = dest_wb.create_sheet(title=new_sheet_name)\n",
    "            \n",
    "            print(f\"Copying sheet '{sheet_name}' as '{new_sheet_name}'...\")\n",
    "            \n",
    "            # Get the range of data to copy\n",
    "            source_max_row = source_ws.max_row\n",
    "            source_max_col = source_ws.max_column\n",
    "            \n",
    "            # Handle merged cells first\n",
    "            merged_ranges = source_ws.merged_cells.ranges\n",
    "            for merged_range in merged_ranges:\n",
    "                # Create the same merge range in destination\n",
    "                dest_ws.merge_cells(str(merged_range))\n",
    "                \n",
    "                # Copy the value from the top-left cell of the merge range\n",
    "                source_value = source_ws.cell(merged_range.min_row, merged_range.min_col).value\n",
    "                dest_ws.cell(merged_range.min_row, merged_range.min_col).value = source_value\n",
    "                \n",
    "                # Copy formatting from the first cell of merge range\n",
    "                source_cell = source_ws.cell(merged_range.min_row, merged_range.min_col)\n",
    "                dest_cell = dest_ws.cell(merged_range.min_row, merged_range.min_col)\n",
    "                \n",
    "                if source_cell.has_style:\n",
    "                    dest_cell.font = copy(source_cell.font)\n",
    "                    dest_cell.fill = copy(source_cell.fill)\n",
    "                    dest_cell.border = copy(source_cell.border)\n",
    "                    dest_cell.alignment = copy(source_cell.alignment)\n",
    "                    dest_cell.number_format = source_cell.number_format\n",
    "            \n",
    "            # Copy all data and formatting\n",
    "            for row in range(1, source_max_row + 1):\n",
    "                for col in range(1, source_max_col + 1):\n",
    "                    # Skip if this cell is part of a merged range\n",
    "                    if any(merged_range.min_row <= row <= merged_range.max_row and \n",
    "                        merged_range.min_col <= col <= merged_range.max_col \n",
    "                        for merged_range in merged_ranges):\n",
    "                        continue\n",
    "                    \n",
    "                    # Get source cell\n",
    "                    source_cell = source_ws.cell(row=row, column=col)\n",
    "                    \n",
    "                    # Get destination cell\n",
    "                    dest_cell = dest_ws.cell(row=row, column=col)\n",
    "                    \n",
    "                    # Copy value\n",
    "                    dest_cell.value = source_cell.value\n",
    "                    \n",
    "                    # Copy formatting if it has any\n",
    "                    if source_cell.has_style:\n",
    "                        dest_cell.font = copy(source_cell.font)\n",
    "                        dest_cell.fill = copy(source_cell.fill)\n",
    "                        dest_cell.border = copy(source_cell.border)\n",
    "                        dest_cell.alignment = copy(source_cell.alignment)\n",
    "                        dest_cell.number_format = source_cell.number_format\n",
    "            \n",
    "            # Copy column widths\n",
    "            for col in range(1, source_max_col + 1):\n",
    "                col_letter = get_column_letter(col)\n",
    "                if source_ws.column_dimensions[col_letter].width:\n",
    "                    dest_ws.column_dimensions[col_letter].width = source_ws.column_dimensions[col_letter].width\n",
    "            \n",
    "            # Copy row heights\n",
    "            for row in range(1, source_max_row + 1):\n",
    "                if source_ws.row_dimensions[row].height:\n",
    "                    dest_ws.row_dimensions[row].height = source_ws.row_dimensions[row].height\n",
    "        \n",
    "        # Save the destination workbook\n",
    "        dest_wb.save(dest_path)\n",
    "        print(f\"Successfully copied all sheets from {source_path} to {dest_path}\")\n",
    "        print(f\"Final sheets in destination: {dest_wb.sheetnames}\")\n",
    "\n",
    "        if os.path.exists(source_path):\n",
    "            os.remove(source_path)\n",
    "\n",
    "        \n",
    "        if os.path.exists(dest_path):\n",
    "            os.startfile(dest_path)\n",
    "        print(f\"Opened {dest_path} in Excel successfully!\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred while copying sheets: {str(e)}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "\n",
    "# Execute the copy function\n",
    "copy_all_sheets_from_combined()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
