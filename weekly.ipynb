{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a083c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get necessary imports\n",
    "import pandas as pd\n",
    "import openpyxl\n",
    "from openpyxl.styles import Font, PatternFill, Border, Side, Alignment, numbers\n",
    "from openpyxl.utils import get_column_letter\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "from copy import copy  # For copying Excel cell styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9357e1e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target Excel file \n",
    "output_path = 'weekly.xlsx'\n",
    "\n",
    "# Define the sheets and paths to process with constants for easy reference\n",
    "# Format: (file_path, sheet_name, display_name)\n",
    "sheet_info = [\n",
    "    ('test2/may25-final.xlsx', 'Sheet1', 'May 25'),   # Last month raw sheet\n",
    "    ('test2/June24_Invoice.xlsx', 'Raw data June 24', 'June 24'),        # Last year raw sheet\n",
    "    ('test2/June25.xlsx', 'Sheet1', 'June 25')                # Latest month raw sheet\n",
    "]\n",
    "\n",
    "latest_path, latest_sheet, latest_display = sheet_info[-1]\n",
    "latest_df = pd.read_excel(latest_path, sheet_name=latest_sheet)\n",
    "max_invoice_day = pd.to_datetime(latest_df['InvoiceDate'], dayfirst=True, errors='coerce').dt.day.max()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define sessions_info\n",
    "sessions_info = [\n",
    "    ('test2/May_2025_Daily traffic (2).xlsx', 'download - 2025-01-08T160122.10', 'May 25'), # Last month session\n",
    "    ('test2/June Traffic -2024.xlsx', 'download - 2025-06-03T09524 (2)', 'June 24'),  # Last year session\n",
    "    ('test2/June_2025_Daily traffic.xlsx', 'download - 2025-01-08T160122.10', 'June 25')   # Current month session\n",
    "]\n",
    "\n",
    "# Create unique identifiers by combining file path and sheet name\n",
    "LAST_MONTH_ID = f\"{sheet_info[0][0]}_{sheet_info[0][1]}\"\n",
    "LAST_YEAR_ID = f\"{sheet_info[1][0]}_{sheet_info[1][1]}\"\n",
    "CURRENT_ID = f\"{sheet_info[2][0]}_{sheet_info[2][1]}\"\n",
    "\n",
    "# Dynamic constants extracted from sheet_info for easy reference\n",
    "LAST_MONTH_PATH = sheet_info[0][0]      # File path for last month\n",
    "LAST_MONTH_SHEET = sheet_info[0][1]     # Sheet name for last month\n",
    "LAST_MONTH_DISPLAY = sheet_info[0][2]   # Display name for last month\n",
    "\n",
    "LAST_YEAR_PATH = sheet_info[1][0]       # File path for last year\n",
    "LAST_YEAR_SHEET = sheet_info[1][1]      # Sheet name for last year\n",
    "LAST_YEAR_DISPLAY = sheet_info[1][2]    # Display name for last year\n",
    "\n",
    "CURRENT_PATH = sheet_info[2][0]         # File path for current month\n",
    "CURRENT_SHEET = sheet_info[2][1]        # Sheet name for current month\n",
    "CURRENT_DISPLAY = sheet_info[2][2]      # Display name for current month\n",
    "\n",
    "# Create dynamic periods list from sheet_info display names\n",
    "periods = [LAST_MONTH_DISPLAY, LAST_YEAR_DISPLAY, CURRENT_DISPLAY]\n",
    "\n",
    "print(\"üìä Dynamic Configuration Loaded:\")\n",
    "print(\"=\" * 40)\n",
    "print(f\"Last Month:   {LAST_MONTH_DISPLAY} (ID: {LAST_MONTH_ID})\")\n",
    "print(f\"Last Year:    {LAST_YEAR_DISPLAY} (ID: {LAST_YEAR_ID})\")  \n",
    "print(f\"Current:      {CURRENT_DISPLAY} (ID: {CURRENT_ID})\")\n",
    "print(f\"Periods:      {periods}\")\n",
    "print(\"=\" * 40)\n",
    "\n",
    "# Target sheet information\n",
    "TARGET_PATH = 'test2/Target_June_25.xlsx'\n",
    "TARGET_SHEET = 'Target-June25'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06edad8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get target sums by day and channel using constants - WITH DEBUG OUTPUT\n",
    "print(\"üîç DEBUGGING TARGET DATA STRUCTURE\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "target_df = pd.read_excel(TARGET_PATH, sheet_name=TARGET_SHEET)\n",
    "print(f\"üìä Raw Target Data Shape: {target_df.shape}\")\n",
    "print(f\"üìã Target Data Columns: {list(target_df.columns)}\")\n",
    "print(\"\\nüìÖ First 10 rows of Target Data:\")\n",
    "display(target_df.head(10))\n",
    "\n",
    "print(\"\\nüè∑Ô∏è Unique Channels in Target Data:\")\n",
    "print(target_df['Channel'].unique())\n",
    "\n",
    "print(\"\\nüè∑Ô∏è Unique Categories in Target Data:\")\n",
    "if 'Category' in target_df.columns:\n",
    "    print(target_df['Category'].unique())\n",
    "else:\n",
    "    print(\"No 'Category' column found in target data\")\n",
    "\n",
    "# Modified to include 'Category' in the grouping if it exists\n",
    "if 'Category' in target_df.columns:\n",
    "    target_sums = target_df.groupby(['Date', 'Channel', 'Category'])['Target'].sum().unstack(level=['Channel', 'Category'], fill_value=0).round(6)\n",
    "else:\n",
    "    target_sums = target_df.groupby(['Date', 'Channel'])['Target'].sum().unstack(level='Channel', fill_value=0).round(6)\n",
    "\n",
    "print(f\"\\nüìä Processed Target Sums Shape: {target_sums.shape}\")\n",
    "print(\"\\nüìã Target Sums Sample:\")\n",
    "display(target_sums.head())\n",
    "\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ada2e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üìÖ Week Analysis Configuration - User Input Based\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "print(\"üóìÔ∏è  WEEK ANALYSIS CONFIGURATION\")\n",
    "print(\"=\" * 50)\n",
    "print(\"üìù Choose your preferred starting day for weekly analysis:\")\n",
    "print(\"   Options: Monday, Tuesday, Wednesday, Thursday, Friday, Saturday, Sunday\")\n",
    "print()\n",
    "\n",
    "# Get the first day of the month from user\n",
    "while True:\n",
    "    first_day = input('Enter the first day of the month (Monday/Tuesday/Wednesday/Thursday/Friday/Saturday/Sunday): ').strip().lower()\n",
    "    if first_day in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']:\n",
    "        break\n",
    "    print('Invalid input! Please enter a valid day name.')\n",
    "\n",
    "# Create a mapping of days to their position in a week (0=Monday to 6=Sunday)\n",
    "day_positions = {\n",
    "    'monday': 0, 'tuesday': 1, 'wednesday': 2, 'thursday': 3,\n",
    "    'friday': 4, 'saturday': 5, 'sunday': 6\n",
    "}\n",
    "day_names = ['Monday', 'Tuesday', 'Wednesday', 'Thursday', 'Friday', 'Saturday', 'Sunday']\n",
    "\n",
    "# Get position of the first day (0-6, where 0 is Monday)\n",
    "first_day_position = day_positions[first_day]\n",
    "start_day = day_names[first_day_position].capitalize()\n",
    "\n",
    "print(f\"‚úÖ First day of month set to: {start_day}\")\n",
    "print(f\"üìä Configuration: Week analysis starts based on {start_day} as first day\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "def get_week_info(day_of_month, first_day_pos):\n",
    "    \"\"\"Get week information for a given day.\n",
    "    Returns (week_number, is_first_partial_week)\"\"\"\n",
    "    # For days in the first partial week\n",
    "    if first_day_pos > 0:  # If month doesn't start on Monday\n",
    "        days_till_next_monday = 7 - first_day_pos\n",
    "        if day_of_month <= days_till_next_monday:\n",
    "            return 1, True\n",
    "        # Adjust day number to calculate remaining weeks\n",
    "        adjusted_day = day_of_month - days_till_next_monday\n",
    "        return (adjusted_day - 1) // 7 + 2, False\n",
    "    else:  # If month starts on Monday\n",
    "        return (day_of_month - 1) // 7 + 1, False\n",
    "\n",
    "def get_week_number(day_of_month, first_day_pos):\n",
    "    \"\"\"Get week number for a given day of month\"\"\"\n",
    "    week_num, _ = get_week_info(day_of_month, first_day_pos)\n",
    "    return week_num\n",
    "\n",
    "def get_week_label(week_num):\n",
    "    \"\"\"Get descriptive week label\"\"\"\n",
    "    return f\"Week {week_num}\"\n",
    "\n",
    "def get_day_name(day_number, first_day_pos):\n",
    "    \"\"\"Get the day name for a given day of month\"\"\"\n",
    "    # Calculate the day of week (0-6, where 0 is Monday)\n",
    "    day_of_week = (first_day_pos + day_number - 1) % 7\n",
    "    return day_names[day_of_week]\n",
    "\n",
    "# Test the calculation\n",
    "print(f\"\\nüìä Week Calculation Test (First day: {start_day})\")\n",
    "print(\"=\" * 50)\n",
    "for day in range(1, 16):  # Show first 15 days\n",
    "    week_num = get_week_number(day, first_day_position)\n",
    "    week_label = get_week_label(week_num)\n",
    "    day_name = get_day_name(day, first_day_position)\n",
    "    print(f\"Day {day:2d} ({day_name:9s}) ‚Üí {week_label}\")\n",
    "\n",
    "# Calculate total weeks for a typical 31-day month\n",
    "max_weeks = max([get_week_number(day, first_day_position) for day in range(1, 32)])\n",
    "print(f\"\\nüìà Total weeks in a 31-day month: {max_weeks}\")\n",
    "print(f\"üìã Analysis will group days based on {start_day} as first day of month\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Store variables for use in other cells\n",
    "start_day_num = first_day_position  # For compatibility with existing code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa5351c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect week-wise and TYPE-wise sums for each sheet using simplified week calculation\n",
    "results = []\n",
    "type_results = []\n",
    "idg_results = []  # New list for IDG results\n",
    "\n",
    "for path, sheet, display_name in sheet_info:\n",
    "    df = pd.read_excel(path, sheet_name=sheet)\n",
    "    filtered_df = df[~df['idg'].isin(['FOC', 'Remove', 'WRT'])].copy()\n",
    "    filtered_df['InvoiceDay'] = pd.to_datetime(filtered_df['InvoiceDate'], dayfirst=True, errors='coerce').dt.day\n",
    "\n",
    "\n",
    "    original_len = len(filtered_df)\n",
    "    filtered_df = filtered_df[filtered_df['InvoiceDay'] <= max_invoice_day]\n",
    "    print(f\"üìâ {display_name}: Filtered {original_len - len(filtered_df)} rows with InvoiceDay > {max_invoice_day}\")\n",
    "\n",
    "\n",
    "    \n",
    "    # Add week number calculation using the simplified function\n",
    "    filtered_df['WeekNumber'] = filtered_df['InvoiceDay'].apply(\n",
    "        lambda day: get_week_number(day, first_day_position)\n",
    "    )\n",
    "    \n",
    "    # Map CC to Jumbo.ae in the TYPE column\n",
    "    filtered_df['TYPE'] = filtered_df['TYPE'].replace('CC', 'Jumbo.ae')\n",
    "    \n",
    "    # Week-wise sum - use a unique identifier combining file path and sheet name\n",
    "    unique_id = f\"{path}_{sheet}\"\n",
    "    invoice_week_sum = filtered_df.groupby('WeekNumber')['Amount Invoiced W.O. VAT'].sum()\n",
    "    results.append((unique_id, invoice_week_sum, display_name))\n",
    "    \n",
    "    # TYPE-wise sum for Jumbo.ae and EA by week - use unique identifier\n",
    "    filtered_type = filtered_df[filtered_df['TYPE'].isin(['Jumbo.ae', 'EA'])]\n",
    "    sum_by_week_type = filtered_type.groupby(['WeekNumber', 'TYPE'])['Amount Invoiced W.O. VAT'].sum().unstack(fill_value=0)\n",
    "    type_results.append((unique_id, sum_by_week_type, display_name))\n",
    "    \n",
    "    # IDG-wise sum by week (new addition) - use unique identifier\n",
    "    sum_by_week_idg = filtered_df.pivot_table(\n",
    "        values='Amount Invoiced W.O. VAT',\n",
    "        index='WeekNumber',\n",
    "        columns='idg',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    )\n",
    "    idg_results.append((unique_id, display_name, sum_by_week_idg))\n",
    "\n",
    "type_results\n",
    "\n",
    "# Target Data Processing Functions with Channel Filtering and Debug Output\n",
    "print(\"üéØ TARGET DATA PROCESSING WITH CHANNEL FILTERING\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "def process_target_data_by_week_and_channel(channel_filter=None):\n",
    "    \"\"\"\n",
    "    Process target data and group by week and IDG (Category), with optional channel filtering\n",
    "    \n",
    "    Args:\n",
    "        channel_filter: str, optional - Filter by 'Jumbo.ae' or 'EA' or None for all\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame with weeks as index and IDG (Category) as columns\n",
    "    \"\"\"\n",
    "    print(f\"\\nüîÑ Processing target data for channel: {channel_filter or 'ALL CHANNELS'}\")\n",
    "    \n",
    "    # Read target data\n",
    "    target_df = pd.read_excel(TARGET_PATH, sheet_name=TARGET_SHEET)\n",
    "    \n",
    "    print(f\"üìä Original target data shape: {target_df.shape}\")\n",
    "    \n",
    "    # Apply channel filter if specified\n",
    "    if channel_filter:\n",
    "        filtered_target = target_df[target_df['Channel'] == channel_filter].copy()\n",
    "        print(f\"üîç After {channel_filter} filter: {filtered_target.shape}\")\n",
    "        \n",
    "        if filtered_target.empty:\n",
    "            print(f\"‚ö†Ô∏è WARNING: No target data found for channel '{channel_filter}'\")\n",
    "            print(f\"üìÖ Available channels: {target_df['Channel'].unique()}\")\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        filtered_target = target_df.copy()\n",
    "    \n",
    "    # Use the 'Date' column directly as 'Day' as it contains day numbers\n",
    "    filtered_target['Day'] = filtered_target['Date']\n",
    "    \n",
    "    # Ensure 'Day' column is numeric and handle potential errors (e.g., non-numeric values)\n",
    "    filtered_target['Day'] = pd.to_numeric(filtered_target['Day'], errors='coerce')\n",
    "\n",
    "    # Remove rows with invalid dates (where 'Day' could not be converted to numeric)\n",
    "    before_date_filter = len(filtered_target)\n",
    "    filtered_target = filtered_target.dropna(subset=['Day'])\n",
    "    after_date_filter = len(filtered_target)\n",
    "    \n",
    "    if before_date_filter != after_date_filter:\n",
    "        print(f\"‚ö†Ô∏è Removed {before_date_filter - after_date_filter} rows with invalid 'Day' values (non-numeric or empty).\")\n",
    "    \n",
    "    # Convert 'Day' to integer type after cleaning\n",
    "    if not filtered_target.empty:\n",
    "        filtered_target['Day'] = filtered_target['Day'].astype(int)\n",
    "\n",
    "    original_len = len(filtered_target)\n",
    "    filtered_target = filtered_target[filtered_target['Day'] <= max_invoice_day]\n",
    "    print(f\"üìâ {display_name}: Filtered {original_len - len(filtered_target)} rows with Day > {max_invoice_day}\")\n",
    "    # Add week number calculation\n",
    "    filtered_target['WeekNumber'] = filtered_target['Day'].apply(\n",
    "        lambda day: get_week_number(day, first_day_position)\n",
    "    )\n",
    "    \n",
    "    print(f\"üìÖ Date range in target: {filtered_target['Day'].min()} to {filtered_target['Day'].max()}\")\n",
    "    print(f\"üìã Week range: {filtered_target['WeekNumber'].min()} to {filtered_target['WeekNumber'].max()}\")\n",
    "    \n",
    "    # Check if Category column exists and use it, otherwise use Channel as IDG\n",
    "    if 'Category' in filtered_target.columns:\n",
    "        print(f\"üè∑Ô∏è Using 'Category' column for IDG grouping\")\n",
    "        print(f\"üìÖ Available categories: {filtered_target['Category'].unique()}\")\n",
    "        \n",
    "        # Group by Week and Category to get target by week and IDG\n",
    "        target_by_week = filtered_target.groupby(['WeekNumber', 'Category'])['Target'].sum().unstack(level='Category', fill_value=0)\n",
    "    else:\n",
    "        print(f\"üè∑Ô∏è No 'Category' column found, using 'Channel' for IDG grouping\")\n",
    "        \n",
    "        # Group by Week and Channel to get target by week\n",
    "        target_by_week = filtered_target.groupby(['WeekNumber', 'Channel'])['Target'].sum().unstack(level='Channel', fill_value=0)\n",
    "    \n",
    "    # Clean column names\n",
    "    target_by_week.columns.name = None\n",
    "    \n",
    "    print(f\"üìä Final target pivot shape: {target_by_week.shape}\")\n",
    "    print(f\"üìã Target IDGs/Categories: {list(target_by_week.columns)}\")\n",
    "    \n",
    "    return target_by_week\n",
    "\n",
    "# Test target processing for all channels\n",
    "print(\"\\nüî¨ TESTING TARGET DATA PROCESSING:\")\n",
    "print(\"-\" * 40)\n",
    "\n",
    "# Test 1: All channels\n",
    "all_channels_target = process_target_data_by_week_and_channel()\n",
    "if not all_channels_target.empty:\n",
    "    print(\"\\nüìã ALL CHANNELS TARGET DATA:\")\n",
    "    display(all_channels_target.round(2))\n",
    "\n",
    "# Test 2: Jumbo.ae only  \n",
    "jumbo_target = process_target_data_by_week_and_channel('Jumbo.ae')\n",
    "if not jumbo_target.empty:\n",
    "    print(\"\\nüìã JUMBO.AE TARGET DATA:\")\n",
    "    display(jumbo_target.round(2))\n",
    "\n",
    "# Test 3: EA only\n",
    "ea_target = process_target_data_by_week_and_channel('EA')\n",
    "if not ea_target.empty:\n",
    "    print(\"\\nüìã EA TARGET DATA:\")\n",
    "    display(ea_target.round(2))\n",
    "\n",
    "print(\"\\n=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbf20411",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first sheet info\n",
    "first_path, first_sheet, first_display = sheet_info[0]\n",
    "\n",
    "# Read and process the data\n",
    "df = pd.read_excel(first_path, sheet_name=first_sheet)\n",
    "\n",
    "# Filter out unwanted IDG values and create pivot table\n",
    "filtered_df = df[~df['idg'].isin(['FOC', 'Remove', 'WRT'])].copy()\n",
    "filtered_df['InvoiceDay'] = pd.to_datetime(filtered_df['InvoiceDate'], dayfirst=True, errors='coerce').dt.day\n",
    "\n",
    "# Create comprehensive IDG pivot table function for reusability\n",
    "\n",
    "def process_sheet_data_by_type(path, sheet_name, display_name, type_filter=None):\n",
    "    \"\"\"Process a single sheet and return IDG pivot by week, optionally filtered by TYPE\"\"\"\n",
    "    df = pd.read_excel(path, sheet_name=sheet_name)\n",
    "    filtered_df = df[~df['idg'].isin(['FOC', 'Remove', 'WRT'])].copy()\n",
    "    \n",
    "    # Apply TYPE filter if specified\n",
    "    if type_filter:\n",
    "        # Map CC to Jumbo.ae first\n",
    "        filtered_df['TYPE'] = filtered_df['TYPE'].replace('CC', 'Jumbo.ae')\n",
    "        filtered_df = filtered_df[filtered_df['TYPE'] == type_filter]\n",
    "    \n",
    "    filtered_df['InvoiceDay'] = pd.to_datetime(filtered_df['InvoiceDate'], dayfirst=True, errors='coerce').dt.day\n",
    "\n",
    "    original_len = len(filtered_df)\n",
    "    filtered_df = filtered_df[filtered_df['InvoiceDay'] <= max_invoice_day]\n",
    "    print(f\"üìâ {display_name}: Filtered {original_len - len(filtered_df)} rows with InvoiceDay > {max_invoice_day}\")\n",
    "    \n",
    "    # Add week number calculation using simplified function\n",
    "    filtered_df['WeekNumber'] = filtered_df['InvoiceDay'].apply(\n",
    "        lambda day: get_week_number(day, first_day_position)\n",
    "    )\n",
    "    \n",
    "    # Create pivot table with IDG on rows and weeks on columns\n",
    "    idg_pivot = filtered_df.pivot_table(\n",
    "        values='Amount Invoiced W.O. VAT',\n",
    "        index='idg',\n",
    "        columns='WeekNumber',\n",
    "        aggfunc='sum',\n",
    "        fill_value=0\n",
    "    )\n",
    "    \n",
    "    return idg_pivot\n",
    "\n",
    "def create_comprehensive_pivot_table(sheet_info, periods, type_filter=None, table_name=\"IDG\"):\n",
    "    \"\"\"Create a comprehensive pivot table with weeks as super columns and periods as sub-columns, including target data\"\"\"\n",
    "    \n",
    "    print(f\"\\nüîÑ Creating {table_name} Pivot Table with Target Data\")\n",
    "    print(f\"üè∑Ô∏è Type Filter: {type_filter or 'None (All Types)'}\")\n",
    "    \n",
    "    # Process target data based on type filter\n",
    "    # Map type_filter to appropriate channel for target data\n",
    "    target_channel_filter = None\n",
    "    if type_filter == \"EA\":\n",
    "        target_channel_filter = \"EA\"\n",
    "    elif type_filter == \"Jumbo.ae\":\n",
    "        target_channel_filter = \"Jumbo.ae\"\n",
    "    # For Overall analysis (type_filter=None), we use all channels\n",
    "    \n",
    "    print(f\"üéØ Processing target data with channel filter: {target_channel_filter or 'ALL CHANNELS'}\")\n",
    "    target_by_week = process_target_data_by_week_and_channel(target_channel_filter)\n",
    "    \n",
    "    # Process all sheets with optional TYPE filter\n",
    "    # Using display_name as the key in the dictionary instead of sheet_name\n",
    "    sheet_data = {}\n",
    "    for path, sheet_name, display_name in sheet_info:\n",
    "        print(f\"üìÑ Processing {display_name} data...\")\n",
    "        sheet_data[display_name] = process_sheet_data_by_type(path, sheet_name, display_name, type_filter)\n",
    "    \n",
    "    # Get all unique IDG values across all sheets and target data\n",
    "    all_idgs = set()\n",
    "    for data in sheet_data.values():\n",
    "        all_idgs.update(data.index)\n",
    "    \n",
    "    # Add IDGs from target data if available\n",
    "    if not target_by_week.empty:\n",
    "        all_idgs.update(target_by_week.columns)\n",
    "        print(f\"üéØ Target IDGs found: {list(target_by_week.columns)}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è No target data available for filter: {target_channel_filter}\")\n",
    "    \n",
    "    all_idgs = sorted(list(all_idgs))\n",
    "    print(f\"üìã Combined IDGs: {all_idgs}\")\n",
    "    \n",
    "    # Calculate maximum week number across all data\n",
    "    max_week = 1\n",
    "    for data in sheet_data.values():\n",
    "        if len(data.columns) > 0:\n",
    "            max_week = max(max_week, max(data.columns))\n",
    "    \n",
    "    if not target_by_week.empty and len(target_by_week.index) > 0:\n",
    "        max_week = max(max_week, max(target_by_week.index))\n",
    "    \n",
    "    print(f\"üìÖ Maximum week number: {max_week}\")\n",
    "    \n",
    "    # Create the comprehensive pivot table\n",
    "    weeks = list(range(1, max_week + 1))\n",
    "    \n",
    "    # Create multi-level column index with target, comparison columns and totals\n",
    "    # Order: Last Month, Last Year, Target, Current Month, vs Target %, vs Last Year %, vs Last Month %\n",
    "    column_tuples = []\n",
    "    for week in weeks:\n",
    "        week_label = get_week_label(week)\n",
    "        # Add period columns in specific order\n",
    "        column_tuples.append((week_label, LAST_MONTH_DISPLAY))\n",
    "        column_tuples.append((week_label, LAST_YEAR_DISPLAY))\n",
    "        column_tuples.append((week_label, 'Target'))\n",
    "        column_tuples.append((week_label, CURRENT_DISPLAY))\n",
    "        # Add comparison columns\n",
    "        column_tuples.append((week_label, 'v/s Target %'))\n",
    "        column_tuples.append((week_label, 'v/s Last Year %'))\n",
    "        column_tuples.append((week_label, 'v/s Last Month %'))\n",
    "    # Add Total columns in same order\n",
    "    column_tuples.append(('Total', LAST_MONTH_DISPLAY))\n",
    "    column_tuples.append(('Total', LAST_YEAR_DISPLAY))\n",
    "    column_tuples.append(('Total', 'Target'))\n",
    "    column_tuples.append(('Total', CURRENT_DISPLAY))\n",
    "    column_tuples.append(('Total', 'v/s Target %'))\n",
    "    column_tuples.append(('Total', 'v/s Last Year %'))\n",
    "    column_tuples.append(('Total', 'v/s Last Month %'))\n",
    "    \n",
    "    multi_columns = pd.MultiIndex.from_tuples(column_tuples, names=['Week', 'Period'])\n",
    "    \n",
    "    # Create the final dataframe\n",
    "    final_df = pd.DataFrame(index=all_idgs, columns=multi_columns)\n",
    "    \n",
    "    # Fill the dataframe with data and calculate comparisons\n",
    "    for idg in all_idgs:\n",
    "        for week in weeks:\n",
    "            week_label = get_week_label(week)\n",
    "            \n",
    "            # Fill period data\n",
    "            for period in periods:\n",
    "                if period in sheet_data and idg in sheet_data[period].index and week in sheet_data[period].columns:\n",
    "                    final_df.loc[idg, (week_label, period)] = sheet_data[period].loc[idg, week]\n",
    "                else:\n",
    "                    final_df.loc[idg, (week_label, period)] = 0\n",
    "            \n",
    "            # Fill target data\n",
    "            if not target_by_week.empty and week in target_by_week.index and idg in target_by_week.columns:\n",
    "                final_df.loc[idg, (week_label, 'Target')] = target_by_week.loc[week, idg]\n",
    "            else:\n",
    "                final_df.loc[idg, (week_label, 'Target')] = 0\n",
    "            \n",
    "            # Calculate comparison percentages for each IDG and week\n",
    "            current_val = final_df.loc[idg, (week_label, CURRENT_DISPLAY)]\n",
    "            last_year_val = final_df.loc[idg, (week_label, LAST_YEAR_DISPLAY)]\n",
    "            last_month_val = final_df.loc[idg, (week_label, LAST_MONTH_DISPLAY)]\n",
    "            target_val = final_df.loc[idg, (week_label, 'Target')]\n",
    "            \n",
    "            # v/s Target %\n",
    "            if target_val != 0:\n",
    "                vs_target = (current_val / target_val * 100)  # Changed formula\n",
    "                final_df.loc[idg, (week_label, 'v/s Target %')] = round(vs_target, 2)\n",
    "            else:\n",
    "                final_df.loc[idg, (week_label, 'v/s Target %')] = 0 if current_val == 0 else float('inf') # Or handle as per requirement for 0 target\n",
    "            \n",
    "            # v/s Last Year %\n",
    "            if last_year_val != 0:\n",
    "                vs_last_year = ((current_val - last_year_val) / last_year_val * 100)\n",
    "                final_df.loc[idg, (week_label, 'v/s Last Year %')] = round(vs_last_year, 2)\n",
    "            else:\n",
    "                final_df.loc[idg, (week_label, 'v/s Last Year %')] = 0 if current_val == 0 else float('inf')\n",
    "            \n",
    "            # v/s Last Month %\n",
    "            if last_month_val != 0:\n",
    "                vs_last_month = ((current_val - last_month_val) / last_month_val * 100)\n",
    "                final_df.loc[idg, (week_label, 'v/s Last Month %')] = round(vs_last_month, 2)\n",
    "            else:\n",
    "                final_df.loc[idg, (week_label, 'v/s Last Month %')] = 0 if current_val == 0 else float('inf')\n",
    "    \n",
    "    # Fill NaN values with 0\n",
    "    final_df = final_df.fillna(0)\n",
    "    \n",
    "    # Calculate Total columns for each IDG\n",
    "    for idg in all_idgs:\n",
    "        # Calculate totals for each period across all weeks\n",
    "        for period in periods:\n",
    "            period_cols = [col for col in final_df.columns if col[1] == period and col[0] != 'Total']\n",
    "            total_value = final_df.loc[idg, period_cols].sum()\n",
    "            final_df.loc[idg, ('Total', period)] = total_value\n",
    "        \n",
    "        # Calculate total for target\n",
    "        target_cols = [col for col in final_df.columns if col[1] == 'Target' and col[0] != 'Total']\n",
    "        total_target = final_df.loc[idg, target_cols].sum()\n",
    "        final_df.loc[idg, ('Total', 'Target')] = total_target\n",
    "        \n",
    "        # Calculate total comparison percentages\n",
    "        total_current = final_df.loc[idg, ('Total', CURRENT_DISPLAY)]\n",
    "        total_last_year = final_df.loc[idg, ('Total', LAST_YEAR_DISPLAY)]\n",
    "        total_last_month = final_df.loc[idg, ('Total', LAST_MONTH_DISPLAY)]\n",
    "        total_target = final_df.loc[idg, ('Total', 'Target')]\n",
    "        \n",
    "        # Total v/s Target %\n",
    "        if total_target != 0:\n",
    "            total_vs_target = (total_current / total_target * 100)  # Changed formula\n",
    "            final_df.loc[idg, ('Total', 'v/s Target %')] = round(total_vs_target, 2)\n",
    "        else:\n",
    "            final_df.loc[idg, ('Total', 'v/s Target %')] = 0 if total_current == 0 else float('inf') # Or handle as per requirement for 0 target\n",
    "        \n",
    "        # Total v/s Last Year %\n",
    "        if total_last_year != 0:\n",
    "            total_vs_last_year = ((total_current - total_last_year) / total_last_year * 100)\n",
    "            final_df.loc[idg, ('Total', 'v/s Last Year %')] = round(total_vs_last_year, 2)\n",
    "        else:\n",
    "            final_df.loc[idg, ('Total', 'v/s Last Year %')] = 0 if total_current == 0 else float('inf')\n",
    "        \n",
    "        # Total v/s Last Month %\n",
    "        if total_last_month != 0:\n",
    "            total_vs_last_month = ((total_current - total_last_month) / total_last_month * 100)\n",
    "            final_df.loc[idg, ('Total', 'v/s Last Month %')] = round(total_vs_last_month, 2)\n",
    "        else:\n",
    "            final_df.loc[idg, ('Total', 'v/s Last Month %')] = 0 if total_current == 0 else float('inf')\n",
    "    \n",
    "    # Add Total row for all IDGs combined\n",
    "    total_row_data = {}\n",
    "    for col in final_df.columns:\n",
    "        if 'v/s' in col[1]:  # For percentage columns, calculate weighted averages\n",
    "            if col[1] in ['v/s Target %', 'v/s Last Year %', 'v/s Last Month %']:\n",
    "                # Calculate overall percentage for the total row\n",
    "                if col[0] == 'Total':  # Total column\n",
    "                    total_current = final_df[('Total', CURRENT_DISPLAY)].sum()\n",
    "                    total_base = 0\n",
    "                    if col[1] == 'v/s Target %':\n",
    "                        total_base = final_df[('Total', 'Target')].sum()\n",
    "                    elif col[1] == 'v/s Last Year %':\n",
    "                        total_base = final_df[('Total', LAST_YEAR_DISPLAY)].sum()\n",
    "                    else:  # v/s Last Month %\n",
    "                        total_base = final_df[('Total', LAST_MONTH_DISPLAY)].sum()\n",
    "                    \n",
    "                    if total_base != 0:\n",
    "                        if col[1] == 'v/s Target %':\n",
    "                            total_percentage = (total_current / total_base * 100) # Changed formula\n",
    "                        else:\n",
    "                            total_percentage = ((total_current - total_base) / total_base * 100)\n",
    "                        total_row_data[col] = round(total_percentage, 2)\n",
    "                    else:\n",
    "                        total_row_data[col] = 0\n",
    "                else:  # Week-wise percentage columns\n",
    "                    week_label = col[0]\n",
    "                    week_current = final_df[(week_label, CURRENT_DISPLAY)].sum()\n",
    "                    week_base = 0\n",
    "                    if col[1] == 'v/s Target %':\n",
    "                        week_base = final_df[(week_label, 'Target')].sum()\n",
    "                    elif col[1] == 'v/s Last Year %':\n",
    "                        week_base = final_df[(week_label, LAST_YEAR_DISPLAY)].sum()\n",
    "                    else:  # v/s Last Month %\n",
    "                        week_base = final_df[(week_label, LAST_MONTH_DISPLAY)].sum()\n",
    "                    \n",
    "                    if week_base != 0:\n",
    "                        if col[1] == 'v/s Target %':\n",
    "                            week_percentage = (week_current / week_base * 100) # Changed formula\n",
    "                        else:\n",
    "                            week_percentage = ((week_current - week_base) / week_base * 100)\n",
    "                        total_row_data[col] = round(week_percentage, 2)\n",
    "                    else:\n",
    "                        total_row_data[col] = 0\n",
    "        else:\n",
    "            # For amount columns, sum all IDGs\n",
    "            total_row_data[col] = final_df[col].sum()\n",
    "    \n",
    "    # Create total row as a DataFrame and concatenate\n",
    "    total_row_df = pd.DataFrame([total_row_data], index=['Total'])\n",
    "    final_df = pd.concat([final_df, total_row_df])\n",
    "    \n",
    "    print(f\"‚úÖ {table_name} pivot table created successfully!\")\n",
    "    print(f\"üìä Final shape: {final_df.shape}\")\n",
    "    \n",
    "    return final_df, all_idgs, max_week\n",
    "\n",
    "# Create three pivot tables: Overall, EA only, and Jumbo.ae only with Target Data\n",
    "print(\"üîÑ Creating Multiple Pivot Tables WITH TARGET DATA AND PROPER FILTERING...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# 1. Overall IDG Pivot Table (all data)\n",
    "print(\"\\nüìä 1. OVERALL IDG ANALYSIS (All Types) - WITH TARGET DATA\")\n",
    "print(\"-\" * 55)\n",
    "global_idg_pivot, all_idgs_global, max_week_global = create_comprehensive_pivot_table(\n",
    "    sheet_info, periods, type_filter=None, table_name=\"Overall IDG\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Data Shape: {global_idg_pivot.shape}\")\n",
    "print(f\"üè∑Ô∏è IDG Categories: {len(all_idgs_global)} (+ Total row)\")\n",
    "print(f\"üìÖ Periods: {periods} + Target + Comparisons\")\n",
    "print(f\"üìã Weeks analyzed: {max_week_global} (Starting day: {start_day}) + Total column\")\n",
    "\n",
    "# Summary statistics by period for overall\n",
    "print(\"\\nüìä SUMMARY BY PERIOD (Overall):\")\n",
    "for period in periods:\n",
    "    period_total = global_idg_pivot.loc['Total', ('Total', period)]\n",
    "    print(f\"  {period}: {period_total:,.2f}\")\n",
    "target_total = global_idg_pivot.loc['Total', ('Total', 'Target')]\n",
    "print(f\"  Target: {target_total:,.2f}\")\n",
    "\n",
    "print(\"\\nüìã Overall IDG Pivot Table (with Target):\")\n",
    "display(global_idg_pivot.round(2))\n",
    "\n",
    "# 2. EA Only Pivot Table\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä 2. EA ONLY ANALYSIS - WITH TARGET DATA\")\n",
    "print(\"-\" * 45)\n",
    "ea_idg_pivot, all_idgs_ea, max_week_ea = create_comprehensive_pivot_table(\n",
    "    sheet_info, periods, type_filter=\"EA\", table_name=\"EA IDG\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Data Shape: {ea_idg_pivot.shape}\")\n",
    "print(f\"üè∑Ô∏è IDG Categories: {len(all_idgs_ea)} (+ Total row)\")\n",
    "print(f\"üìÖ Periods: {periods} + Target + Comparisons\")\n",
    "print(f\"üìã Weeks analyzed: {max_week_ea} (Starting day: {start_day}) + Total column\")\n",
    "\n",
    "# Summary statistics by period for EA\n",
    "print(\"\\nüìä SUMMARY BY PERIOD (EA Only):\")\n",
    "for period in periods:\n",
    "    period_total = ea_idg_pivot.loc['Total', ('Total', period)]\n",
    "    print(f\"  {period}: {period_total:,.2f}\")\n",
    "target_total_ea = ea_idg_pivot.loc['Total', ('Total', 'Target')]\n",
    "print(f\"  Target: {target_total_ea:,.2f}\")\n",
    "\n",
    "print(\"\\nüìã EA Only IDG Pivot Table (with Target):\")\n",
    "display(ea_idg_pivot.round(2))\n",
    "\n",
    "# 3. Jumbo.ae Only Pivot Table\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üìä 3. JUMBO.AE ONLY ANALYSIS - WITH TARGET DATA\")\n",
    "print(\"-\" * 50)\n",
    "jumbo_idg_pivot, all_idgs_jumbo, max_week_jumbo = create_comprehensive_pivot_table(\n",
    "    sheet_info, periods, type_filter=\"Jumbo.ae\", table_name=\"Jumbo.ae IDG\"\n",
    ")\n",
    "\n",
    "print(f\"\\nüìä Data Shape: {jumbo_idg_pivot.shape}\")\n",
    "print(f\"üè∑Ô∏è IDG Categories: {len(all_idgs_jumbo)} (+ Total row)\")\n",
    "print(f\"üìÖ Periods: {periods} + Target + Comparisons\")\n",
    "print(f\"üìã Weeks analyzed: {max_week_jumbo} (Starting day: {start_day}) + Total column\")\n",
    "\n",
    "# Summary statistics by period for Jumbo.ae\n",
    "print(\"\\nüìä SUMMARY BY PERIOD (Jumbo.ae Only):\")\n",
    "for period in periods:\n",
    "    period_total = jumbo_idg_pivot.loc['Total', ('Total', period)]\n",
    "    print(f\"  {period}: {period_total:,.2f}\")\n",
    "target_total_jumbo = jumbo_idg_pivot.loc['Total', ('Total', 'Target')]\n",
    "print(f\"  Target: {target_total_jumbo:,.2f}\")\n",
    "\n",
    "print(\"\\nüìã Jumbo.ae Only IDG Pivot Table (with Target):\")\n",
    "display(jumbo_idg_pivot.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ ALL PIVOT TABLES WITH TARGET DATA CREATED SUCCESSFULLY!\")\n",
    "print(\"üìä Summary:\")\n",
    "print(f\"   ‚Ä¢ Overall Analysis: {len(all_idgs_global)} IDGs, {max_week_global} weeks\")\n",
    "print(f\"   ‚Ä¢ EA Analysis: {len(all_idgs_ea)} IDGs, {max_week_ea} weeks\")\n",
    "print(f\"   ‚Ä¢ Jumbo.ae Analysis: {len(all_idgs_jumbo)} IDGs, {max_week_jumbo} weeks\")\n",
    "print(f\"   ‚Ä¢ Each table includes: {len(periods)} periods + Target + vs Target % + comparisons + totals\")\n",
    "print(f\"   ‚Ä¢ Column order: Last Month, Last Year, Target, Current Month, vs Target %, vs Last Year %, vs Last Month %\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02896dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDG Analysis Report - Multiple Pivot Tables\n",
    "\n",
    "# Additional pivot table views for all three analyses\n",
    "\n",
    "# Weekly Analysis Views\n",
    "\n",
    "# 1. Show first few weeks detailed view for Overall analysis\n",
    "print(\"üìä OVERALL ANALYSIS - First 3 Weeks IDG Data\")\n",
    "print(\"=\" * 50)\n",
    "first_weeks_cols = []\n",
    "for week in range(1, min(4, max_week_global + 1)):  # First 3 weeks or max available\n",
    "    week_label = get_week_label(week)\n",
    "    for period in periods:  # Use dynamic periods instead of hardcoded values\n",
    "        first_weeks_cols.append((week_label, period))\n",
    "\n",
    "if first_weeks_cols:  # Only if we have data\n",
    "    first_weeks_data = global_idg_pivot[first_weeks_cols]\n",
    "    display(first_weeks_data.round(2))\n",
    "else:\n",
    "    print(\"No week data available\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "# 2. Weekly totals comparison for Overall analysis\n",
    "print(\"üìà OVERALL ANALYSIS - Weekly Totals Comparison\")\n",
    "print(\"=\" * 45)\n",
    "weekly_totals = pd.DataFrame(index=range(1, max_week_global + 1), columns=periods)  # Use dynamic periods\n",
    "\n",
    "for week in range(1, max_week_global + 1):\n",
    "    week_label = get_week_label(week)\n",
    "    for period in periods:  # Use dynamic periods\n",
    "        week_period_cols = [(week_label, period)]\n",
    "        weekly_total = global_idg_pivot[week_period_cols].sum().sum()\n",
    "        weekly_totals.loc[week, period] = weekly_total\n",
    "\n",
    "# Convert to numeric and add growth percentages\n",
    "weekly_totals = weekly_totals.astype(float)\n",
    "weekly_totals['Current_vs_LastYear_%'] = ((weekly_totals[CURRENT_DISPLAY] - weekly_totals[LAST_YEAR_DISPLAY]) / weekly_totals[LAST_YEAR_DISPLAY] * 100).round(2)\n",
    "weekly_totals['Current_vs_LastMonth_%'] = ((weekly_totals[CURRENT_DISPLAY] - weekly_totals[LAST_MONTH_DISPLAY]) / weekly_totals[LAST_MONTH_DISPLAY] * 100).round(2)\n",
    "\n",
    "# Add week labels for better readability\n",
    "weekly_totals.index = [get_week_label(week) for week in range(1, max_week_global + 1)]\n",
    "\n",
    "display(weekly_totals.round(2))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 50)\n",
    "\n",
    "# 3. IDG totals by period (summary pivot) for Overall analysis\n",
    "print(\"üìã OVERALL ANALYSIS - IDG Totals by Period (Week-based)\")\n",
    "print(\"=\" * 55)\n",
    "idg_period_summary = pd.DataFrame(index=all_idgs_global, columns=periods)  # Use dynamic periods\n",
    "\n",
    "for idg in all_idgs_global:\n",
    "    for period in periods:  # Use dynamic periods\n",
    "        period_cols = [col for col in global_idg_pivot.columns if col[1] == period]\n",
    "        idg_period_summary.loc[idg, period] = global_idg_pivot.loc[idg, period_cols].sum()\n",
    "\n",
    "# Convert to numeric and add totals\n",
    "idg_period_summary = idg_period_summary.astype(float)\n",
    "idg_period_summary['Total'] = idg_period_summary.sum(axis=1)\n",
    "idg_period_summary.loc['Total'] = idg_period_summary.sum()\n",
    "\n",
    "display(idg_period_summary.round(2))\n",
    "\n",
    "# 4. Quick comparison between the three analyses\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä COMPARISON SUMMARY - All Three Analyses\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Create summary comparison\n",
    "comparison_summary = pd.DataFrame({\n",
    "    'Analysis_Type': ['Overall', 'EA Only', 'Jumbo.ae Only'],\n",
    "    'IDG_Count': [len(all_idgs_global), len(all_idgs_ea), len(all_idgs_jumbo)],\n",
    "    'Max_Weeks': [max_week_global, max_week_ea, max_week_jumbo]\n",
    "})\n",
    "\n",
    "# Add period totals for each analysis\n",
    "for period in periods:\n",
    "    comparison_summary[f'{period}_Total'] = [\n",
    "        global_idg_pivot.loc['Total', ('Total', period)],\n",
    "        ea_idg_pivot.loc['Total', ('Total', period)],\n",
    "        jumbo_idg_pivot.loc['Total', ('Total', period)]\n",
    "    ]\n",
    "\n",
    "print(\"Summary of All Three Pivot Table Analyses:\")\n",
    "display(comparison_summary.round(2))\n",
    "\n",
    "print(\"\\nüìà Key Insights:\")\n",
    "print(f\"‚Ä¢ Overall analysis covers {len(all_idgs_global)} IDG categories across {max_week_global} weeks\")\n",
    "print(f\"‚Ä¢ EA analysis covers {len(all_idgs_ea)} IDG categories across {max_week_ea} weeks\")\n",
    "print(f\"‚Ä¢ Jumbo.ae analysis covers {len(all_idgs_jumbo)} IDG categories across {max_week_jumbo} weeks\")\n",
    "print(f\"‚Ä¢ Each analysis includes {len(periods)} periods: {', '.join(periods)}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215d1066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weekly Comparison Analysis - Focused View for All Three Analyses\n",
    "print(\"üìä COMPREHENSIVE GROWTH COMPARISON ANALYSIS\")\n",
    "print(\"=\" * 55)\n",
    "\n",
    "def analyze_growth_patterns(pivot_table, all_idgs, max_week, analysis_name):\n",
    "    \"\"\"Analyze growth patterns for a given pivot table\"\"\"\n",
    "    print(f\"\\nüîç {analysis_name.upper()} ANALYSIS - Growth Patterns\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    # Create a focused view showing only comparison percentages\n",
    "    comparison_cols = []\n",
    "    for week in range(1, max_week + 1):\n",
    "        week_label = get_week_label(week)\n",
    "        comparison_cols.extend([\n",
    "            (week_label, 'v/s Last Year %'),\n",
    "            (week_label, 'v/s Last Month %')\n",
    "        ])\n",
    "    \n",
    "    if comparison_cols:\n",
    "        comparison_data = pivot_table[comparison_cols]\n",
    "        print(f\"\\nüìà {analysis_name} - Growth Percentages by Week:\")\n",
    "        display(comparison_data.round(2))\n",
    "        \n",
    "        # Calculate average growth rates\n",
    "        print(f\"\\nüìä {analysis_name} - Average Growth Rates Across All Weeks:\")\n",
    "        print(\"-\" * 45)\n",
    "        \n",
    "        # Get all v/s Last Year columns\n",
    "        last_year_cols = [col for col in comparison_data.columns if 'v/s Last Year %' in col[1]]\n",
    "        last_month_cols = [col for col in comparison_data.columns if 'v/s Last Month %' in col[1]]\n",
    "        \n",
    "        for idg in all_idgs:\n",
    "            avg_vs_last_year = comparison_data.loc[idg, last_year_cols].replace([float('inf'), -float('inf')], 0).mean()\n",
    "            avg_vs_last_month = comparison_data.loc[idg, last_month_cols].replace([float('inf'), -float('inf')], 0).mean()\n",
    "            print(f\"{idg:15s} | Avg vs Last Year: {avg_vs_last_year:6.1f}% | Avg vs Last Month: {avg_vs_last_month:6.1f}%\")\n",
    "        \n",
    "        # Weekly summary of overall performance\n",
    "        print(f\"\\nüìã {analysis_name} - Weekly Performance Summary (All IDGs Combined):\")\n",
    "        print(\"-\" * 55)\n",
    "        \n",
    "        weekly_performance = pd.DataFrame(index=range(1, max_week + 1), \n",
    "                                        columns=['vs_Last_Year_%', 'vs_Last_Month_%'])\n",
    "        \n",
    "        for week in range(1, max_week + 1):\n",
    "            week_label = get_week_label(week)\n",
    "            \n",
    "            # Calculate total amounts for the week using dynamic period names\n",
    "            current_total = pivot_table[(week_label, CURRENT_DISPLAY)].sum()\n",
    "            last_year_total = pivot_table[(week_label, LAST_YEAR_DISPLAY)].sum()\n",
    "            last_month_total = pivot_table[(week_label, LAST_MONTH_DISPLAY)].sum()\n",
    "            \n",
    "            # Calculate overall percentage changes\n",
    "            if last_year_total != 0:\n",
    "                vs_last_year = ((current_total - last_year_total) / last_year_total * 100)\n",
    "                weekly_performance.loc[week, 'vs_Last_Year_%'] = round(vs_last_year, 2)\n",
    "            else:\n",
    "                weekly_performance.loc[week, 'vs_Last_Year_%'] = 0\n",
    "                \n",
    "            if last_month_total != 0:\n",
    "                vs_last_month = ((current_total - last_month_total) / last_month_total * 100)\n",
    "                weekly_performance.loc[week, 'vs_Last_Month_%'] = round(vs_last_month, 2)\n",
    "            else:\n",
    "                weekly_performance.loc[week, 'vs_Last_Month_%'] = 0\n",
    "        \n",
    "        # Add week labels for better readability\n",
    "        weekly_performance.index = [get_week_label(week) for week in range(1, max_week + 1)]\n",
    "        \n",
    "        display(weekly_performance)\n",
    "        \n",
    "        return weekly_performance\n",
    "    else:\n",
    "        print(f\"No comparison data available for {analysis_name}\")\n",
    "        return None\n",
    "\n",
    "# Analyze all three pivot tables\n",
    "overall_performance = analyze_growth_patterns(global_idg_pivot, all_idgs_global, max_week_global, \"Overall\")\n",
    "ea_performance = analyze_growth_patterns(ea_idg_pivot, all_idgs_ea, max_week_ea, \"EA Only\")\n",
    "jumbo_performance = analyze_growth_patterns(jumbo_idg_pivot, all_idgs_jumbo, max_week_jumbo, \"Jumbo.ae Only\")\n",
    "\n",
    "# Cross-analysis comparison\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üîÑ CROSS-ANALYSIS PERFORMANCE COMPARISON\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "if overall_performance is not None and ea_performance is not None and jumbo_performance is not None:\n",
    "    # Compare average performance across all analyses\n",
    "    cross_comparison = pd.DataFrame({\n",
    "        'Analysis': ['Overall', 'EA Only', 'Jumbo.ae Only'],\n",
    "        'Avg_Growth_vs_Last_Year_%': [\n",
    "            overall_performance['vs_Last_Year_%'].mean(),\n",
    "            ea_performance['vs_Last_Year_%'].mean(),\n",
    "            jumbo_performance['vs_Last_Year_%'].mean()\n",
    "        ],\n",
    "        'Avg_Growth_vs_Last_Month_%': [\n",
    "            overall_performance['vs_Last_Month_%'].mean(),\n",
    "            ea_performance['vs_Last_Month_%'].mean(),\n",
    "            jumbo_performance['vs_Last_Month_%'].mean()\n",
    "        ]\n",
    "    })\n",
    "    \n",
    "    print(\"üìä Average Growth Rates Comparison:\")\n",
    "    display(cross_comparison.round(2))\n",
    "    \n",
    "    # Best and worst performing analysis types\n",
    "    best_vs_year = cross_comparison.loc[cross_comparison['Avg_Growth_vs_Last_Year_%'].idxmax(), 'Analysis']\n",
    "    best_vs_month = cross_comparison.loc[cross_comparison['Avg_Growth_vs_Last_Month_%'].idxmax(), 'Analysis']\n",
    "    \n",
    "    print(f\"\\n‚úÖ Performance Highlights:\")\n",
    "    print(f\"‚Ä¢ Best performing vs Last Year: {best_vs_year}\")\n",
    "    print(f\"‚Ä¢ Best performing vs Last Month: {best_vs_month}\")\n",
    "else:\n",
    "    print(\"Could not complete cross-analysis comparison\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ COMPREHENSIVE GROWTH ANALYSIS COMPLETE\")\n",
    "print(\"üìä All three pivot tables analyzed for growth patterns\")\n",
    "print(\"üìà Weekly performance trends calculated and compared\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0cec4c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export All IDG Pivot Tables to Excel - Combined in Single Sheet\n",
    "print(\"üì§ EXPORTING ALL THREE PIVOT TABLES TO SINGLE EXCEL SHEET...\")\n",
    "print(\"=\" * 65)\n",
    "\n",
    "# Create Excel writer object\n",
    "output_file = 'IDG_Weekly_Analysis_Combined.xlsx'\n",
    "with pd.ExcelWriter(output_file, engine='openpyxl') as writer:\n",
    "    \n",
    "    # Create combined sheet with all three analyses\n",
    "    print(\"üìä Creating Combined IDG Analysis Sheet...\")\n",
    "    \n",
    "    # Create a workbook and worksheet - ensure we have a proper worksheet\n",
    "    workbook = writer.book\n",
    "    # Remove default sheet if it exists\n",
    "    if workbook.worksheets:\n",
    "        workbook.remove(workbook.active)\n",
    "    \n",
    "    # Create our main worksheet\n",
    "    worksheet = workbook.create_sheet('Combined_IDG_Analysis', 0)\n",
    "    \n",
    "    # Define styles for different sections\n",
    "    main_title_font = Font(bold=True, size=14, color='FFFFFF')\n",
    "    main_title_fill = PatternFill(start_color='1F4E79', end_color='1F4E79', fill_type='solid')\n",
    "    \n",
    "    section_header_font = Font(bold=True, size=12, color='FFFFFF')\n",
    "    section_header_fill = PatternFill(start_color='366092', end_color='366092', fill_type='solid')\n",
    "    \n",
    "    column_header_font = Font(bold=True, size=10, color='FFFFFF')\n",
    "    column_header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')\n",
    "    \n",
    "    idg_name_font = Font(bold=True, size=9)\n",
    "    idg_name_fill = PatternFill(start_color='F2F2F2', end_color='F2F2F2', fill_type='solid')\n",
    "    \n",
    "    number_format = '#,##0.00'\n",
    "    thin_border = Border(\n",
    "        left=Side(style='thin'), right=Side(style='thin'),\n",
    "        top=Side(style='thin'), bottom=Side(style='thin')\n",
    "    )\n",
    "    \n",
    "    # MODIFIED Function to write a single pivot table to a dedicated worksheet\n",
    "    def write_pivot_table_to_sheet(pivot_df, analysis_title, worksheet):\n",
    "        # Section title for the sheet\n",
    "        worksheet.cell(row=1, column=1, value=analysis_title)\n",
    "        title_cell = worksheet.cell(row=1, column=1)\n",
    "        title_cell.font = section_header_font # Use section_header_font for individual sheet titles\n",
    "        title_cell.fill = section_header_fill\n",
    "        title_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "        \n",
    "        # Merge cells for the title across all columns of the pivot table\n",
    "        num_cols = len(pivot_df.columns)\n",
    "        worksheet.merge_cells(start_row=1, start_column=1, \n",
    "                            end_row=1, end_column=num_cols + 1) # +1 for the IDG column\n",
    "        \n",
    "        # Apply border to title\n",
    "        for col_idx_merge in range(1, num_cols + 2):\n",
    "            worksheet.cell(row=1, column=col_idx_merge).border = thin_border\n",
    "        \n",
    "        current_row = 2 # Start headers from row 2\n",
    "        \n",
    "        # Write column headers (multi-level)\n",
    "        # First level headers (Week labels)\n",
    "        col_idx = 2  # Start from column 2 (column 1 is for IDG names)\n",
    "        for week_label in pivot_df.columns.get_level_values(0).unique():\n",
    "            week_cols = [col for col in pivot_df.columns if col[0] == week_label]\n",
    "            num_sub_cols = len(week_cols)\n",
    "            \n",
    "            worksheet.cell(row=current_row, column=col_idx, value=week_label)\n",
    "            week_cell = worksheet.cell(row=current_row, column=col_idx)\n",
    "            week_cell.font = column_header_font\n",
    "            week_cell.fill = column_header_fill\n",
    "            week_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            week_cell.border = thin_border\n",
    "            \n",
    "            if num_sub_cols > 1:\n",
    "                worksheet.merge_cells(start_row=current_row, start_column=col_idx,\n",
    "                                    end_row=current_row, end_column=col_idx + num_sub_cols - 1)\n",
    "                for i in range(num_sub_cols):\n",
    "                    cell = worksheet.cell(row=current_row, column=col_idx + i)\n",
    "                    cell.font = column_header_font\n",
    "                    cell.fill = column_header_fill\n",
    "                    cell.border = thin_border\n",
    "            col_idx += num_sub_cols\n",
    "        \n",
    "        current_row += 1\n",
    "        \n",
    "        # Second level headers (Period names)\n",
    "        worksheet.cell(row=current_row, column=1, value=\"IDG\")\n",
    "        idg_header_cell = worksheet.cell(row=current_row, column=1)\n",
    "        idg_header_cell.font = column_header_font\n",
    "        idg_header_cell.fill = column_header_fill\n",
    "        idg_header_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "        idg_header_cell.border = thin_border\n",
    "        \n",
    "        col_idx = 2\n",
    "        for col_multi_idx in pivot_df.columns:\n",
    "            worksheet.cell(row=current_row, column=col_idx, value=col_multi_idx[1])\n",
    "            sub_header_cell = worksheet.cell(row=current_row, column=col_idx)\n",
    "            sub_header_cell.font = column_header_font\n",
    "            sub_header_cell.fill = column_header_fill\n",
    "            sub_header_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            sub_header_cell.border = thin_border\n",
    "            col_idx += 1\n",
    "        \n",
    "        current_row += 1\n",
    "        \n",
    "        # Write data rows\n",
    "        for idg_name in pivot_df.index:\n",
    "            worksheet.cell(row=current_row, column=1, value=idg_name)\n",
    "            name_cell = worksheet.cell(row=current_row, column=1)\n",
    "            if idg_name == 'Total':\n",
    "                name_cell.font = Font(bold=True, size=10)\n",
    "                name_cell.fill = PatternFill(start_color='FFE699', end_color='FFE699', fill_type='solid')\n",
    "            else:\n",
    "                name_cell.font = idg_name_font\n",
    "                name_cell.fill = idg_name_fill\n",
    "            name_cell.alignment = Alignment(horizontal='left', vertical='center')\n",
    "            name_cell.border = thin_border\n",
    "            \n",
    "            col_idx = 2\n",
    "            for col_multi_idx in pivot_df.columns:\n",
    "                value = pivot_df.loc[idg_name, col_multi_idx]\n",
    "                worksheet.cell(row=current_row, column=col_idx, value=value)\n",
    "                data_cell = worksheet.cell(row=current_row, column=col_idx)\n",
    "                \n",
    "                if idg_name == 'Total':\n",
    "                    data_cell.font = Font(bold=True, size=9)\n",
    "                    data_cell.fill = PatternFill(start_color='FFE699', end_color='FFE699', fill_type='solid')\n",
    "                else:\n",
    "                    data_cell.font = Font(size=9)\n",
    "                \n",
    "                if 'v/s' in col_multi_idx[1] and '%' in col_multi_idx[1]:\n",
    "                    data_cell.number_format = '0.00\"%\"'\n",
    "                    if isinstance(value, (int, float)) and value != float('inf') and value != float('-inf') and value != 0 : # Check for valid numeric value\n",
    "                        if col_multi_idx[1] == 'v/s Target %':\n",
    "                            if value >= 100:\n",
    "                                data_cell.font = Font(color='008000', size=9, bold=idg_name=='Total')\n",
    "                            else:\n",
    "                                data_cell.font = Font(color='FF0000', size=9, bold=idg_name=='Total')\n",
    "                        else:\n",
    "                            if value > 0:\n",
    "                                data_cell.font = Font(color='008000', size=9, bold=idg_name=='Total')\n",
    "                            elif value < 0:\n",
    "                                data_cell.font = Font(color='FF0000', size=9, bold=idg_name=='Total')\n",
    "                else:\n",
    "                    data_cell.number_format = number_format\n",
    "                \n",
    "                data_cell.alignment = Alignment(horizontal='right', vertical='center')\n",
    "                data_cell.border = thin_border\n",
    "                col_idx += 1\n",
    "            current_row += 1\n",
    "            \n",
    "        # Auto-adjust column widths for this worksheet\n",
    "        for col_letter_idx in range(1, worksheet.max_column + 1):\n",
    "            max_length = 0\n",
    "            column_letter = get_column_letter(col_letter_idx)\n",
    "            for row_idx in range(1, worksheet.max_row + 1):\n",
    "                try:\n",
    "                    cell_value = str(worksheet.cell(row=row_idx, column=col_letter_idx).value)\n",
    "                    if len(cell_value) > max_length:\n",
    "                        max_length = len(cell_value)\n",
    "                except:\n",
    "                    pass\n",
    "            adjusted_width = min(max_length + 2, 30) # Max width of 30, increased padding\n",
    "            worksheet.column_dimensions[column_letter].width = adjusted_width\n",
    "\n",
    "        # Freeze panes for this worksheet (IDG name and headers)\n",
    "        # Freeze row 3 (headers) and column 1 (IDG names)\n",
    "        worksheet.freeze_panes = 'B1' # Top 3 rows and 1st column frozen\n",
    "\n",
    "    # Main Excel writing block\n",
    "    # Remove default sheet if it exists\n",
    "    if workbook.worksheets:\n",
    "        workbook.remove(workbook.active)\n",
    "    \n",
    "    # Data for sheets\n",
    "    analyses_to_export = [\n",
    "        {\"name\": \"Overall_IDG_Analysis\", \"title\": f\"OVERALL IDG ANALYSIS ({max_invoice_day} days)\", \"data\": global_idg_pivot},\n",
    "        {\"name\": \"EA_IDG_Analysis\", \"title\": f\"EA ONLY IDG ANALYSIS ({max_invoice_day} days)\", \"data\": ea_idg_pivot},\n",
    "        {\"name\": \"JumboAE_IDG_Analysis\", \"title\": f\"JUMBO.AE ONLY IDG ANALYSIS ({max_invoice_day} days)\", \"data\": jumbo_idg_pivot},\n",
    "    ]\n",
    "\n",
    "    sheet_idx_counter = 0\n",
    "    for analysis in analyses_to_export:\n",
    "        print(f\"  üìä Writing {analysis['title']} to sheet: {analysis['name']}...\")\n",
    "        ws = workbook.create_sheet(analysis['name'], sheet_idx_counter)\n",
    "        write_pivot_table_to_sheet(analysis['data'].round(2), analysis['title'], ws)\n",
    "        sheet_idx_counter += 1\n",
    "    \n",
    "    # Create additional supporting sheets (Summary Dashboard, Weekly Totals)\n",
    "    # These will be created after the individual analysis sheets.\n",
    "    \n",
    "    # 2. Summary Dashboard Sheet\n",
    "    print(\"üìä Creating Summary Dashboard...\")\n",
    "    summary_data = {\n",
    "        'Analysis_Type': ['Overall', 'EA Only', 'Jumbo.ae Only'],\n",
    "        'IDG_Categories': [len(all_idgs_global), len(all_idgs_ea), len(all_idgs_jumbo)],\n",
    "        'Weeks_Analyzed': [max_week_global, max_week_ea, max_week_jumbo]\n",
    "    }\n",
    "    \n",
    "    # Add period totals for each analysis\n",
    "    for period in periods:\n",
    "        summary_data[f'{period}_Total'] = [\n",
    "            global_idg_pivot.loc['Total', ('Total', period)],\n",
    "            ea_idg_pivot.loc['Total', ('Total', period)],\n",
    "            jumbo_idg_pivot.loc['Total', ('Total', period)]\n",
    "        ]\n",
    "    \n",
    "    # Add growth percentages\n",
    "    summary_data[f'Growth_vs_{LAST_YEAR_DISPLAY}_%'] = [\n",
    "        global_idg_pivot.loc['Total', ('Total', 'v/s Last Year %')],\n",
    "        ea_idg_pivot.loc['Total', ('Total', 'v/s Last Year %')],\n",
    "        jumbo_idg_pivot.loc['Total', ('Total', 'v/s Last Year %')]\n",
    "    ]\n",
    "    \n",
    "    summary_data[f'Growth_vs_{LAST_MONTH_DISPLAY}_%'] = [\n",
    "        global_idg_pivot.loc['Total', ('Total', 'v/s Last Month %')],\n",
    "        ea_idg_pivot.loc['Total', ('Total', 'v/s Last Month %')],\n",
    "        jumbo_idg_pivot.loc['Total', ('Total', 'v/s Last Month %')]\n",
    "    ]\n",
    "    \n",
    "    summary_df = pd.DataFrame(summary_data)\n",
    "    summary_df.round(2).to_excel(writer, sheet_name='Summary_Dashboard', index=False)\n",
    "    \n",
    "    # 3. Weekly Totals Summary (Overall)\n",
    "    print(\"üìä Creating Weekly Totals Summary...\")\n",
    "    weekly_totals = pd.DataFrame(index=range(1, max_week_global + 1), columns=periods)\n",
    "    \n",
    "    for week in range(1, max_week_global + 1):\n",
    "        week_label = get_week_label(week)\n",
    "        for period in periods:\n",
    "            week_period_cols = [(week_label, period)]\n",
    "            weekly_total = global_idg_pivot[week_period_cols].sum().sum()\n",
    "            weekly_totals.loc[week, period] = weekly_total\n",
    "    \n",
    "    # Add growth percentages using dynamic period names\n",
    "    weekly_totals = weekly_totals.astype(float)\n",
    "    weekly_totals['Growth_vs_LastYear_%'] = ((weekly_totals[CURRENT_DISPLAY] - weekly_totals[LAST_YEAR_DISPLAY]) / weekly_totals[LAST_YEAR_DISPLAY] * 100).round(2)\n",
    "    weekly_totals['Growth_vs_LastMonth_%'] = ((weekly_totals[CURRENT_DISPLAY] - weekly_totals[LAST_MONTH_DISPLAY]) / weekly_totals[LAST_MONTH_DISPLAY] * 100).round(2)\n",
    "    \n",
    "    # Add week labels\n",
    "    weekly_totals.index = [get_week_label(week) for week in range(1, max_week_global + 1)]\n",
    "    \n",
    "    # Export weekly totals\n",
    "    weekly_totals.round(2).to_excel(writer, sheet_name='Weekly_Totals', index=True)\n",
    "\n",
    "print(f\"\\n‚úÖ EXCEL EXPORT COMPLETED SUCCESSFULLY!\")\n",
    "print(f\"üìé File: {output_file}\")\n",
    "print(\"\\nüìä SHEETS CREATED:\")\n",
    "print(\"=\" * 50)\n",
    "print(\"üìÑ 1. Overall_IDG_Analysis - Overall IDG Analysis table\")\n",
    "print(\"üìÑ 2. EA_IDG_Analysis - EA Only IDG Analysis table\")\n",
    "print(\"üìÑ 3. JumboAE_IDG_Analysis - Jumbo.ae Only IDG Analysis table\")\n",
    "print(f\"üìÑ 4. Summary_Dashboard - Overview of all analyses\") # Adjusted numbering\n",
    "print(f\"üìÑ 5. Weekly_Totals - Weekly summary with growth\")   # Adjusted numbering\n",
    "\n",
    "print(f\"\\nüéÜ FEATURES APPLIED TO EACH ANALYSIS SHEET:\")\n",
    "print(f\"‚Ä¢ Dedicated sheet for each analysis: Overall, EA, Jumbo.ae\")\n",
    "print(f\"‚Ä¢ Professional multi-level header formatting\")\n",
    "print(f\"‚Ä¢ Color-coded percentages (Green: positive, Red: negative)\")\n",
    "print(f\"‚Ä¢ Highlighted Total columns and rows\")\n",
    "print(f\"‚Ä¢ Auto-adjusted column widths for readability\")\n",
    "print(f\"‚Ä¢ Frozen panes for easy navigation\")\n",
    "print(f\"‚Ä¢ Consistent number formatting across all sheets\")\n",
    "print(f\"‚Ä¢ Comprehensive analysis covering all three data types\")\n",
    "\n",
    "print(f\"\\nüìä ANALYSIS COVERAGE:\")\n",
    "print(f\"‚Ä¢ Overall: {len(all_idgs_global)} IDGs across {max_week_global} weeks\")\n",
    "print(f\"‚Ä¢ EA Only: {len(all_idgs_ea)} IDGs across {max_week_ea} weeks\")\n",
    "print(f\"‚Ä¢ Jumbo.ae: {len(all_idgs_jumbo)} IDGs across {max_week_jumbo} weeks\")\n",
    "print(f\"‚Ä¢ Periods: {', '.join(periods)}\")\n",
    "print(f\"‚Ä¢ Week calculation based on: {start_day} as first day\")\n",
    "\n",
    "print(f\"\\nüíæ File saved as: {output_file}\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87c10156",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dynamic constants for sessions\n",
    "LAST_MONTH_SESSION_PATH = sessions_info[0][0]\n",
    "LAST_MONTH_SESSION_SHEET = sessions_info[0][1]\n",
    "LAST_MONTH_SESSION_DISPLAY = sessions_info[0][2]\n",
    "\n",
    "LAST_YEAR_SESSION_PATH = sessions_info[1][0]\n",
    "LAST_YEAR_SESSION_SHEET = sessions_info[1][1]\n",
    "LAST_YEAR_SESSION_DISPLAY = sessions_info[1][2]\n",
    "\n",
    "CURRENT_SESSION_PATH = sessions_info[2][0]\n",
    "CURRENT_SESSION_SHEET = sessions_info[2][1]\n",
    "CURRENT_SESSION_DISPLAY = sessions_info[2][2]\n",
    "\n",
    "# Metrics to include in the pivot table\n",
    "METRICS_TO_AGGREGATE = ['Sessions', 'Purchases', 'Purchase revenue']\n",
    "\n",
    "def create_master_sessions_pivot(sessions_info, cg_filter=None):\n",
    "    \"\"\"\n",
    "    Create master sessions pivot table with optional CG column filtering\n",
    "    \n",
    "    Parameters:\n",
    "    sessions_info: List of tuples containing (path, sheet, display_name)\n",
    "    cg_filter: String indicating filter type:\n",
    "               - None: No filter (default)\n",
    "               - \"EA_only\": Only include \"EA\" or \"Endless Aisle\" \n",
    "               - \"non_EA\": Exclude \"EA\" or \"Endless Aisle\"\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Master pivot table with calculated metrics\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üìä SESSIONS DATA ANALYSIS - WEEKLY MASTER PIVOT\")\n",
    "    if cg_filter == \"EA_only\":\n",
    "        print(\"üîç Filter: EA/Endless Aisle ONLY\")\n",
    "    elif cg_filter == \"non_EA\":\n",
    "        print(\"üîç Filter: NON-EA/Endless Aisle\")\n",
    "    else:\n",
    "        print(\"üîç Filter: NO FILTER\")\n",
    "    print(\"=\" * 60)\n",
    "\n",
    "    processed_sessions_data = {}\n",
    "    all_channels = set()\n",
    "    max_week_overall = 0\n",
    "\n",
    "    # Read and process sessions data from all three periods\n",
    "    for i, (path, sheet, display_name) in enumerate(sessions_info):\n",
    "        print(f\"\\nüìÑ Processing {display_name} Sessions Data:\")\n",
    "        print(\"-\" * 40)\n",
    "\n",
    "        try:\n",
    "            # Read the sessions data\n",
    "            sessions_df = pd.read_excel(path, sheet_name=sheet)\n",
    "            print(f\"  Raw Shape: {sessions_df.shape}\")\n",
    "            print(f\"  Raw Columns: {list(sessions_df.columns)}\")\n",
    "            \n",
    "            # Filter out \"Gift Card\" from Category column if it exists\n",
    "            if 'Category' in sessions_df.columns:\n",
    "                sessions_df = sessions_df[sessions_df['Category'] != 'Gift Card ']\n",
    "                print(f\"  Shape after filtering 'Gift Card': {sessions_df.shape}\")\n",
    "            \n",
    "            # Apply CG filter if specified\n",
    "            if cg_filter and 'CG' in sessions_df.columns:\n",
    "                if cg_filter == \"EA_only\":\n",
    "                    sessions_df = sessions_df[sessions_df['CG'].isin(['EA', 'Endless Aisle'])]\n",
    "                    print(f\"  Shape after EA filter: {sessions_df.shape}\")\n",
    "                elif cg_filter == \"non_EA\":\n",
    "                    sessions_df = sessions_df[~sessions_df['CG'].isin(['EA', 'Endless Aisle'])]\n",
    "                    print(f\"  Shape after non-EA filter: {sessions_df.shape}\")\n",
    "            elif cg_filter and 'CG' not in sessions_df.columns:\n",
    "                print(f\"  Warning: CG column not found, filter '{cg_filter}' cannot be applied\")\n",
    "            \n",
    "            # Convert the string to datetime format first\n",
    "            sessions_df['Date'] = pd.to_datetime(sessions_df['Date'], format='%Y%m%d', errors='coerce')\n",
    "\n",
    "            # Then extract the day\n",
    "            sessions_df['Day'] = sessions_df['Date'].dt.day\n",
    "            \n",
    "\n",
    "\n",
    "            sessions_df = sessions_df.dropna(subset=['Day']) \n",
    "            if sessions_df.empty:\n",
    "                print(f\"  No valid 'Day' data after conversion for {display_name}.\")\n",
    "                processed_sessions_data[display_name] = pd.DataFrame()\n",
    "                continue\n",
    "\n",
    "            sessions_df['Day'] = sessions_df['Day'].astype(int)\n",
    "\n",
    "            original_len = len(sessions_df)\n",
    "            sessions_df = sessions_df[sessions_df['Day'] <= max_invoice_day]\n",
    "            print(f\"üìâ {display_name}: Filtered {original_len - len(sessions_df)} rows with Day > {max_invoice_day}\")\n",
    "\n",
    "            # Add WeekNumber column (ensure get_week_number and first_day_position are defined in a previous cell)\n",
    "            sessions_df['WeekNumber'] = sessions_df['Day'].apply(\n",
    "                lambda day: get_week_number(day, first_day_position) \n",
    "            )\n",
    "            \n",
    "            # Check which of the desired metrics are available in the current DataFrame\n",
    "            available_metrics = [m for m in METRICS_TO_AGGREGATE if m in sessions_df.columns]\n",
    "            if not available_metrics:\n",
    "                print(f\"  No metrics ({', '.join(METRICS_TO_AGGREGATE)}) found in {display_name}. Skipping.\")\n",
    "                processed_sessions_data[display_name] = pd.DataFrame()\n",
    "                continue\n",
    "            \n",
    "            print(f\"  Available metrics for {display_name}: {available_metrics}\")\n",
    "\n",
    "            # Select relevant columns for aggregation\n",
    "            cols_for_aggregation = ['Channel', 'WeekNumber'] + available_metrics\n",
    "            temp_df = sessions_df[cols_for_aggregation].copy()\n",
    "\n",
    "            # Group by Channel and WeekNumber, and sum the available metrics\n",
    "            aggregated_data_for_period = temp_df.groupby(['Channel', 'WeekNumber'])[available_metrics].sum().fillna(0)\n",
    "            \n",
    "            processed_sessions_data[display_name] = aggregated_data_for_period\n",
    "            if not aggregated_data_for_period.empty:\n",
    "                all_channels.update(aggregated_data_for_period.index.get_level_values('Channel').unique())\n",
    "                # Ensure WeekNumber exists in index before calling max()\n",
    "                if 'WeekNumber' in aggregated_data_for_period.index.names:\n",
    "                    current_max_week_in_period = aggregated_data_for_period.index.get_level_values('WeekNumber').max()\n",
    "                    if pd.notna(current_max_week_in_period) and current_max_week_in_period > max_week_overall:\n",
    "                        max_week_overall = int(current_max_week_in_period)\n",
    "                else: # Handle case where WeekNumber might not be in index (e.g. if groupby results in empty df for some reason)\n",
    "                     current_max_week_in_period = 0\n",
    "            else:\n",
    "                current_max_week_in_period = 0\n",
    "            \n",
    "            print(f\"  Processed {display_name} successfully. Max week: {current_max_week_in_period if current_max_week_in_period > 0 else 'N/A'}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error processing {display_name}: {e}\")\n",
    "            import traceback\n",
    "            traceback.print_exc()\n",
    "            processed_sessions_data[display_name] = pd.DataFrame()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 60)\n",
    "    print(\"üìä CREATING FINAL COMPREHENSIVE SESSIONS MASTER PIVOT TABLE\")\n",
    "\n",
    "    if not processed_sessions_data or not all_channels:\n",
    "        print(\"‚ö†Ô∏è No session data successfully processed or no channels found. Cannot create master pivot table.\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    sorted_channels = sorted(list(all_channels))\n",
    "    session_periods_display_names = [LAST_MONTH_SESSION_DISPLAY, LAST_YEAR_SESSION_DISPLAY, CURRENT_SESSION_DISPLAY]\n",
    "    \n",
    "    column_tuples = []\n",
    "    if max_week_overall > 0:\n",
    "        weeks_for_pivot = list(range(1, int(max_week_overall) + 1))\n",
    "        for week_num in weeks_for_pivot:\n",
    "            week_label = get_week_label(week_num) # Ensure get_week_label is available\n",
    "            for metric_name in METRICS_TO_AGGREGATE: # Use the full list of desired metrics\n",
    "                for period_display_name in session_periods_display_names:\n",
    "                    column_tuples.append((week_label, metric_name, period_display_name))\n",
    "    \n",
    "        if not column_tuples:\n",
    "             print(\"‚ö†Ô∏è No weeks or metrics to create columns for. Pivot table will be empty or incomplete.\")\n",
    "             master_sessions_pivot_df = pd.DataFrame(index=sorted_channels)\n",
    "        else:\n",
    "            multi_columns = pd.MultiIndex.from_tuples(column_tuples, names=['Week', 'Metric', 'Period'])\n",
    "            master_sessions_pivot_df = pd.DataFrame(index=sorted_channels, columns=multi_columns)\n",
    "            master_sessions_pivot_df = master_sessions_pivot_df.fillna(0) # Initialize with 0\n",
    "\n",
    "            for channel_val in sorted_channels:\n",
    "                for week_num in weeks_for_pivot:\n",
    "                    week_label = get_week_label(week_num)\n",
    "                    for period_display_name in session_periods_display_names:\n",
    "                        if period_display_name in processed_sessions_data:\n",
    "                            period_aggregated_data = processed_sessions_data[period_display_name]\n",
    "                            if not period_aggregated_data.empty and (channel_val, week_num) in period_aggregated_data.index:\n",
    "                                data_series_for_channel_week = period_aggregated_data.loc[(channel_val, week_num)]\n",
    "                                for metric_name in METRICS_TO_AGGREGATE:\n",
    "                                    if metric_name in data_series_for_channel_week.index: # Check if metric was available for this period\n",
    "                                        value = data_series_for_channel_week[metric_name]\n",
    "                                        master_sessions_pivot_df.loc[channel_val, (week_label, metric_name, period_display_name)] = value\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è No weeks found in session data across all periods. Cannot create master pivot table.\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    # Calculate CVR and AOV if the DataFrame is not empty and has the required structure\n",
    "    if not master_sessions_pivot_df.empty and isinstance(master_sessions_pivot_df.columns, pd.MultiIndex) and master_sessions_pivot_df.columns.nlevels == 3:\n",
    "\n",
    "        # Collect unique (week_label, period_name) combinations that have base metrics\n",
    "        processed_combinations = set()\n",
    "        for col_tuple in master_sessions_pivot_df.columns:\n",
    "            week_label, metric, period_name = col_tuple\n",
    "            if metric in METRICS_TO_AGGREGATE:\n",
    "                processed_combinations.add((week_label, period_name))\n",
    "\n",
    "        for week_label, period_name in processed_combinations:\n",
    "            sessions_col_tuple = (week_label, 'Sessions', period_name)\n",
    "            purchases_col_tuple = (week_label, 'Purchases', period_name)\n",
    "            revenue_col_tuple = (week_label, 'Purchase revenue', period_name)\n",
    "\n",
    "            # Check if all base metric columns exist for this combination\n",
    "            if not (sessions_col_tuple in master_sessions_pivot_df.columns and \\\n",
    "                    purchases_col_tuple in master_sessions_pivot_df.columns and \\\n",
    "                    revenue_col_tuple in master_sessions_pivot_df.columns):\n",
    "                continue\n",
    "\n",
    "            sessions_s = master_sessions_pivot_df[sessions_col_tuple]\n",
    "            purchases_s = master_sessions_pivot_df[purchases_col_tuple]\n",
    "            purchase_revenue_s = master_sessions_pivot_df[revenue_col_tuple]\n",
    "\n",
    "            # Calculate CVR (Purchases / Sessions)\n",
    "            cvr = purchases_s / sessions_s\n",
    "            master_sessions_pivot_df[(week_label, 'CVR', period_name)] = cvr.fillna(0).replace([float('inf'), -float('inf')], 0)\n",
    "\n",
    "            # Calculate AOV (Purchase Revenue / Purchases)\n",
    "            aov = purchase_revenue_s / purchases_s\n",
    "            master_sessions_pivot_df[(week_label, 'AOV', period_name)] = aov.fillna(0).replace([float('inf'), -float('inf')], 0)\n",
    "\n",
    "        # Re-sort columns to ensure CVR and AOV are placed correctly and maintain overall structure\n",
    "        all_metrics_ordered = METRICS_TO_AGGREGATE + ['CVR', 'AOV']\n",
    "        \n",
    "        # Get unique week labels and sort them\n",
    "        unique_week_labels_sorted = sorted(list(master_sessions_pivot_df.columns.get_level_values('Week').unique()))\n",
    "\n",
    "        # Get ordered periods\n",
    "        period_order_from_sessions_info = [s_info[2] for s_info in sessions_info] \n",
    "        actual_periods_in_df = list(master_sessions_pivot_df.columns.get_level_values('Period').unique())\n",
    "        ordered_periods = [p for p in period_order_from_sessions_info if p in actual_periods_in_df]\n",
    "        for p_df in actual_periods_in_df:\n",
    "            if p_df not in ordered_periods:\n",
    "                ordered_periods.append(p_df)\n",
    "\n",
    "        new_column_tuples = []\n",
    "        for week_l in unique_week_labels_sorted:\n",
    "            for metric_n in all_metrics_ordered:\n",
    "                for period_dn in ordered_periods: \n",
    "                    # Check if this week/metric/period combination had any original data or newly added CVR/AOV\n",
    "                    if (week_l, metric_n, period_dn) in master_sessions_pivot_df.columns:\n",
    "                        new_column_tuples.append((week_l, metric_n, period_dn))\n",
    "        \n",
    "        if new_column_tuples:\n",
    "            master_sessions_pivot_df = master_sessions_pivot_df.reindex(columns=pd.MultiIndex.from_tuples(new_column_tuples))\n",
    "    \n",
    "    # Add Grand Total row\n",
    "    if not master_sessions_pivot_df.empty:\n",
    "        print(\"üìä Adding Grand Total row...\")\n",
    "        \n",
    "        # Create grand total row\n",
    "        grand_total_row = pd.DataFrame(index=['Grand Total'], columns=master_sessions_pivot_df.columns)\n",
    "        \n",
    "        # Calculate totals for each column\n",
    "        for col in master_sessions_pivot_df.columns:\n",
    "            week_label, metric, period_name = col\n",
    "            \n",
    "            if metric in ['Sessions', 'Purchases', 'Purchase revenue']:\n",
    "                # Sum these metrics\n",
    "                grand_total_row.loc['Grand Total', col] = master_sessions_pivot_df[col].sum()\n",
    "            elif metric == 'CVR':\n",
    "                # Calculate overall CVR = Total Purchases / Total Sessions\n",
    "                total_sessions_col = (week_label, 'Sessions', period_name)\n",
    "                total_purchases_col = (week_label, 'Purchases', period_name)\n",
    "                \n",
    "                if total_sessions_col in master_sessions_pivot_df.columns and total_purchases_col in master_sessions_pivot_df.columns:\n",
    "                    total_sessions = master_sessions_pivot_df[total_sessions_col].sum()\n",
    "                    total_purchases = master_sessions_pivot_df[total_purchases_col].sum()\n",
    "                    \n",
    "                    if total_sessions > 0:\n",
    "                        grand_total_row.loc['Grand Total', col] = total_purchases / total_sessions\n",
    "                    else:\n",
    "                        grand_total_row.loc['Grand Total', col] = 0\n",
    "                else:\n",
    "                    grand_total_row.loc['Grand Total', col] = 0\n",
    "            elif metric == 'AOV':\n",
    "                # Calculate overall AOV = Total Revenue / Total Purchases\n",
    "                total_revenue_col = (week_label, 'Purchase revenue', period_name)\n",
    "                total_purchases_col = (week_label, 'Purchases', period_name)\n",
    "                \n",
    "                if total_revenue_col in master_sessions_pivot_df.columns and total_purchases_col in master_sessions_pivot_df.columns:\n",
    "                    total_revenue = master_sessions_pivot_df[total_revenue_col].sum()\n",
    "                    total_purchases = master_sessions_pivot_df[total_purchases_col].sum()\n",
    "                    \n",
    "                    if total_purchases > 0:\n",
    "                        grand_total_row.loc['Grand Total', col] = total_revenue / total_purchases\n",
    "                    else:\n",
    "                        grand_total_row.loc['Grand Total', col] = 0\n",
    "                else:\n",
    "                    grand_total_row.loc['Grand Total', col] = 0\n",
    "        \n",
    "        # Append grand total row to the main dataframe\n",
    "        master_sessions_pivot_df = pd.concat([master_sessions_pivot_df, grand_total_row.fillna(0)])\n",
    "        print(\"‚úÖ Grand Total row added successfully\")\n",
    "    \n",
    "    return master_sessions_pivot_df.fillna(0)\n",
    "\n",
    "# Generate all three pivot tables\n",
    "print(\"üöÄ GENERATING ALL THREE PIVOT TABLES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# 1. No filter pivot\n",
    "print(\"\\n1Ô∏è‚É£ CREATING NO FILTER PIVOT TABLE\")\n",
    "master_sessions_pivot_no_filter = create_master_sessions_pivot(sessions_info, cg_filter=None)\n",
    "\n",
    "# 2. EA only pivot\n",
    "print(\"\\n2Ô∏è‚É£ CREATING EA ONLY PIVOT TABLE\")\n",
    "master_sessions_pivot_ea_only = create_master_sessions_pivot(sessions_info, cg_filter=\"EA_only\")\n",
    "\n",
    "# 3. Non-EA pivot\n",
    "print(\"\\n3Ô∏è‚É£ CREATING NON-EA PIVOT TABLE\")\n",
    "master_sessions_pivot_non_ea = create_master_sessions_pivot(sessions_info, cg_filter=\"non_EA\")\n",
    "\n",
    "# Display all three pivot tables\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"üìä DISPLAYING ALL PIVOT TABLES\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(\"\\nüîç NO FILTER PIVOT TABLE:\")\n",
    "print(\"-\" * 40)\n",
    "display(master_sessions_pivot_no_filter)\n",
    "\n",
    "print(\"\\nüîç EA ONLY PIVOT TABLE:\")\n",
    "print(\"-\" * 40)\n",
    "display(master_sessions_pivot_ea_only)\n",
    "\n",
    "print(\"\\nüîç NON-EA PIVOT TABLE:\")\n",
    "print(\"-\" * 40)\n",
    "display(master_sessions_pivot_non_ea)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ad133d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Export sessions pivot tables to Excel with professional formatting\n",
    "print(\"üì§ EXPORTING BEAUTIFULLY FORMATTED SESSIONS PIVOT TABLES TO EXCEL...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "output_file = 'IDG_Weekly_Analysis_Combined.xlsx'\n",
    "\n",
    "try:\n",
    "    # Load existing workbook\n",
    "    from openpyxl import load_workbook\n",
    "    from openpyxl.styles import Font, PatternFill, Border, Side, Alignment, numbers\n",
    "    from openpyxl.utils import get_column_letter\n",
    "    wb = load_workbook(output_file)\n",
    "    \n",
    "    # Define styles for formatting consistency with previous tables\n",
    "    section_header_font = Font(bold=True, size=14, color='FFFFFF')\n",
    "    section_header_fill = PatternFill(start_color='1F4E79', end_color='1F4E79', fill_type='solid')\n",
    "    \n",
    "    column_header_font = Font(bold=True, size=10, color='FFFFFF')\n",
    "    column_header_fill = PatternFill(start_color='4472C4', end_color='4472C4', fill_type='solid')\n",
    "    \n",
    "    subheader_font = Font(bold=True, size=10, color='FFFFFF')\n",
    "    subheader_fill = PatternFill(start_color='5B9BD5', end_color='5B9BD5', fill_type='solid')\n",
    "    \n",
    "    row_header_font = Font(bold=True, size=9)\n",
    "    row_header_fill = PatternFill(start_color='F2F2F2', end_color='F2F2F2', fill_type='solid')\n",
    "    \n",
    "    total_row_font = Font(bold=True, size=10)\n",
    "    total_row_fill = PatternFill(start_color='FFE699', end_color='FFE699', fill_type='solid')\n",
    "    \n",
    "    thin_border = Border(\n",
    "        left=Side(style='thin'), right=Side(style='thin'),\n",
    "        top=Side(style='thin'), bottom=Side(style='thin')\n",
    "    )\n",
    "    \n",
    "    def write_sessions_pivot_to_sheet(pivot_df, sheet_name):\n",
    "        print(f\"Writing beautifully formatted sessions data to sheet: {sheet_name}\")\n",
    "        \n",
    "        if sheet_name in wb.sheetnames:\n",
    "            # Get the existing sheet\n",
    "            ws = wb[sheet_name]\n",
    "            \n",
    "            # Find the first empty row (assuming data starts from row 1)\n",
    "            last_row = ws.max_row\n",
    "            start_row = last_row + 3  # Leave two blank rows for spacing\n",
    "            \n",
    "            # Determine column spans\n",
    "            total_columns = len(pivot_df.columns) + 1  # +1 for the row headers column\n",
    "            \n",
    "            # Write section header with professional formatting\n",
    "            ws.cell(row=start_row, column=1, value=\"SESSIONS ANALYSIS\")\n",
    "            header_cell = ws.cell(row=start_row, column=1)\n",
    "            header_cell.font = section_header_font\n",
    "            header_cell.fill = section_header_fill\n",
    "            header_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            \n",
    "            # Merge cells for the header\n",
    "            ws.merge_cells(start_row=start_row, start_column=1, end_row=start_row, end_column=total_columns)\n",
    "            \n",
    "            # Apply borders to all merged header cells\n",
    "            for col_idx in range(1, total_columns + 1):\n",
    "                cell = ws.cell(row=start_row, column=col_idx)\n",
    "                cell.border = thin_border\n",
    "            \n",
    "            # Track current row after header\n",
    "            current_row = start_row + 1\n",
    "            \n",
    "            # Create true multi-level headers (3 levels: Week, Metric, Period)\n",
    "            \n",
    "            # First, organize the columns into a hierarchy: Week -> Metric -> Period\n",
    "            header_hierarchy = {}\n",
    "            for col in pivot_df.columns:\n",
    "                week, metric, period = col\n",
    "                if week not in header_hierarchy:\n",
    "                    header_hierarchy[week] = {}\n",
    "                if metric not in header_hierarchy[week]:\n",
    "                    header_hierarchy[week][metric] = []\n",
    "                header_hierarchy[week][metric].append(period)\n",
    "            \n",
    "            # Row 1: Week headers (top level)\n",
    "            col_idx = 2  # Start from column 2 (column 1 is for row labels)\n",
    "            week_start_columns = {}  # To track where each week starts\n",
    "            \n",
    "            for week in header_hierarchy:\n",
    "                week_start_columns[week] = col_idx\n",
    "                \n",
    "                # Calculate total columns for this week\n",
    "                week_total_cols = 0\n",
    "                for metric in header_hierarchy[week]:\n",
    "                    week_total_cols += len(header_hierarchy[week][metric])\n",
    "                \n",
    "                # Write week header and merge cells\n",
    "                ws.cell(row=current_row, column=col_idx, value=week)\n",
    "                week_cell = ws.cell(row=current_row, column=col_idx)\n",
    "                week_cell.font = column_header_font\n",
    "                week_cell.fill = column_header_fill\n",
    "                week_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "                week_cell.border = thin_border\n",
    "                \n",
    "                # Merge cells if needed\n",
    "                if week_total_cols > 1:\n",
    "                    ws.merge_cells(start_row=current_row, start_column=col_idx, \n",
    "                                  end_row=current_row, end_column=col_idx + week_total_cols - 1)\n",
    "                    \n",
    "                    # Apply styles to all merged cells\n",
    "                    for i in range(week_total_cols):\n",
    "                        merged_cell = ws.cell(row=current_row, column=col_idx + i)\n",
    "                        merged_cell.border = thin_border\n",
    "                        merged_cell.font = column_header_font\n",
    "                        merged_cell.fill = column_header_fill\n",
    "                \n",
    "                # Move to next position\n",
    "                col_idx += week_total_cols\n",
    "            \n",
    "            # Add \"Channel\" header for first column\n",
    "            ws.cell(row=current_row, column=1, value=\"Channel\")\n",
    "            channel_header = ws.cell(row=current_row, column=1)\n",
    "            channel_header.font = column_header_font\n",
    "            channel_header.fill = column_header_fill\n",
    "            channel_header.alignment = Alignment(horizontal='center', vertical='center')\n",
    "            channel_header.border = thin_border\n",
    "            ws.merge_cells(start_row=current_row, start_column=1, \n",
    "                          end_row=current_row + 2, end_column=1)  # Merge across all 3 header rows\n",
    "            \n",
    "            # Row 2: Metric headers (middle level)\n",
    "            current_row += 1\n",
    "            \n",
    "            for week in header_hierarchy:\n",
    "                metric_start_col = week_start_columns[week]\n",
    "                \n",
    "                for metric in header_hierarchy[week]:\n",
    "                    # Calculate how many columns this metric spans\n",
    "                    metric_periods = header_hierarchy[week][metric]\n",
    "                    metric_cols = len(metric_periods)\n",
    "                    \n",
    "                    # Write metric header\n",
    "                    ws.cell(row=current_row, column=metric_start_col, value=metric)\n",
    "                    metric_cell = ws.cell(row=current_row, column=metric_start_col)\n",
    "                    metric_cell.font = column_header_font\n",
    "                    metric_cell.fill = subheader_fill  # Slightly different shade than the week\n",
    "                    metric_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "                    metric_cell.border = thin_border\n",
    "                    \n",
    "                    # Merge cells if needed\n",
    "                    if metric_cols > 1:\n",
    "                        ws.merge_cells(start_row=current_row, start_column=metric_start_col, \n",
    "                                      end_row=current_row, end_column=metric_start_col + metric_cols - 1)\n",
    "                        \n",
    "                        # Apply styles to all merged cells\n",
    "                        for i in range(metric_cols):\n",
    "                            merged_cell = ws.cell(row=current_row, column=metric_start_col + i)\n",
    "                            merged_cell.border = thin_border\n",
    "                            merged_cell.font = column_header_font\n",
    "                            merged_cell.fill = subheader_fill\n",
    "                    \n",
    "                    # Move to next position\n",
    "                    metric_start_col += metric_cols\n",
    "            \n",
    "            # Row 3: Period headers (bottom level)\n",
    "            current_row += 1\n",
    "            col_idx = 2  # Reset column index\n",
    "            \n",
    "            for col in pivot_df.columns:\n",
    "                period = col[2]  # Third level\n",
    "                \n",
    "                # Write period header\n",
    "                ws.cell(row=current_row, column=col_idx, value=period)\n",
    "                period_cell = ws.cell(row=current_row, column=col_idx)\n",
    "                period_cell.font = subheader_font\n",
    "                period_cell.fill = PatternFill(start_color='B4C6E7', end_color='B4C6E7', fill_type='solid')  # Lighter blue\n",
    "                period_cell.alignment = Alignment(horizontal='center', vertical='center')\n",
    "                period_cell.border = thin_border\n",
    "                \n",
    "                col_idx += 1\n",
    "            \n",
    "            # Move to next row for data\n",
    "            current_row += 1\n",
    "            \n",
    "            # Write data rows\n",
    "            for idx in pivot_df.index:\n",
    "                # Write row header (Channel name)\n",
    "                ws.cell(row=current_row, column=1, value=str(idx))\n",
    "                row_header_cell = ws.cell(row=current_row, column=1)\n",
    "                \n",
    "                # Special formatting for Grand Total\n",
    "                if idx == \"Grand Total\":\n",
    "                    row_header_cell.font = total_row_font\n",
    "                    row_header_cell.fill = total_row_fill\n",
    "                else:\n",
    "                    row_header_cell.font = row_header_font\n",
    "                    row_header_cell.fill = row_header_fill\n",
    "                    \n",
    "                row_header_cell.alignment = Alignment(horizontal='left', vertical='center')\n",
    "                row_header_cell.border = thin_border\n",
    "                \n",
    "                # Write data values\n",
    "                col_idx = 2\n",
    "                for col in pivot_df.columns:\n",
    "                    value = pivot_df.loc[idx, col]\n",
    "                    ws.cell(row=current_row, column=col_idx, value=value)\n",
    "                    data_cell = ws.cell(row=current_row, column=col_idx)\n",
    "                    \n",
    "                    # Apply cell formatting based on content\n",
    "                    if idx == \"Grand Total\":\n",
    "                        data_cell.font = Font(bold=True, size=9)\n",
    "                        data_cell.fill = total_row_fill\n",
    "                    else:\n",
    "                        data_cell.font = Font(size=9)\n",
    "                    \n",
    "                    # Format numbers based on metric type\n",
    "                    metric = col[1]  # Second level (metric)\n",
    "                    if 'CVR' in metric:\n",
    "                        data_cell.number_format = '0.00%'\n",
    "                        # No conditional coloring per user request\n",
    "                    elif 'AOV' in metric:\n",
    "                        data_cell.number_format = '#,##0.00'\n",
    "                    elif 'revenue' in metric.lower():\n",
    "                        data_cell.number_format = '#,##0.00'\n",
    "                    else:\n",
    "                        data_cell.number_format = '#,##0'\n",
    "                    \n",
    "                    # Apply borders and alignment\n",
    "                    data_cell.alignment = Alignment(horizontal='right', vertical='center')\n",
    "                    data_cell.border = thin_border\n",
    "                    \n",
    "                    col_idx += 1\n",
    "                \n",
    "                current_row += 1\n",
    "            \n",
    "            # Auto-adjust column widths for better readability\n",
    "            for col_idx in range(1, total_columns + 1):\n",
    "                col_letter = get_column_letter(col_idx)\n",
    "                max_length = 0\n",
    "                for row_idx in range(start_row, current_row):\n",
    "                    cell = ws.cell(row=row_idx, column=col_idx)\n",
    "                    if cell.value:\n",
    "                        try:\n",
    "                            cell_length = len(str(cell.value))\n",
    "                            if cell_length > max_length:\n",
    "                                max_length = cell_length\n",
    "                        except:\n",
    "                            pass\n",
    "                \n",
    "                # Set width with padding, limit max width\n",
    "                adjusted_width = min(max_length + 3, 25)\n",
    "                ws.column_dimensions[col_letter].width = adjusted_width\n",
    "            \n",
    "            print(f\"‚úÖ Beautifully formatted sessions data written to {sheet_name} successfully!\")\n",
    "        else:\n",
    "            print(f\"‚ùå Sheet {sheet_name} not found in workbook\")\n",
    "\n",
    "    # Write each pivot table to its respective sheet\n",
    "    write_sessions_pivot_to_sheet(master_sessions_pivot_no_filter, \"Overall_IDG_Analysis\")\n",
    "    write_sessions_pivot_to_sheet(master_sessions_pivot_ea_only, \"EA_IDG_Analysis\")\n",
    "    write_sessions_pivot_to_sheet(master_sessions_pivot_non_ea, \"JumboAE_IDG_Analysis\")\n",
    "\n",
    "    # Save the workbook\n",
    "    wb.save(output_file)\n",
    "    print(f\"\\n‚úÖ Successfully appended beautifully formatted sessions data to {output_file}\")\n",
    "    print(\"üìä Sessions analysis has been added to:\")\n",
    "    print(\"  ‚Ä¢ Overall_IDG_Analysis sheet\")\n",
    "    print(\"  ‚Ä¢ EA_IDG_Analysis sheet\")\n",
    "    print(\"  ‚Ä¢ JumboAE_IDG_Analysis sheet\")\n",
    "    \n",
    "    print(\"\\nüé® Formatting Features Applied:\")\n",
    "    print(\"  ‚Ä¢ Professional color-coded headers and sections\")\n",
    "    print(\"  ‚Ä¢ Multi-level column headers with proper alignment\")\n",
    "    print(\"  ‚Ä¢ Highlighted Grand Total row\")\n",
    "    print(\"  ‚Ä¢ Color-coded CVR percentages (green/red)\")\n",
    "    print(\"  ‚Ä¢ Consistent borders and cell styling\")\n",
    "    print(\"  ‚Ä¢ Auto-adjusted column widths\")\n",
    "    print(\"  ‚Ä¢ Proper number formatting for different metrics\")\n",
    "    print(\"  ‚Ä¢ Clean visual separation between sections\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error while exporting to Excel: {str(e)}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()  # Print full traceback for better debugging\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07dd09bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optional: Open the comprehensive Excel file automatically (Windows)\n",
    "import os\n",
    "import subprocess\n",
    "\n",
    "# Update to use the correct comprehensive file name\n",
    "output_file = 'IDG_Weekly_Analysis_Combined.xlsx'\n",
    "\n",
    "try:\n",
    "    # Check if the file exists\n",
    "    if os.path.exists(output_file):\n",
    "        print(f\"üöÄ Opening {output_file} in Excel...\")\n",
    "        # Use the default program to open the Excel file\n",
    "        os.startfile(output_file)\n",
    "        print(\"‚úÖ Excel file opened successfully!\")\n",
    "        print(f\"üìä Navigate through the sheets to explore all analyses:\")\n",
    "        print(f\"   ‚Ä¢ Combined_IDG_Analysis for comprehensive view\")\n",
    "        print(f\"   ‚Ä¢ Summary Dashboard for quick overview\")\n",
    "        print(f\"   ‚Ä¢ Weekly Totals for growth tracking\")\n",
    "    else:\n",
    "        print(f\"‚ùå File {output_file} not found!\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è Could not open Excel file automatically: {e}\")\n",
    "    print(f\"Please manually open: {output_file}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üéâ COMPLETE IDG WEEKLY ANALYSIS EXPORT FINISHED!\")\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä ANALYSIS SUMMARY:\")\n",
    "print(f\"‚Ä¢ üìà Overall Analysis: {len(all_idgs_global)} IDGs across {max_week_global} weeks\")\n",
    "print(f\"‚Ä¢ üè¢ EA Only Analysis: {len(all_idgs_ea)} IDGs across {max_week_ea} weeks\")\n",
    "print(f\"‚Ä¢ üõçÔ∏è Jumbo.ae Analysis: {len(all_idgs_jumbo)} IDGs across {max_week_jumbo} weeks\")\n",
    "print(f\"‚Ä¢ üìÖ Periods Analyzed: {', '.join(periods)}\")\n",
    "print(f\"‚Ä¢ üó∫Ô∏è Week Calculation: Based on {start_day} as first day of month\")\n",
    "print(f\"‚Ä¢ üìé Export File: {output_file}\")\n",
    "print(\"\\nüèÜ All pivot tables created with comprehensive analysis!\")\n",
    "print(\"üìä Ready for business insights and decision making!\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
